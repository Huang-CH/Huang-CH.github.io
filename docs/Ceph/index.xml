<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ceph on 黄 超 | H&amp;C</title>
    <link>https://Huang-CH.github.io/docs/Ceph/</link>
    <description>Recent content in Ceph on 黄 超 | H&amp;C</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://Huang-CH.github.io/docs/Ceph/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ceph部署手册</title>
      <link>https://Huang-CH.github.io/docs/Ceph/Ceph%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Huang-CH.github.io/docs/Ceph/Ceph%E9%83%A8%E7%BD%B2%E6%89%8B%E5%86%8C/</guid>
      <description>主机规划#  Ceph-01
 eth0：10.10.10.101/24 eth1：192.168.1.101/24  Ceph-02
 eth0：10.10.10.102/24 eth1：192.168.1.102/24  Ceph-03
 eth0：10.10.10.103/24 eth1：192.168.1.103/24  操作系统：OpenEuler 22.03 LTS
  基础配置# 修改主机名称
hostnamectl set-hostname Ceph-0X 修改IP地址
vim /etc/sysconfig/network-scripts/ifcfg-ethX 关闭防火墙
systemctl stop firewalld.service &amp;amp;&amp;amp; systemctl disable firewalld.service 关闭SELinux
sed -i &amp;#39;s/SELINUX=enforcing/SELINUX=disabled/&amp;#39; /etc/selinux/config 修改/etc/hosts文件
10.10.10.101 Ceph-01 10.10.10.102 Ceph-02 10.10.10.103 Ceph-03 192.168.1.101 Ceph-01-Cluster 192.168.1.102 Ceph-02-Cluster 192.168.1.103 Ceph-03-Cluster 安装时间同步服务
yum -y install chrony 同步时间
chronyc sources -v  安装Docker# 在/opt/目录下新建installer目录</description>
    </item>
    
    <item>
      <title>:Ceph客户端安装手册</title>
      <link>https://Huang-CH.github.io/docs/Ceph/Ceph%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://Huang-CH.github.io/docs/Ceph/Ceph%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AE%89%E8%A3%85%E6%89%8B%E5%86%8C/</guid>
      <description>安装Ceph客户端# 在客户端主机（10.10.1.200）上安装ceph-common
yum -y install ceph-common 在MON主机（10.10.10.101）上将ceph.conf和ceph.client.admin.keyring拷贝至客户端主机（10.10.10.200）
scp /etc/ceph/ceph.conf root@10.10.10.200:/etc/ceph/ scp /etc/ceph/ceph.client.admin.keyring root@10.10.10.200:/etc/ceph/ 在客户端主机上查看Ceph集群信息
ceph -s  使用Ceph块存储#  块存储接口可以像使用本地磁盘一样来使用Ceph提供的块存储设备。
使用Ceph块存储设备前，需要先创建一个RBD池。再创建RBD池之后，对存储进行定义，并创建属于该池的块存储设备。块存储设备创建完成后，就可以在Ceph客户端进行映射和挂载了。
  RBD创建与挂载# 创建RBD Pool
ceph osd pool create rbd 512  其中，512是放置组（Placement Group）的数量，放置组数量的计算公式为PGs = ( OSDs * 100 ) / pool size，其中pool size是复制池的副本数量，或用于删除代码池的K+M总和（ceph osd erasure-code-profile的返回值），其结果应舍入到接近2的指数。
设置每个OSD中最大放置组限制数为1000
ceph config set mon mon_max_pg_per_osd 1000 设置RBD Pool自动扩展
ceph osd pool set &amp;lt;POOL_NAME&amp;gt; pg_autoscale_mode on 若要删除RBD Pool，必须设置--mon-allow-pool-delete=true参数，否则无法删除</description>
    </item>
    
  </channel>
</rss>
