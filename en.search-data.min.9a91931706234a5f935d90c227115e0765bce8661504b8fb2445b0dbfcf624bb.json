[{"id":0,"href":"/docs/Python/Python%E4%B9%8B%E5%9F%BA%E7%A1%80%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Python之基础数据类型","section":"Python","content":"Python基础数据类型\r#\r\r Python数据类型的分类（按照可变与不可变进行分类）：\n可变（不可哈希）的数据类型：列表（list）、字典（dict）、集合（set）\n不可变（可哈希）的数据类型：字符串（str）、数值（int）、布尔值（bool）、元组（tuple）\n 按照存储空间从低到高排序\n  数字\n  字符串\n  集合（无序，即无索引相关信息）\n  元组（有序，需要存储索引相关信息，不可变）\n  列表（有序，需要存储索引相关信息，可变，需要处理数据的增、删、改等操作）\n  字典（3.6之后有序，需要存储key与value的相关信息，可变，需要处理数据的增、删、改等操作）\n 数字 \u0026lt; 字符串 \u0026lt; 集合 \u0026lt; 元组 \u0026lt; 列表 \u0026lt; 字典\n    按照存值类型区分\n 非容器型/原子类型：数字、字符串 容器型：元组、列表、字典   按照可变类型区分\n 不可变类型：数字、字符串、布尔值、元组 可变类型：列表、字典   按照访问顺序区分\n  直接访问：数字\n  顺序访问（序列类型）：字符串、元组、列表\n  键值访问（映射类型）：字典\n键值访问的效率远高于顺序访问，但占用的存储空间也更大。\n   int\r#\r\r 数值类型\nint() 函数用于将一个字符串或数字转换为整型\n 函数语法\nint(x, base=10)  x：字符串或数字。 base：进制数，默认十进制。\n  返回值\n 返回整型数据\n  常用内置方法\n bit_length() （十进制转换成二进制后有效的二进制位数）\n bit_length()i = 10 print(i.bit_length())  bool\r#\r\r 布尔值\nbool() 函数用于将给定参数转换为布尔类型，如果没有参数，返回False\nbool类型是int的子类\n 函数语法\nbool(x)  x：要进行转换的参数。\n  返回值\n 返回True或False\n  bool与其他数据类型的转换\n所有的数据类型都可以转换成布尔值，即：所数据类型都自带布尔值，非零即True，零或空即False。\nbool转换成int\n bool 值：True转换成int的值是：1\nbool值：False转换成int的值是：0\n int转换成bool\n 非零即True，零即False\n bool转换成str\n 布尔值加上单引号或双引号即变成字符串\n str转换成bool\n 非空即True，空字符串即False。\n  字符串\r#\r\r 字符串（str）是 Python 中最常用的数据类型。使用引号(\u0026lsquo;或\u0026quot;)来创建字符串。字符串从左至右有顺序，可进行索引、切片，索引、切片后的数据开辟新的内存空间，数据类型仍是字符串。\ns = \u0026#34;Python字符串\u0026#34;  字符串的类型有两种：一种是str，另一种是bytes\n  字符串的索引\r#\r\r Python 对字符串中的元素取值时，可以使用方括号来截取字符串中的元素\ns = \u0026#34;Python字符串\u0026#34; print(s[4]) # 输出结果：o  字符串的切片\r#\r\r  切片的特点是：顾头不顾尾\n 字符串从头切片\ns = \u0026#34;Python字符串\u0026#34; print(s[0:6]\t# 可以简写成：print(s[:6]) # 输出结果：Python 字符串从中间切片\ns = \u0026#34;Python字符串\u0026#34; print(s[6:8]) # 输出结果： 字符 字符串从未尾切片\ns = \u0026#34;Python字符串\u0026#34; print(s[-3:]) # 输出结果： 字符串 字符串切片加步长\ns = \u0026#34;Python字符串\u0026#34; print(s[1:8:2]) # 输出结果： yhn符 字符串反向切片\ns = \u0026#34;Python字符串\u0026#34; print(s[-1::-1])\t# s[-1::-1]表示从字符串的末尾到开头，最后的-1表示反向步长，进行反向切片 # 输出结果：串符字nohtyP  字符串常用的内置方法\r#\r\r upper：将字符串中的英文全部变为大写（★）\ns = \u0026#34;Python字符串\u0026#34; s_upper = s.upper() # 不会更改字符串s的值，s_upper会开辟新的内存空间存储数据 print(s_upper) # 输出结果：PYTHON字符串 # 应用场景（用于验证码或其他不区分大小写的验证） code = \u0026#34;QwEr\u0026#34; while 1: user_input_code = input(\u0026#34;请输入验证码：\u0026#34;).strip() if user_input_code.upper() == code.upper(): print(\u0026#34;验证成功！\u0026#34;) break else: print(\u0026#34;验证失败！请重新输入！\u0026#34;) lower：将字符串中的英文全部变为小写（★）\ns = \u0026#34;Python字符串\u0026#34; s_lower = s.lower() print(s_lower) # 输出结果：python字符串 capitalize：将字符串首字母大写，其他变成小写\ns = \u0026#34;pyThon\u0026#34; print(s.capitalize()) #输出结果：Python swapcase：将字符串中的大小写字母互换\ns = \u0026#34;pyThon\u0026#34; print(s.swapcase()) #输出结果：PYtHON title：非字母元素隔开的每个单词首字母大写\ns = \u0026#34;beautiful is better than ugly.\u0026#34; print(s.title()) #输出结果：Beautiful Is Better Than Ugly. center：字符串居中，可设置左右宽度及空白填充字符\ns = \u0026#34;Welcome\u0026#34; print(s.center(20,\u0026#34;-\u0026#34;)) #输出结果：------Welcome------- find：通过字符查找所在字符串中的索引位置（特点：如果有重复，则找到第一个，后面的就不找了，如果找不到返回值：-1）\ns = \u0026#34;Welcome\u0026#34; print(s.find(\u0026#34;c\u0026#34;)) #输出结果：3 # 如果找不到就返回-1 s = \u0026#34;Welcome\u0026#34; print(s.find(\u0026#34;a\u0026#34;)) #输出结果：-1 index：通过字符查找所在字符串中的索引位置（特点：如果有重复，则找到第一个，后面的就不找了，如果找不到会报错）\ns = \u0026#34;Welcome\u0026#34; print(s.index(\u0026#34;c\u0026#34;)) #输出结果：3 # 如果找不到会报错 s = \u0026#34;Welcome\u0026#34; print(s.index(\u0026#34;a\u0026#34;)) #输出结果： \u0026#39;\u0026#39;\u0026#39; Traceback (most recent call last): File \u0026#34;C:/Python/Python3.8/test.py\u0026#34;, line 5, in \u0026lt;module\u0026gt; print(s.index(\u0026#34;a\u0026#34;)) ValueError: substring not found \u0026#39;\u0026#39;\u0026#39; startswith：判断字符串是否以……开始（★）\ns = \u0026#34;Python字符串\u0026#34; print(s.startswith(\u0026#34;Py\u0026#34;)) # 输出结果：True s = \u0026#34;Python字符串\u0026#34; # print(s.startswith(\u0026#34;py\u0026#34;)) # # 输出结果：False s = \u0026#34;Python字符串\u0026#34; print(s.startswith(\u0026#34;t\u0026#34;, 2, 6))\t# 判断字符串2到6的切片是否以\u0026#34;t\u0026#34;开头 # 输出结果：True endswith：判断字符串是否以……结束（★）\ns = \u0026#34;Python字符串\u0026#34; print(s.endswith(\u0026#34;字符串\u0026#34;)) # 输出结果：True # 其他功能同startswith replace：替换字符串中指定的元素（★）\ns = \u0026#34;Python字符串是Python中最常用的数据类型\u0026#34; print(s.replace(\u0026#34;Python\u0026#34;, \u0026#34;py\u0026#34;)) # 默认将所有指定内容全部替换 # s.replace(\u0026#34;Python\u0026#34;, \u0026#34;py\u0026#34;)不会更改字符串s的值，会开辟新的内存空间存储数据。 # 输出结果：py字符串是py中最常用的数据类型 s = \u0026#34;Python字符串是Python中最常用的数据类型\u0026#34; print(s.replace(\u0026#34;Python\u0026#34;, \u0026#34;py\u0026#34;, 1)) # 1表示从左往右指定替换的个数 # py字符串是Python中最常用的数据类型 strip：去除字符串左右两边的空白（★）\ns = \u0026#34; \\nPython字符串 \\t\u0026#34; print(s.strip()) # 输出结果：Python字符串 # 不仅可以去除空白，还可以去除指定的字符 s = \u0026#34;aacdPython字符串abc\u0026#34; print(s.strip(\u0026#34;abcd\u0026#34;)) # 输出结果：Python字符串 # 去除机制和原理：左右两边同时查找有没有指定去除的元素，有就去除，知道没有后停止。 split：将字符串分割成列表（非常重要）（★）\n# 默认按照空格分割成列表 s = \u0026#34;Python 字符串\u0026#34; print(s.split()) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;字符串\u0026#39;] # 按照指定字符分割成列表 s = \u0026#34;,Python,字,符,串\u0026#34; print(s.split(\u0026#34;,\u0026#34;)) # 输出结果：[\u0026#39;\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;字\u0026#39;, \u0026#39;符\u0026#39;, \u0026#39;串\u0026#39;] # 按照指定字符的个数分割成列表 s = \u0026#34;,Python,字,符,串\u0026#34; print(s.split(\u0026#34;,\u0026#34;, 2)) # 输出结果：[\u0026#39;\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;字,符,串\u0026#39;] john：将任何可迭代对象换成字符串类型（非常重要）（★）\ns = \u0026#34;Python字符串\u0026#34; s1 = \u0026#34;-\u0026#34;.join(s) print(s1) # 输出结果：P-y-t-h-o-n-字-符-串 l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;转换\u0026#34;, \u0026#34;字符串\u0026#34;] s = \u0026#34;\u0026#34;.join(l) print(s) # 输出结果：Python列表转换字符串 l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;转换\u0026#34;, \u0026#34;字符串\u0026#34;] s = \u0026#34;-\u0026#34;.join(l) print(s) # 输出结果：Python-列表-转换-字符串 count：计算字符串中某个字符出现的次数（★）\ns = \u0026#34;qwertyasdfgswdfgdef\u0026#34; print(s.count(\u0026#34;f\u0026#34;)) # 输出结果：3 format：字符串格式化输出（★）\n# 按照顺序进行格式化输出 s = \u0026#34;{}字符串{}\u0026#34;.format(\u0026#34;Python\u0026#34;, \u0026#34;格式化输出\u0026#34;) print(s) # 输出结果：Python字符串格式化输出 # 按照索引进行格式化输出 s = \u0026#34;{1}字符串{0}\u0026#34;.format(\u0026#34;Python\u0026#34;, \u0026#34;格式化输出\u0026#34;) print(s) # 输出结果：格式化输出字符串Python # 按照key、value格式化输出 s = \u0026#34;{a}字符串{b}\u0026#34;.format(a=\u0026#34;Python\u0026#34;, b=\u0026#34;格式化输出\u0026#34;) print(s) # 输出结果：Python字符串格式化输出 is系列：对字符串进行判断的一系列内置功能（★）\ns = \u0026#34;Python字符串\u0026#34; print(s.isalpha() # 判断是否由字母组成 # 输出结果：True s = \u0026#34;Python字符串\u0026#34; print(s.isdecimal()) # 判断是否由十进制数字组成 # 输出结果：False # 应用案例： while 1: s = input(\u0026#34;请输入交易金额：\u0026#34;) if s.isdecimal(): s = int(s) print(\u0026#34;交易金额为：{}元\u0026#34;.format(s)) break else: print(\u0026#34;输入有误，请重新输入！\u0026#34;) s = \u0026#34;Python字符串\u0026#34; print(s.isalnum()) # 判断是否由字母或数字组成 # 输出结果：False  字符串的成员运算\r#\r\r  所有可迭代对象（字符串、列表、元组等）都支持成员运算，返回布尔值。一般与for循环联用。\n 运算符：in\n如果在指定的序列中找到值返回True，否则返回False。\ns = \u0026#34;Python字符串\u0026#34; print(\u0026#34;hon\u0026#34; in s) # 输出结果：True s = \u0026#34;Python字符串\u0026#34; print(\u0026#34;Pon\u0026#34; in s) # 输出结果：False 运算符：not in\n如果在指定的序列中没有找到值返回 True，否则返回 False。\ns = \u0026#34;Python字符串\u0026#34; print(\u0026#34;字符串\u0026#34; not in s) # 输出结果：False s = \u0026#34;Python字符串\u0026#34; print(\u0026#34;字串\u0026#34; not in s) # 输出结果：True  字符串的格式化操作\r#\r\r 方式一：%-formatting（Python诞生时就有）\ns = \u0026#39;%s的格式化%s\u0026#39; %(\u0026#39;字符串\u0026#39;, \u0026#39;输出\u0026#39;) print(s)\t# 字符串的格式化输出 方式二：str.format()（Python 2.6中引入）\ns = \u0026#39;{}的格式化{}\u0026#39;.format(\u0026#39;字符串\u0026#39;, \u0026#39;输出\u0026#39;) print(s)\t# 字符串的格式化输出 s = \u0026#39;{b}的格式化{a}\u0026#39;.format(a=\u0026#39;字符串\u0026#39;, b=\u0026#39;输出\u0026#39;) print(s)\t# 输出的格式化字符串 方式三：F-Strings（Python 3.6中引入，不仅格式更简单，支持表达式，而且替换的效率更高）\n# 标准格式化输出 s1 = \u0026#39;Python\u0026#39; s2 = \u0026#39;输出\u0026#39; s = F\u0026#39;{s1}的格式化{s2}\u0026#39; print(s)\t# Python的格式化输出 # 任意表达式输出 d = {\u0026#39;name\u0026#39;:\u0026#39;Python\u0026#39;, \u0026#39;age\u0026#39;:2020-1989} s = F\u0026#39;{d[\u0026#34;name\u0026#34;]}今年{d[\u0026#34;age\u0026#34;]}岁了\u0026#39; print(s)\t# Python今年31岁了 # 调取函数 def func(): return \u0026#39;Python\u0026#39; s = F\u0026#39;{func()}的格式化输出\u0026#39; print(s)\t# Python的格式化输出 # -------------------------分隔符---------------------------- def func(a,b): c = a + b return c s = F\u0026#39;两个数的求和结果是：{func(10,20)}\u0026#39; print(s)\t# 两个数的求和结果是：30  bytes\r#\r\r bytes函数返回一个新的bytes对象，该对象是一个 0 \u0026lt;= x \u0026lt; 256 区间内的整数不可变序列。它是bytearray的不可变版本。主要用于文件操作和网络编程。\n 字符串转化bytes（字符串的中文和英文的bytes表现形式不一样）\ns_1 = \u0026#34;abc\u0026#34; s_2 = \u0026#34;字符串\u0026#34; b_1 = s_1.encode(\u0026#34;UTF-8\u0026#34;) b_2 = s_2.encode(\u0026#34;UTF-8\u0026#34;) print(b_1, type(b_1)) print(b_2, type(b_2)) \u0026#39;\u0026#39;\u0026#39; 输出结果： b\u0026#39;abc\u0026#39; \u0026lt;class \u0026#39;bytes\u0026#39;\u0026gt; b\u0026#39;\\xe5\\xad\\x97\\xe7\\xac\\xa6\\xe4\\xb8\\xb2\u0026#39; \u0026lt;class \u0026#39;bytes\u0026#39;\u0026gt; \u0026#39;\u0026#39;\u0026#39; # bytes转换字符串  bytes转换字符串\nb_1 = b\u0026#34;abc\u0026#34; b_2 = b\u0026#39;\\xe5\\xad\\x97\\xe7\\xac\\xa6\\xe4\\xb8\\xb2\u0026#39; s_1 = b_1.decode(\u0026#34;UTF-8\u0026#34;)\t# 用什么编码类编码的，也要用什么编码类型解码。 s_2 = b_2.decode(\u0026#34;UTF-8\u0026#34;) print(s_1, type(s_1)) print(s_2, type(s_2)) \u0026#39;\u0026#39;\u0026#39; 输出结果： abc \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; 字符串 \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026#39;\u0026#39;\u0026#39;  列表\r#\r\r 列表（list）是Python中最基本的数据结构，是一个容器型的数据类型，可以盛放任何数据类型。\n 列表中的每个元素都分配一个位置，叫做索引，第一个位置的索引是0，第二个位置的索引是1，依此类推\n创建一个列表，在内存中开辟一个空间，这个列表中的每一条数据存储，实际上是一个定长的（4个字节）内存地址，内存地址上存储的才是真实数据\n  列表的创建\r#\r\r 方法一：直接加中括号\nl = [1, \u0026#34;Python\u0026#34;] 方法二：使用list()方法\nl = list(\u0026#34;Python\u0026#34;) print(l) # 输出结果： [\u0026#39;P\u0026#39;, \u0026#39;y\u0026#39;, \u0026#39;t\u0026#39;, \u0026#39;h\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;n\u0026#39;] # 注意：list()内必须是一个可迭代的对象  列表的操作\r#\r\r 增\r#\r\r Python向列表中增加数据有三种方式\n append（追加，只能追加到最后）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.append(\u0026#34;学习\u0026#34;) print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;查\u0026#39;, \u0026#39;学习\u0026#39;] # 不能通过 print(l.append) 这种方式进行打印 应用场景举例：\nuser_list = [] while 1: add_user = input(\u0026#34;请输入需要增加的用户名（按Q或q退出）：\u0026#34;).strip() if add_user.upper() == \u0026#34;Q\u0026#34;: print(\u0026#34;程序退出！\u0026#34;) break else: user_list.append(add_user) print(\u0026#34;用户已添加！\u0026#34;) print(user_list)  insert（可以指定位置插入，但不要这么用，因为会改变列表的索引）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.insert(2, \u0026#34;的\u0026#34;) print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;的\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;查\u0026#39;]  extend（迭代追加）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.extend(\u0026#39;学习\u0026#39;) print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;查\u0026#39;, \u0026#39;学\u0026#39;, \u0026#39;习\u0026#39;] l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.extend([\u0026#34;学习\u0026#34;, ]) print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;查\u0026#39;, \u0026#39;学习\u0026#39;]  删\r#\r\r Python删除列表中的值有六种方式\n pop（按照索引位置删除，不要按照索引位置删除，会改变列表的索引）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.pop() print(l)\t# 默认删除最后一个元素 # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;改\u0026#39;] l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.pop(3) print(l) # 输出结果：[\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] print(l.pop(3))\t# pop具有返回值，返回的是删除的元素 # 输出结果：删  remove（按照指定元素删除，如果有重复元素，默认从左往右删除第一个）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.remove(\u0026#34;删\u0026#34;)\t# 没有返回值 print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;查\u0026#39;]  del（列表、字典通用，可按照索引、切片删除）\n# 按照索引删除 l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] del l[3] print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;查\u0026#39;] # 按照切片删除 l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] del l[::2] print(l) # 输出结果：[\u0026#39;列表\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;查\u0026#39;]  clear（清空列表中的所有元素）（了解即可）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l.clear() print(l) # 输出结果：[]  for循环删除\n 注意：在使用for循环按照索引删除列表元素的时候，一定要注意正向步长删除会引起元素索引的变化，导致删除结果错误，因此为保证for循环按照索引删除元素时索引变化不影响删除结果，一般采用反向步长，从后往前删，此方法称之为“倒叙删除法”。\n在循环一个列表时，最好不要改变一个列表的大小，这样有可能会影响最终的结果。\n l = [1, 2, 3, 4, 5, 6] # 删除列表中索引为奇数位置的元素 for i in range(len(l)-1,-1,-1): if i % 2 == 1: l.pop(i) print(l) # 输出结果：[1, 3, 5]  思维置换法\n 思路，从列表中取得想要的值产生新的列表，然后用新的列表替换原有列表\n l = [1, 2, 3, 4, 5, 6] # 删除列表中的1，3，4，6 list_1 = [l[1]] list_2 = [l[-2]] l = list_1 + list_2 print(l) # 输出结果：[2, 5]  改\r#\r\r Python更改列表中的值有两种方法\n 按照索引改值\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l[4] = \u0026#34;按照索引改值\u0026#34; print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;按照索引改\u0026#39;, \u0026#39;查\u0026#39;]  按照切片改值（了解）\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l[2:] = \u0026#34;按照切片改值\u0026#34; print(l) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;按\u0026#39;, \u0026#39;照\u0026#39;, \u0026#39;切\u0026#39;, \u0026#39;片\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;值\u0026#39;] l = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] l[::2] = \u0026#34;abc\u0026#34;\t# 切片加步长，就必须将迭代的元素与修改的值对应上，即改几个元素就得写几个元素。 print(l) # 输出结果：[\u0026#39;a\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;删\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;查\u0026#39;]  查\r#\r\r Python中有三种查询列表的方式\n 按照索引查询\n 按照切片查询\n for循环查询\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;增\u0026#34;, \u0026#34;删\u0026#34;, \u0026#34;改\u0026#34;, \u0026#34;查\u0026#34;] for i in l: print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： Python 列表 增 删 改 查 \u0026#39;\u0026#39;\u0026#39;  列表的嵌套\r#\r\r l = [1, [\u0026#34;Python\u0026#34;, [\u0026#34;列\u0026#34;, \u0026#34;表\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;嵌套\u0026#34;]]  将列表中的 \u0026ldquo;Python\u0026rdquo; 变成大写\nl = [1, [\u0026#34;Python\u0026#34;, [\u0026#34;列\u0026#34;, \u0026#34;表\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;嵌套\u0026#34;]] l[1][0] = l[1][0].upper() print(l) # 输出结果：[1, [\u0026#39;PYTHON\u0026#39;, [\u0026#39;列\u0026#39;, \u0026#39;表\u0026#39;], \u0026#39;的\u0026#39;, \u0026#39;嵌套\u0026#39;]]  给列表 l 中的列表 [\u0026ldquo;列\u0026rdquo;, \u0026ldquo;表\u0026rdquo;] 增加一个元素\u0026quot;\u0026amp;\u0026quot;\nl = [1, [\u0026#34;Python\u0026#34;, [\u0026#34;列\u0026#34;, \u0026#34;表\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;嵌套\u0026#34;]] l[1][1].insert(1,\u0026#34;\u0026amp;\u0026#34;) print(l) # 输出结果：[1, [\u0026#39;Python\u0026#39;, [\u0026#39;列\u0026#39;, \u0026#39;\u0026amp;\u0026#39;, \u0026#39;表\u0026#39;], \u0026#39;的\u0026#39;, \u0026#39;嵌套\u0026#39;]]  给列表 l 中的 [\u0026ldquo;列\u0026rdquo;, \u0026ldquo;表\u0026rdquo;] 通过字符串拼接的方式变成 [\u0026ldquo;列\u0026rdquo;, \u0026ldquo;表的\u0026rdquo;]，并删除列表 l 中的 \u0026ldquo;的\u0026rdquo; 元素\nl = [1, [\u0026#34;Python\u0026#34;, [\u0026#34;列\u0026#34;, \u0026#34;表\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;嵌套\u0026#34;]] l[1][1][1] = l[1][1][1] + \u0026#34;的\u0026#34;\t# 等号左边的 l[1][1][1] 表示要改元素\u0026#34;表\u0026#34; l[1].pop(2) print(l) # 输出结果：[1, [\u0026#39;Python\u0026#39;, [\u0026#39;列\u0026#39;, \u0026#39;表的\u0026#39;], \u0026#39;嵌套\u0026#39;]] # 代码可以精简成： l = [1, [\u0026#34;Python\u0026#34;, [\u0026#34;列\u0026#34;, \u0026#34;表\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;嵌套\u0026#34;]] l[1][1][1] += \u0026#34;的\u0026#34;\t# count = count + 1 可以简写成 count += 1 l[1].pop(2) print(l) # 输出结果：[1, [\u0026#39;Python\u0026#39;, [\u0026#39;列\u0026#39;, \u0026#39;表的\u0026#39;], \u0026#39;嵌套\u0026#39;]]  给列表 l 中的列表 [\u0026ldquo;列\u0026rdquo;, \u0026ldquo;表\u0026rdquo;] 变成字符串 \u0026ldquo;列表\u0026rdquo;\nl = [1, [\u0026#34;Python\u0026#34;, [\u0026#34;列\u0026#34;, \u0026#34;表\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;嵌套\u0026#34;]] l[1][1] = \u0026#34;\u0026#34;.join(l[1][1]) print(l) # 输出结果：[1, [\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, \u0026#39;的\u0026#39;, \u0026#39;嵌套\u0026#39;]]  列表的内置方法\r#\r\r count：计算列表中指定元素出现的次数\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;的\u0026#34;, \u0026#34;内置\u0026#34;, \u0026#34;方法\u0026#34;] print(l.count(\u0026#34;Python\u0026#34;)) #输出结果：1  index：找到指定元素在列表中的索引位置\nl = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, \u0026#34;的\u0026#34;, \u0026#34;内置\u0026#34;, \u0026#34;方法\u0026#34;] print(l.index(\u0026#34;的\u0026#34;)) #输出结果：2  sort：给列表中的数字或字符串进行排序，且列表中不能既有数字也有字符串，字符串按照字幕的顺序排序，一般用于数字排序。默认从小到大排序。\n# 从小到大排列 l = [3,2,5,4,6,8,7,9] l.sort() print(l) #输出结果：[2, 3, 4, 5, 6, 7, 8, 9] # 从大到小排列 l = [3,2,5,4,6,8,7,9] l.sort(reverse=True) print(l) #输出结果：[9, 8, 7, 6, 5, 4, 3, 2]  reverse：反转排序\nl = [3,2,5,4,6,8,7,9] l.reverse() print(l) #输出结果：[9, 7, 8, 6, 4, 5, 2, 3]  列表的运算\r#\r\r  Python 3.4之后的列表支持与列表相加和与数字相乘\n  列表相加\nlist_1 = [\u0026#34;Python\u0026#34;, \u0026#34;列表\u0026#34;, 3, 2, \u0026#34;的\u0026#34;, \u0026#34;内置\u0026#34;, \u0026#34;方法\u0026#34;] list_2 = [3,2,5,4] print(list_1 + list_2) # 输出结果：[\u0026#39;Python\u0026#39;, \u0026#39;列表\u0026#39;, 3, 2, \u0026#39;的\u0026#39;, \u0026#39;内置\u0026#39;, \u0026#39;方法\u0026#39;, 3, 2, 5, 4]  列表与数字相乘\nl = [1, 2] print(l * 3) #输出结果：[1, 2, 1, 2, 1, 2]  列表推导式\r#\r\r  可以用一行代码快速创建一个比较复杂且有规律的列表\n  循环模式（[变量1 for 变量2 in 可迭代对象]）\n# 创建一个包含数字1到10的列表 l = [] for i in range(1,11): l.append(i) print(l)\t# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 使用列表推导式 l = [i for i in range(1,11)] print(l)\t# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 构建一个Python-1到Python-100的列表 l = [f\u0026#39;Python-{i}\u0026#39; for i in range(1,101)] print(l)  筛选模式（[变量1 for 变量2 in 可迭代对象 if 判断条件]）\n# 创建一个包含从1到10中所有偶数的列表 l = [i for i in range(1,11) if i % 2 == 0] print(l)\t# [2, 4, 6, 8, 10] # 将含有两个o的所有单词留下，组成一个新的列表（没有使用列表推导式） word_list = [ [\u0026#39;food\u0026#39;,\u0026#39;eat\u0026#39;,\u0026#39;foot\u0026#39;,\u0026#39;hand\u0026#39;], [\u0026#39;dog\u0026#39;,\u0026#39;bear\u0026#39;,\u0026#39;root\u0026#39;,\u0026#39;colour\u0026#39;] ] l = [] for i in word_list: for word in i: if word.count(\u0026#39;o\u0026#39;) == 2: l.append(word) print(l) # 将含有两个o的所有单词留下，组成一个新的列表（使用列表推导式） word_list = [ [\u0026#39;food\u0026#39;,\u0026#39;eat\u0026#39;,\u0026#39;foot\u0026#39;,\u0026#39;hand\u0026#39;], [\u0026#39;dog\u0026#39;,\u0026#39;bear\u0026#39;,\u0026#39;root\u0026#39;,\u0026#39;colour\u0026#39;] ] l = [word for i in word_list for word in i if word.count(\u0026#39;o\u0026#39;) == 2] print(l)  列表推导式的优缺点\n优点：\n 一行构建，简单\n# 用一行代码构建一个列表：[2, 3, 4, 5, 6, 7, 8, 9, 10, \u0026#39;J\u0026#39;, \u0026#39;Q\u0026#39;, \u0026#39;K\u0026#39;, \u0026#39;A\u0026#39;] l = [i for i in range(2,11)] + list(\u0026#39;JQKA\u0026#39;)   缺点\n 列表推导式只能构建比较复杂且有规律的列表，注意，是有规律的列表；\n超过三层循环才能构建成功的列表，就不建议使用列表推导式了；\n无法开启debug模式，也就是说进行Trouble Shooting时会相对来说困难些\n  元组\r#\r\r 元组（tuple）也称之为只读列表，没有增、删、改，只能查。\n 元组内的列表元素，虽不能删，但可以改\n  元组内列表的更改\r#\r\r tu = (1, \u0026#34;Python\u0026#34;, [\u0026#34;元\u0026#34;, \u0026#34;组\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;取值\u0026#34;) tu[2].insert(1,\u0026#34;$\u0026#34;) print(tu) # 输出结果：(1, \u0026#39;Python\u0026#39;, [\u0026#39;元\u0026#39;, \u0026#39;$\u0026#39;, \u0026#39;组\u0026#39;], \u0026#39;的\u0026#39;, \u0026#39;取值\u0026#39;)  元组取值的方式\r#\r\r 索引取值\ntu = (1, \u0026#34;Python\u0026#34;, [\u0026#34;元\u0026#34;, \u0026#34;组\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;取值\u0026#34;) tu[3] print(tu[3]) # 输出结果：的  切片取值\ntu = (1, \u0026#34;Python\u0026#34;, [\u0026#34;元\u0026#34;, \u0026#34;组\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;取值\u0026#34;) tu[:2] print(tu[:2]) # 输出结果：(1, \u0026#39;Python\u0026#39;)  迭代取值\ntu = (1, \u0026#34;Python\u0026#34;, [\u0026#34;元\u0026#34;, \u0026#34;组\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;取值\u0026#34;) for i in tu: print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： 1 Python [\u0026#39;元\u0026#39;, \u0026#39;组\u0026#39;] 的 取值 \u0026#39;\u0026#39;\u0026#39;  查询元组元素的个数\ntu = (1, \u0026#34;Python\u0026#34;, [\u0026#34;元\u0026#34;, \u0026#34;组\u0026#34;], \u0026#34;的\u0026#34;, \u0026#34;取值\u0026#34;) print(len(tu)) # 输出结果：5  计算元组中指定元素出现的个数\ntu = (1,2,3,5,2,3,3,4,2,5,) print(tu.count(2)) #输出结果：3  应用场景\r#\r\r 不想让别人改动的数据可以存储在元组中\n元组的拆包，给变量分别赋值（列表也可以拆包，但一般都是用元组拆包）\na,b = (1,2)\t# 赋值的变量和元组的元素个数和位置必须一一对应，不能多也不能少 print(a) # 输出结果：1 print(b) # 输出结果：2  特殊情况\r#\r\r 如果元组中只有一个元素，且元素后没有逗号，那么它不是元组，它与元组中元素的数据类型一致\ntu = (\u0026#34;Python\u0026#34;) print(tu,type(tu)) #输出结果：Python \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; tu = (1) print(tu,type(tu)) #输出结果：1 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt; tu = ([1,2,3]) print(tu,type(tu)) #输出结果：[1, 2, 3] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt;  集合\r#\r\r 集合（set）是一个无序的、不重复元素序列，因此集合没有索引且没有重复的元素。\n 集合是一个容器型的数据类型，他要求里面的元素是不可变的数据类型，但集合本身却是一个可变的数据类型。\n  集合的作用\r#\r\r 遇到如下需求，应考虑使用集合\n 列表的去重。 关系测试。交集、并集、差集等。   集合的创建方式\r#\r\r 可以使用大括号 { } 或者set()函数创建集合，注意：创建一个空集合必须用set()而不是{ }，因为{ }是用来创建一个空字典\n 方式一：使用set()\nset_creat = set({1, 2, \u0026#39;集合\u0026#39;, False}) print(set_creat) # 输出结果：{False, 1, 2, \u0026#39;集合\u0026#39;}  方式二:直接创建\nset_creat = {1, 2, \u0026#39;集合\u0026#39;, False} print(set_creat) # 输出结果：{\u0026#39;集合\u0026#39;, 1, 2, False}  集合的操作\r#\r\r 增\r#\r\r 方式一：内置函数add\nset_creat = {1, \u0026#39;集合\u0026#39;, \u0026#39;de\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;} set_creat.add(\u0026#39;没有改\u0026#39;) print(set_creat) # 输出结果：{1, \u0026#39;删\u0026#39;, \u0026#39;没有改\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;集合\u0026#39;, \u0026#39;de\u0026#39;}  方式二：内置函数update迭代增加\nset_creat = {1, \u0026#39;集合\u0026#39;, \u0026#39;de\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;} set_creat.update(\u0026#39;没有改\u0026#39;) print(set_creat) # 输出结果：{\u0026#39;删\u0026#39;, 1, \u0026#39;de\u0026#39;, \u0026#39;集合\u0026#39;, \u0026#39;改\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;有\u0026#39;, \u0026#39;没\u0026#39;}  删\r#\r\r 方式一：内置函数remove按照元素删除\nset_creat = {1, \u0026#39;集合\u0026#39;, \u0026#39;de\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;} set_creat.remove(\u0026#39;de\u0026#39;) print(set_creat) # 输出结果：{1, \u0026#39;删\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;集合\u0026#39;} 方式二：内置函数pop随机删除\nset_creat = {1, \u0026#39;集合\u0026#39;, \u0026#39;de\u0026#39;, \u0026#39;增\u0026#39;, \u0026#39;删\u0026#39;} set_creat.pop() print(set_creat) # 输出结果：{\u0026#39;增\u0026#39;, \u0026#39;集合\u0026#39;, \u0026#39;de\u0026#39;, \u0026#39;删\u0026#39;}  虽然集合没有“改”，但可以变相改值，即先删后增\n  集合的关系操作\r#\r\r 交集（使用\u0026amp;或intersection）\nset_1 = {1, 3, 5, 2, 4, 6}\rset_2 = {2, 4, 6, 3, 5, 7}\rprint(set_1 \u0026amp; set_2)\r# 输出结果：{2, 3, 4, 5, 6}\r 并集（使用|或union）\nset_1 = {1, 3, 5, 2, 4, 6} set_2 = {2, 4, 6, 3, 5, 7} print(set_1 | set_2) # 输出结果：{1, 2, 3, 4, 5, 6, 7}  差集（使用-或difference）\nset_1 = {1, 3, 5, 2, 4, 6} set_2 = {2, 4, 6, 3, 5, 7} print(set_1 - set_2) # 输出结果：{1}  反交集（使用^或symmetric_difference）\nset_1 = {1, 3, 5, 2, 4, 6} set_2 = {2, 4, 6, 3, 5, 7} print(set_1 ^ set_2) # 输出结果：{1, 7}  子集（即：包含于，使用\u0026lt;）\nset_1 = {1, 2, 3} set_2 = {1, 2, 3, 4, 5, 6} print(set_1 \u0026lt; set_2) # 输出结果：True  超集（即：包含，使用\u0026gt;）\nset_1 = {1, 2, 3} set_2 = {1, 2, 3, 4, 5, 6} print(set_1 \u0026gt; set_2) # 输出结果：False  集合用于列表去重\r#\r\r 使用集合对列表进行去重虽然简单，但由于集合是无序的，因此无法保证列表原来的顺序。\nlist_1 = [1, 1, 1, 2, 3, 3, 4, 4, 5, 6] set_1 = set(list_1) list_1 = list(set_1) print(list_1) # 输出结果：[1, 2, 3, 4, 5, 6]  集合的推导式\r#\r\r 同列表和字典一样，集合也有推导式\ns = {i for i in range(1,11)} print(s)\t# {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}  字典\r#\r\r 字典（dict），虽然列表可以存储大量数据，但由于列表的数据关联性不强，且列表的查询速度比较慢，因此产生了字典；\n 字典是另一种可变容器模型，且可存储任意类型对象\n 字典的每个键（key）和值（value）对用冒号:分割，每个对之间用逗号,分割，整个字典包括在花括号{ }中 ,格式如下所示：\nd = {key1 : value1, key2 : value2 } # 字典实例 d = {\u0026#34;张三\u0026#34;:{\u0026#34;年龄\u0026#34;:18, \u0026#34;性别\u0026#34;:\u0026#34;男\u0026#34;},\u0026#34;李四\u0026#34;:{\u0026#34;年龄\u0026#34;:20, \u0026#34;性别\u0026#34;:\u0026#34;女\u0026#34;}} 其中键必须是唯一的，但值则不必。值可以取任何数据类型，但键必须是不可变的数据类型，如字符串、数字、布尔值或元组。\n 字典特点\r#\r\r 字典在Python 3.5版本及之前版本是无序的。而在Python 3.6版本以后，字典会按照初次建立的顺序排列，但学术上仍然认为Python字典不是有序的。在Python 3.7及以后版本中，字典都是有序的了。\n**字典的优点：**字典查询速度非常快，比列表的查询速度要快的多。可以存储关联性数据。\n**字典的缺点：**空间换时间。字典查询速度快的代价就是浪费空间。\n 字典的创建方式\r#\r\r 创建一个空字典\nd = dict()  方式一：元组的拆包\nd = dict(((\u0026#34;one\u0026#34;,1), (\u0026#34;two\u0026#34;,2), (\u0026#34;three\u0026#34;,3))) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式二：键值对形式\nd = dict(one=1, two=2, three=3) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式三：官方推荐\nd = dict({\u0026#34;one\u0026#34;:1, \u0026#34;two\u0026#34;:2, \u0026#34;three\u0026#34;:3}) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式四：直接花括号\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式五：dict.formkeys()字典的键是来自一个可迭代的对象，把可迭代的对象每一个值当作一个键，所有的键共用一个值，正因为所有键都公用一个值，因此，当键值为可变数据类型时，一个键的值更改，其他键的值也会随着更改）\nd = dict.fromkeys([1,2,3],\u0026#34;字典\u0026#34;) print(d) # 输出结果：{1: \u0026#39;字典\u0026#39;, 2: \u0026#39;字典\u0026#39;, 3: \u0026#39;字典\u0026#39;} d = dict.fromkeys([1,2,3],[6]) print(d) d[1].append(666) print(d) \u0026#39;\u0026#39;\u0026#39; 输出结果： {1: [6], 2: [6], 3: [6]} {1: [6, 666], 2: [6, 666], 3: [6, 666]} \u0026#39;\u0026#39;\u0026#39;  字典的操作\r#\r\r 增\r#\r\r方式一：直接增加\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d[\u0026#39;four\u0026#39;] = 4 print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4} # 如果增加的键值对的键与字典中的键重复，则新键值对会覆盖掉原有键值对，也叫“有则改之，无则增加” d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d[\u0026#39;one\u0026#39;] = 4 print(d) # 输出结果：{\u0026#39;one\u0026#39;: 4, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式二：通过内置函数setdefault增加\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.setdefault(\u0026#39;four\u0026#39;,4) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4} # 如果增加的键值对的键与字典中的键重复，则新键值对不会覆盖掉原有键值对，也叫“有则不改，无则增加”  方式三：通过update方法增加\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.update(four=4,five=5) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4, \u0026#39;five\u0026#39;: 5}  方式四：通过update方法和元组的拆包增加\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.update([(\u0026#39;four\u0026#39;,4),(\u0026#39;five\u0026#39;,5)]) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4, \u0026#39;five\u0026#39;: 5}  方式五：通过update将一个列表更新到另一个列表\ndict_1 = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} dict_2 = {\u0026#39;one\u0026#39;: 0, \u0026#39;four\u0026#39;: 4} dict_1.update(dict_2) print(dict_1) # 输出结果：{\u0026#39;one\u0026#39;: 0, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4} # update()方法特点：有则改之，无则增加  删\r#\r\r方式一：通过内置函数pop进行删除（推荐使用此方式）\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.pop(\u0026#39;three\u0026#39;) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2} # 所有删除方法，只有pop有返回值，返回的值是删除的值 # 当不确定删除的键值在不在字典中，为了防止报错，可以在删除的简直后面增加一个空键值，如果没有要删除的键值，不会报错 d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.pop(\u0026#39;four\u0026#39;,\u0026#34;\u0026#34;) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式二：通过del方式删除\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} del d[\u0026#39;two\u0026#39;] print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;three\u0026#39;: 3} # 如果删除的键字典中没有会报错，因此不推荐此方法  方式三：通过内置函数clear清空字典，并非删除字典\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.clear() print(d) # 输出结果：{}  改\r#\r\r方式一：直接改\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d[\u0026#39;one\u0026#39;] = 4 print(d) # 输出结果：{\u0026#39;one\u0026#39;: 4, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  方式二：通过update方法改\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d.update(one=4) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 4, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3}  查\r#\r\r方式一：直接查，不推荐\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} print(d[\u0026#39;three\u0026#39;]) # 输出结果：3 # 如果查询的键字典中没有会报错，因此不推荐此方法  方式二：通过内置函数get()查询\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d1 = d.get(\u0026#39;two\u0026#39;) print(d1) # 输出结果：2 # # 如果查询的键字典中没有也不会报错，默认返回值是None，返回值可以设置，因此推荐此方法 d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} d1 = d.get(\u0026#39;four\u0026#39;, \u0026#39;没有此键\u0026#39;) print(d1) # 输出结果：没有此键  通过内置方法keys()查询字典内所有的键\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} print(d.keys()) # 输出结果：dict_keys([\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;]) # 此方式可将键名称转换成列表 print(list(d.keys())) # 输出结果：[\u0026#39;one\u0026#39;, \u0026#39;two\u0026#39;, \u0026#39;three\u0026#39;] # 也可以通过for循环列出所有的键 d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} for key in d: print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： one two three \u0026#39;\u0026#39;\u0026#39;  通过内置方法values()查询字典内所有的值\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} print(d.values()) # 输出结果：dict_values([1, 2, 3]) # 同理，也可以转换成列表及使用for循环列出所有的值  通过内置方法item()查询所有的键值对\nd = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} print(d.items()) # 输出结果：dict_items([(\u0026#39;one\u0026#39;, 1), (\u0026#39;two\u0026#39;, 2), (\u0026#39;three\u0026#39;, 3)]) # 将键值对转换成列表 d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} print(list(d.items())) # 输出结果：[(\u0026#39;one\u0026#39;, 1), (\u0026#39;two\u0026#39;, 2), (\u0026#39;three\u0026#39;, 3)] # 使用for循环列出所有的键值对（使用到了元组的拆包） d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3} for key,value in d.items(): print(key,value) \u0026#39;\u0026#39;\u0026#39; 输出结果： one 1 two 2 three 3 \u0026#39;\u0026#39;\u0026#39;  字典的嵌套\r#\r\r d = { \u0026#39;姓名\u0026#39;: \u0026#39;张三\u0026#39;, \u0026#39;性别\u0026#39;: \u0026#39;男\u0026#39;, \u0026#39;配偶\u0026#39;:{\u0026#39;姓名\u0026#39;: \u0026#39;李四\u0026#39;, \u0026#39;性别\u0026#39;: \u0026#39;女\u0026#39;}, \u0026#39;联系方式\u0026#39;:[{\u0026#39;手机\u0026#39;:12345678, \u0026#39;电话\u0026#39;:123456},] }  获取张三的名字\nprint(d.get(\u0026#39;姓名\u0026#39;))  获取联系方式中的字典\nprint(d.get(\u0026#39;联系方式\u0026#39;)[0])  获取手机号\nprint(d.get(\u0026#39;联系方式\u0026#39;)[0].get(\u0026#39;手机\u0026#39;))  获取配偶的姓名\nprint(d.get(\u0026#39;配偶\u0026#39;).get(\u0026#39;姓名\u0026#39;))  字典的循环\r#\r\r 使用for循环一个字典时，如果改变字典的大小（增加或删除元素），就会报错。\n# 将下面字典中所有含t的键值对删掉如何处理呢？ # 首先我们会想到，循环字典，判断字典的键是否含有\u0026#34;t\u0026#34;，可循环字典时改变字典大小就会报错。 # 那么，我们换种思路，不循环字典时删除键值就好了，只要找到满足有两种方法。 # 方法一：先for循环字典，将满足条件的键放入到一个列表中，然后循环列表，删除满足条件的键值 d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4} l = [] for key in d: if \u0026#39;t\u0026#39; in key: l.append(key) for i in l: d.pop(i) print(d) # 输出结果：{\u0026#39;one\u0026#39;: 1, \u0026#39;four\u0026#39;: 4} # 方法二：通过内置方法keys()生成字典中所有键的列表，然后通过循环键的列表删除满足条件的键值 d = {\u0026#39;one\u0026#39;: 1, \u0026#39;two\u0026#39;: 2, \u0026#39;three\u0026#39;: 3, \u0026#39;four\u0026#39;: 4} l = list(d.keys()) # 由于d.keys()生成的列表仍与字典d有关系，直接循环删键值对仍然会报错，因此创建一个新的列表 for key in l: if \u0026#39;t\u0026#39; in key: d.pop(key) print(d)  字典推导式\r#\r\r # 将两个列表通过一行代码生成一个字典 keys = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] values = [1, 2, 3] dic = {keys[i]:values[i] for i in range(len(keys))} print(dic) # {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2, \u0026#39;c\u0026#39;: 3}  range\r#\r\r range类似于列表，是自定制数字范围的列表，里面的元素只能是数字。一般在for循环中使用。\n 函数语法\r#\r\r\u0026#39;\u0026#39;\u0026#39; range(start, stop, step) start: 计数从 start 开始。默认是从 0 开始。 stop: 计数到 stop 结束，但不包括 stop。 step：步长，默认为1。 \u0026#39;\u0026#39;\u0026#39; range(10)\t# 等价于range(0,10) range(5,10) range(10,100,10)  range取值\r#\r\r  特点：顾头不顾尾\n  迭代取值\nfor i in range(5): print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： 0 1 2 3 4 \u0026#39;\u0026#39;\u0026#39; for i in range(0,6,2): print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： 0 2 4 \u0026#39;\u0026#39;\u0026#39; for i in range(5,0,-1): print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： 5 4 3 2 1 \u0026#39;\u0026#39;\u0026#39;  索引取值\n（略）\n 切片取值\n（略）\n 应用\r#\r\r l = [1, \u0026#34;range\u0026#34;, \u0026#34;的\u0026#34;, \u0026#34;for\u0026#34;, \u0026#34;循环\u0026#34;] # 利用for循环，将列表 l 的索引依次打印出来 for i in range(len(l)): print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： 0 1 2 3 4 \u0026#39;\u0026#39;\u0026#39; # 实现多个整数相加，例如用书输入：3+6+4+8，求出结果 count = input(\u0026#34;请输入：\u0026#34;) count_list = count.split(\u0026#34;+\u0026#34;) # [\u0026#39;3\u0026#39;, \u0026#39;6\u0026#39;, \u0026#39;4\u0026#39;, \u0026#39;8\u0026#39;] result = 0 for i in range(len(count_list)): result += int(count_list[i]) print(result) # 输出结果：21  "},{"id":1,"href":"/docs/Golang/Go%E8%AF%AD%E8%A8%80%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/","title":"Go语言编程基础","section":"Golang","content":"Go语言编程基础\r#\r\r 数据类型\r#\r\r 基础数据类型\r#\r\rGo语言数据类型可用于参数和变量的声明，主要有以下几种数据类型：\n 布尔类型\r#\r\r布尔型的值只可以是常量True或者False，例如：var b bool = true\n 数字类型\r#\r\rGo语言支持整型（int）和浮点型（float32、float64）数字，并且原生支持复数，其中位的运算采用补码。\n整形数据\r   关键字 是否有符号 长度（范围）     uint8 无符号 8为整型（0~255）   uint16 无符号 16位整型（0~65535）   uint32 无符号 32位整型（0~4294967295）   uint64 无符号 64位整型（0~18446744073709551615）   int8 有符号 8位整型（-128~127）   int16 有符号 16位整型（-32768~32767）   int32 有符号 32位整型（-2147483648~2147483647）   int64 有符号 64位整型（-9223372036854775808~-9223372036854775807）    其他整型\r   关键字 说明     byte 类似uint8，8位   rune 类似int32，32位   uint 32或64位无符号类型，与系统有关   int 32或64位有符号类型，与系统有关   uintptr 无符号整型，用于存放一个指针    浮点型\r   关键字 说明     float32 IEEE-754 32位浮点型   float64 IEEE-754 64位浮点型     浮点数能够标识的范围可以从很小到很大，这个极限值范围可以在math包中获取，math.MaxFloat32表示float32的最大值，math.MaxFloat64表示float64的最大值。通常情况下应该优先选择float64，因为float32的精度较低，float32大约可以提供小数点后6位的精度，而float64可以提供小数点后15位的精度，在累计计算时误差扩散很快，而且因为浮点数和整数的底层解释方式完全不同，float32能精确表达的最小整数并不大。\n  字符串类型\r#\r\r字符串是一个不可改变的字节序列，字符串可以包含任意的数据，但是通常是用来包含可读的文本。\nGo语言中的字符串是由单个只读的Unicode字符连接起来的，使用UTF-8编码标识Unicode字符，每一个字符对应一个rune类型，一旦字符串变量被赋值后，内部的字符就不能修改。\n在Go语言中，对字符串使用range循环，会在每次迭代时解码一个UTF-8编码的字符，每次循环时，循环的索引时当前文字的起始位置，它的值（rune）是Unicode代码点。\n 使用range迭代字符串时，需要注意，range迭代的是Unicode而不是字节。返回的两个值，第一个是被迭代字符串的UTF-8编码的第一个字节在字符串中的索引，第二个是对应的字符且类型为rune。\n  复合（派生）类型\r#\r\rGo语言中有多种复核数据类型：数组（array）、切片（slice）、字典（map）、结构体（struct）、指针（pointer）、函数（function）、接口（interface）和通道（channel）。\n数据和结构体都是聚合类型，长度固定。而切片和字典都是动态数据结构，长度可变。\n 错误类型\r#\r\rerror类型是Go语言预定义类型。\n 变量\r#\r\r 变量以及声明\r#\r\rGo语言中由四类标记：标识符（identifiers）、关键字（keywords）、运算符（operators）和标点符号（punctuation）、字面量（literals）。\nGo语言变量标识符由字母、数字、下划线组成，其中首字符不能为数字，同一字母的大小写在Go语言中代表不同标识。\n根据Go语言规范，标识符命名程序实体，例如变量和类型，标识符是一个或多个Unicode字母和数字的序列，标识符中的第一个字符必须是Unicode字母。\npackage main import \u0026#34;fmt\u0026#34; // 声明一个全局变量 var character string // 声明多个全局变量 var ( name string age int16 Gender bool 工资 float32 // 没错，中文可以作为变量名称（变量标识符） ) func main() { // 在函数内部，可以使用简式声明变量 \tx := \u0026#34;简式声明变量\u0026#34; // 多个变量可以同时进行声明和赋值，也称为并行或平行赋值 \ta, b, c := \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34; fmt.Printf(\u0026#34;x的值为：%s\\n\u0026#34;, x) fmt.Printf(\u0026#34;a的值为：%s\\n\u0026#34;, a) fmt.Printf(\u0026#34;b的值为：%s\\n\u0026#34;, b) fmt.Printf(\u0026#34;c的值为：%s\\n\u0026#34;, c) }  简式声明一般用在函数内部，在某些上下文中，例如：if、for、switch语句的初始化程序中也可以使用，他们可以用于本地临时变量，但要注意的是：全局变量和简式声明的变量尽量不要同名，否则很容易差生偶然的变量隐藏（Accidental）。\n在Go语言规范中，下划线 _ 也被认为是字母。但如果使用 _ 作为变量对值进行接收时，是得不到任何值的，因为此时的 _ 是空白标识符，用于抛弃值。Go语言有个强制规定，在函数内声明的变量一定要使用，若存在已声明但未使用的变量，则代码编译失败。但在全局声明的变量不使用是没有这个限制的。\n在Go语言中，如果导入的包未使用，也不能通过编译。如果不直接使用包里的函数，而只是调用包中的 init() 函数，或者调试代码时去掉了对某些包功能的使用，可以在包名称的前面添加一个下划线 _ 标识符，表示导入包，但不使用包，从而避免编译失败。\n对于布尔值，好的命名能够很好地提升代码的可读性，例如以 is 或者 Is 开头的 isSorted 、 isFinished 、 isVisible ，使用这样的命名能够在阅读代码时，获得阅读正常语句一样的良好体验。\n在Go语言中，指针属于引用类型，其他的引用类型还包括切片、字典和通道，如果传递引用类型参数或者赋值给引用类型变量，原始数据有改动时，引用类型变量也会发生改变。\n在Go语言中，数组是值类型，因此向函数中传递数组时，函数会得到原始数组数据的一份副本。如果打算更新数组的数据，可以考虑使用数组的指针类型。\nGo语言中，被引用的变量一般存储在堆内存中，以便系统进行垃圾回收（GC），且比栈拥有更大的内存空间。但Go编译器会自动做出选择，程序员不能直接判断其在内存中的位置，究竟是在内存中的堆区还是栈区。\n  零值（nil）\r#\r\r当变量被 var 声明之后，如果没有为其明确指定初始值，Go语言会自动将其值初始化为对应的零值。\n零值表\r   类型 零值     integer（整型） 0   float（浮点型） 0.0   bool（布尔型） false   string（字符串型） 空字符串\u0026quot;\u0026quot;   map（字典类型） nil   slice（切片类型） nil   pointer（指针类型） nil   function（函数类型） nil   interface（接口类型） nil   channel（通道类型） nil   error（错误类型） nil     如果代码中没有指定变量的类型却赋值nil，编译器将无法编译代码，因为它无法确定具体的类型。\n在nil的切片中可以添加元素，但字典中不可以。\n  常量\r#\r\r 定义常量\r#\r\r常量使用关键字 const 定义，用于存储不会改变的数据。常量不能被重新赋予任何值。\n存储在常量中的数据类型只可以是布尔型、数字型（rune、整型、浮点型和复数）和字符串型。\n常量的定义格式为：const identifier[type] = value\nconst Pi = 3.1415926  在Go语言中，可以省略类型 type ，因为编译器可以根据变量（常量）的值来推断其类型。\n常量定义可以限制常量类型，但不是必须的。如果定义常量时没有指定类型，那么它与字面量一样，是无类型（untyped）常量。一个没有指定类型的常量在使用时，会根据其使用环境而推断出它所需要具备的类型。换句话说，未定义类型的常量会在必要时根据上下文来获得相关类型。\n常量的值必须是在编译时就能确定的，可以在其赋值表达式中涉及计算过程，但是所有用于计算的值必须在编译期间就能获得。\n在Go语言中已经预定义了这些常量字面量： true、false 和 iota 。布尔常量只包含两个值： true 和 false\n  iota\r#\r\riota 比较特殊，可以认为它是一个可被编译器修改的常量，在每一个 const 关键字出现时其值都会被重置为 0 ，然后在下一个 const 出现之前，每出现一次 iota ，其所代表的数字就会自动加 1 。\npackage main import \u0026#34;fmt\u0026#34; func main() { const ( a = iota // iota = 0 \tb = iota // iota = 1 \tc = iota // iota = 2 \t) fmt.Println(a) fmt.Println(b) fmt.Println(c) } 第一个 iota 等于 0 ，每当 iota 在新的一行被使用时，它的值都会自动加 1 。所以 a = 0 ， b = 1 ， c = 2 可以简写成：\npackage main import \u0026#34;fmt\u0026#34; func main() { const ( a = iota // iota = 0 \tb // iota = 1 \tc // iota = 2 \t) fmt.Println(a) fmt.Println(b) fmt.Println(c) } 当新的常量 b 被声明和赋值后， iota 将不再向下赋值，后面的常量如果没有赋值，则继承上一个常量值：\npackage main import \u0026#34;fmt\u0026#34; func main() { const ( a = iota // iota = 0 \tb = 10 c ) fmt.Println(a)\t// a = 0 \tfmt.Println(b)\t// b = 10 \tfmt.Println(c)\t// c = 10 } 使用位左移与iota计数配合可优雅地实现存储单位的常量枚举：\npackage main import \u0026#34;fmt\u0026#34; func main() { type ByteSize float64\t// 定义float64的类型别名ByteSize  // 定义常量 \tconst ( _ = iota\t// 通过赋值给空白标识符来忽略值 \tKB ByteSize = 1 \u0026lt;\u0026lt; (10 * iota) MB\t// ByteSize = 1 \u0026lt;\u0026lt; (10 * iota) 会自动向下赋值 \tGB TB PB EB ) // 打印常量 \tfmt.Println(KB) fmt.Println(MB) fmt.Println(GB) fmt.Println(TB) fmt.Println(PB) fmt.Println(EB) }  数值常量包括整型、浮点型以及复数常量。\n常量之所以成为常量，就是因为它是永恒不变的量，因此无法在程序运行过程中修改它的值；在定义常量时，没有强制要求常量名全部大写，但一般都会全部字母大写，以便阅读。\n  字面量（literal）\r#\r\r在Go语言中，字面量是指由字母、数字等构成的字符串或者数值，是值的一种标记法，它只能作为右值出现。\n 整数字面量（Integer literals）\r#\r\r表示整数常量的数字序列。可选前缀用来设置非十进制的基数： 0 表示八进制， 0x 表示十六进制\n10\t// 十进制 0100\t// 八进制 0xBadFace\t// 十六进制  浮点数字面量（Floating literals）\r#\r\r浮点数字字面量是浮点常量的十进制的表示。它有一个整数部分、一个小数点、一个小数部分和一个指数部分。证书和小数部分包括十进制数字，指数部分是e或E，后跟可选的带符号的十进制指数。可以省略整数部分或小数部分中的一个，可以省略小数点或指数之一。\n 虚字面量（Imaginary literals）\r#\r\r虚数字面量是复数常数的虚部的十进制表示。它由浮点字面量或十进制整数后跟小写字母i组成。\n Rune字面量（Rune literals）\r#\r\rRune是int32的别名类型，用于存储Unicode编码的单个字符，字符串需要用 []rune 表示。\n 字符串字面量（String literals）\r#\r\r字符串字面量表示通过连接字符序列获得的字符常量。有两种形式：原始字符串字面量和解释的字符串字面量。\n原始字符串字面量是反引号之间的字符序列。在反引号内，除反向引号外，任何字符都能出现。原始字符串文字的值是由反引号之间的字符组成的字符串，注意不是单引号。\n解释的字符串文字是双引号之间的字符序列。在双引号内，除了换行符和未转义的双引号外，任何字符都可以出现。引号之间的文本形成文字的rune值，反斜杠转义符被解释为符文（rune）。\n 运算符\r#\r\r 内置运算符\r#\r\rGo语言的运算符分为以下几类：\n 算数运算符 关系运算符 逻辑运算符 位运算符 赋值运算符 其他运算符   算数运算符\r#\r\r   运算符 含义 效果     + 相加 A + B   - 相减 A - B   * 相乘 A * B   / 相除 A / B（结果是整数）   % 求余 A % B   ++ 自增 A++   \u0026ndash; 自减 A\u0026ndash;     关系运算符\r#\r\r   运算符 含义 效果（A小于B）     == 检查两个值是否相等，是则返回True，否则返回False （A == B）为False   != 检查两个值是否不相等，是则返回True，否则返回False （A != B）为True   \u0026gt; 检查左边的值是否大于右边的额的值，是则返回True，否则返回False （A \u0026gt; B）为False   \u0026lt; 检查左边的值是否小于右边的额的值，是则返回True，否则返回False （A \u0026lt; B）为True   \u0026gt;= 检查左边的值是否大于或等于右边的额的值，是则返回True，否则返回False （A \u0026gt;= B）为False   \u0026lt;= 检查左边的值是否小于或等于右边的额的值，是则返回True，否则返回False （A \u0026lt;= B）为True     逻辑运算符\r#\r\r   运算符 含义     \u0026amp;\u0026amp; 逻辑与。如果两边的操作数都是True，则结果为True，否则为False   || 逻辑或。如果两边的操作数有一个是True，则结果为True，否则为False   ! 逻辑非。如果两边的操作数都是True，则结果为False，否则为True     位运算符\r#\r\r   运算符 含义     \u0026amp; 参与运算的两个数值各自对应的二进制位相与。（两位均为1才为1）   | 参与运算的两个数值各自对应的二进制位相或。（两位有一个为1就为1）   ^ 参与运算的两个数值各自对应的二进制位相异或，当两个对应的二进制位相异时，结果为1。 （两位不一样则为1）   \u0026laquo; 左移n位就是左边的值乘以2的n次方。其功能是把\u0026quot;\u0026laquo;\u0026ldquo;左边的运算数的各二进制位全部左移若干位，由\u0026rdquo;\u0026laquo;\u0026ldquo;右边的数指定移动的位数   \u0026raquo; 右移n位就是左边的值除以2的n次方。 其功能是把\u0026rdquo;\u0026raquo;\u0026ldquo;左边的运算数的各二进制位全部右移若干位，由\u0026rdquo;\u0026raquo;\u0026ldquo;右边的数指定移动的位数     赋值运算\r#\r\r   运算符 含义 效果     = 将右边的值赋值给左边    += 相加后再赋值 C += A 等于 C = C + A   -= 相减后再赋值 C -= A 等于 C = C - A   *= 相乘后再赋值 C *= A 等于 C = C * A   /= 相除后再赋值 C /= A 等于 C = C / A   %= 求余后再赋值 C %= A 等于 C = C % A   \u0026laquo;= 左移后再赋值 C \u0026lt;\u0026lt;= A  等于 C = C \u0026lt;\u0026lt; A   \u0026raquo;= 右移后再赋值 C \u0026gt;\u0026gt;= A 等于 C = C \u0026gt;\u0026gt; A   \u0026amp;= 二进制位相与后赋值 C \u0026amp;= A 等于 C = C \u0026amp; A   |= 二进制位相或后赋值 `C   ^= 二进制位相异或后赋值 C ^= A 等于 C = C ^ A     其他运算符\r#\r\r   运算符 含义 效果     \u0026amp; 返回变量的内存地址 \u0026amp;v （将返回变量v的内存地址）   * 指针变量 *v （将返回指向变量v在内存地址中的值）    package main import \u0026#34;fmt\u0026#34; func main() { //指针取值 \ta := 10 b := \u0026amp;a // 取变量a的地址，将指针保存到b中 \tfmt.Printf(\u0026#34;type of b:%T\\n\u0026#34;, b) c := *b // 指针取值（根据指针去内存取值） \tfmt.Printf(\u0026#34;type of c:%T\\n\u0026#34;, c) fmt.Printf(\u0026#34;value of c:%v\\n\u0026#34;, c) }  运算符优先级\r#\r\r一元运算符具有最高优先级。二元运算符有五个优先级。乘法运算符优先级最高，然后是加法运算符、比较运算符、逻辑与、逻辑或，优先级数字越大表示优先级越高\n   优先级 运算符     5 * / % \u0026lt;\u0026lt; \u0026gt;\u0026gt; \u0026amp; \u0026amp;^   4 + - `   3 == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;=   2 \u0026amp;\u0026amp;   1 `     可以通过使用括号来临时提升某个表达式的整体运算优先级。也推荐使用括号这种方式来表明运算优先级，这样可以减少代码中的错误。\n  特殊运算符\r#\r\r位清除\u0026amp;^\r#\r\r将指定位置上的值设置为0.将运算符左边数据相异的位保留，相同位清零。例：\nx=2 y=4 x\u0026amp;^y == x\u0026amp;(^y) 首先把x，y换算成二进制，0000 0010 \u0026amp;^ 0000100 = 0000 0010 。如果y某位上的数是0，则取x上对应位置的值；如果y某位上为1，则结果位上取0。\n  如果右侧是0，则左侧数保持不变。\n  如果右侧是1，则左侧数一定清零。\n  功能与a\u0026amp;(^b)相同。\n  如果左侧是变量，也等同于：\nvar a int a \u0026amp;^= b    ^异或（XOR）\r#\r\r在Go语言中XOR是作为二元运算符存在的。但是如果作为一元运算符出现，它的意思是按位取反。\n作为二元运算符，XOR是不进位加法计算，也就是异或计算。例如：0000 0100 + 0000 0010 = 0000 0110\n 字符串\r#\r\r 字符串介绍\r#\r\rGo语言中可以使用反引号或者双引号来定义字符串。反引号表示原生的字符串，即不进行转移。\npackage main import \u0026#34;fmt\u0026#34; // Go语言中可以使用反引号或者双引号来定义字符串。反引号表示原生的字符串，即不进行转义。  // 双引号：字符串使用双引号括起来，其中相关的转移字符将被替换 var strExp1 = \u0026#34;Hello World!\\nHello Gpher!\\n\u0026#34; // 反引号：字符串使用反引号括起来，其中相关的转移字符不会被替换 var strExp2 = `Hello World!\\nHello Gpher!\\n` func main(){ fmt.Println(strExp1)\t// Hello World!\\nHello Gpher! \tfmt.Println(strExp2)\t// Hello World!\\nHello Gpher!\\n }  Go语言中的字符串（string）类型是一种值类型，存储的字符串是不可变的，如果要修改字符串的值，需要将字符串转换为 []byte 或 []rune ，并且修改后的 string 内容是重新生成的。\n// byte和rune的区别 type byte = uint8 type rune = int32 从系统的标准定义可以看出，byte 和 rune 的长度不同，分别是1B和4B\n字符串可以通过比较运算符（ == != \u0026lt; \u0026lt;= \u0026gt; \u0026gt;=）在内存中按字节进行比较\n通过内置函数 len() 可以获取字符串的长度，需要注意的是，len() 函数获取的是每个字符的 UTF-8 编码的长度和，而不是字符数量。\n字符串中含有中文字符，如：Go语言 可以看到，英文字符与英文字符的索引值相差1，英文字符与中文字符的索引值相差1，中文字符与中文字符的索引值相差3\npackage main import \u0026#34;fmt\u0026#34; func main() { s := \u0026#34;Go语言\u0026#34; for k, v := range s { fmt.Printf(\u0026#34;k:%d,v:%c\\n\u0026#34;, k, v) } } 字符串的字符可以通过标准索引法来获取，例如：str[0] ，在中括号内写入索引值，索引从0开始计数\n  字符串拼接\r#\r\rGo语言中，可以通过多种方式实现字符串的拼接\n 使用运算符拼接\r#\r\rpackage main import \u0026#34;fmt\u0026#34; func main() { // 直接使用运算符拼接 \tstr1 := \u0026#34;Hello\u0026#34; + \u0026#34;,\u0026#34; + \u0026#34;World\u0026#34; + \u0026#34;!\u0026#34; fmt.Println(str1) }  由于字符串是不可变的，每一次运算都会产生一个新的字符串，所以会产生很多临时的字符串，这样一来会给垃圾回收带来额外的负担，所以性能比较差\n  fmt.Sprintf()\r#\r\rpackage main import \u0026#34;fmt\u0026#34; func main() { // fmt.Sprintf()方式拼接 \tstr2 := fmt.Sprintf(\u0026#34;%s,%s!\u0026#34;, \u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;) fmt.Println(str2) }  这种拼接方式是内部使用 []byte 来实现的，不像直接使用运算符会产生很多临时的字符串，但由于内部逻辑比较复杂，有很多额外的判断，还用到了接口，所以性能一般\n  string.Join()\r#\r\rpackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { //string.Join() 方式拼接 \tstr3 := strings.Join([]string{\u0026#34;Hello\u0026#34;,\u0026#34;,\u0026#34;,\u0026#34;World\u0026#34;,\u0026#34;!\u0026#34;},\u0026#34;\u0026#34;) fmt.Println(str3) }  string.Join() 会现根据字符串数组的内容，计算出一个拼接之后的长度，然后申请对应大小的内存，一个一个的将字符串填入，在已有一个数组的情况下，这种效率会很高，但是狗仔一个没有的数据，代价也不小\n  bytes.Buffer\r#\r\rpackage main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) func main() { // bytes.Buffer 方式拼接 *推荐* \tvar str4 bytes.Buffer str4.WriteString(\u0026#34;Hello\u0026#34;) str4.WriteString(\u0026#34;,\u0026#34;) str4.WriteString(\u0026#34;World\u0026#34;) str4.WriteString(\u0026#34;!\u0026#34;) fmt.Println(str4.String()) }  这种方式比较理想，可以当成可变字符使用，对内存的增长也有优化，如果能预估字符串的长度，还可以使用 buffer.Grow() 接口来设置 capacity\n  strings.Builder\r#\r\rpackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // strings.Builder 方式拼接 *推荐* \tvar str5 strings.Builder str5.WriteString(\u0026#34;Hello\u0026#34;) str5.WriteString(\u0026#34;,\u0026#34;) str5.WriteString(\u0026#34;World\u0026#34;) str5.WriteString(\u0026#34;!\u0026#34;) fmt.Println(str5.String()) }  strings.Builder 内部通过切片来保存和管理内容。切片内部则是通过一个指针指向实际保存内容的数组。strings.Builder 同样提供了 Grow() 来支持预定义容量。当可以预定义需要使用的容量时，strings.Builder就能避免因扩容而产生新的切片。strings.Builder是非线程安全的，性能和bytes.Buffer 相差无几\n  字符串处理\r#\r\r在Go语言标准库中有四个包对字符串的处理尤为重要： bytes 、 strings 、 strconv 和 unicode 包。\n strings\r#\r\rstrings 包提供了许多如字符串的查询、替换、比较、截断、拆分、和合并等功能。\n  判断以某个字符串开头/结尾：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go语言\u0026#34; // 判断字符串变量str是否以\u0026#34;G\u0026#34;开头,并返回bool值给变量p \tp := strings.HasPrefix(str, \u0026#34;G\u0026#34;) fmt.Println(p) // 打印结果为：true  // 判断字符串变量str是否以\u0026#34;语\u0026#34;结尾,并返回bool值给变量p \ts := strings.HasSuffix(str, \u0026#34;语\u0026#34;) fmt.Println(s) // 打印结果为：false }   字符串分割\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go,语言\u0026#34; // 以逗号对字符串进行分割，返回切片类型返回给变量s \ts := strings.Split(str, \u0026#34;,\u0026#34;) fmt.Println(s)\t// [Go 语言] }   返回字符串索引\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go语言\u0026#34; // 以逗号对字符串进行分割，返回整数类型返回给变量s \ts := strings.Index(str, \u0026#34;语\u0026#34;) fmt.Println(s)\t// 打印结果为：2 }   字符串替换\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go语言,Let\u0026#39;s Go\u0026#34; // 用2个\u0026#34;Python\u0026#34;替换2个\u0026#34;Go\u0026#34; \ts := strings.Replace(str, \u0026#34;Go\u0026#34;, \u0026#34;Python\u0026#34;, 2) fmt.Println(s) // 打印结果为：Python语言,Let\u0026#39;s Python }   字符串大小写转换\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go语言,Let\u0026#39;s Go\u0026#34; // 将str中的所有英文字符全部转换成大写，并赋值给变量s1 \ts1 := strings.ToUpper(str) fmt.Println(s1) // 打印结果为：GO语言,LET\u0026#39;S GO  // 将str中的所有英文字符全部转换成小写，并赋值给变量s2 \ts2 := strings.ToLower(str) fmt.Println(s2) // 打印结果为：go语言,let\u0026#39;s go }   统计某个字符在字符串中出现的次数\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go语言,Let\u0026#39;s Go\u0026#34; // 统计字符“Go”在字符串str中出现的次数，返回整型值赋值给s \ts := strings.Count(str, \u0026#34;Go\u0026#34;) fmt.Println(s)\t// 打印结果为： 2 }   判断字符串的包含关系\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) func main() { // 定义字符串并赋值给变量str \tstr := \u0026#34;Go语言,Let\u0026#39;s Go\u0026#34; // 判断字符“Go”是否在字符串str中，返回布尔值并赋值给s \ts := strings.Contains(str, \u0026#34;Go\u0026#34;) fmt.Println(s)\t// 打印结果为： true }    bytes\r#\r\rbytes 包也提供了很多类似 strings 包功能的函数，但是针对字符串有着相同结构的 []byte 类型。\n strconv\r#\r\rstrconv 包提供了布尔型、整数型、浮点型和对应字符串的相互转换，还提供了双引号转义相关的转换。\n unicode\r#\r\runicode 包提供了 IsDigit 、 IsLetter 、 IsUpper 和 IsLower 等类似的功能，用于给字符分类。\n 流程控制\r#\r\r 标签（label）\r#\r\rfor 、switch 和 select 语句都可以配合标签 label 形式的标识符使用，即某一行第一个以冒号 : 结尾的单词（gofmt会将后续代码自动移至下一行）。Label 在 break 和 continue 语句中是可选参数，而在 goto 语句中则是必传的参数。Label 只在声明它的函数中有效。只要函数中声明了 Label ，那它在该函数的整个作用域都有效。标签的名称是大小写敏感的，为了提升可持续性，一般建议使用全部大写字母。例如：\nERROR: log.Panic(\u0026#34;error encountered\u0026#34;)  在Go语言中，定义标签而不适用标签是非法的，无法通过编译。\nGo语言不推荐使用标签，因为会导致非常糟糕的程序设计，而且总有更加可读的替代方案来实现相同的功能。\n  for 语句\r#\r\rfor 语句是最简单的基于计数器的循环迭代，器基本形式为： for 初始化语句; 条件语句; 结束语句 {}\npackage main import \u0026#34;fmt\u0026#34; // for循环的基本写法 /* 初始语句：i:=0 条件表达式：i \u0026lt;=10 ，条件表达式返回true时循环体不停地进行循环，直到条件表达式返回false时才会退出循环 结束语句：i++ */ func forExp1() { for i := 0; i \u0026lt;= 10; i++ { fmt.Println(i) } } // for循环的特殊写法，省略初始语句，但必须保留初始语句后面的分号 func forExp2() { i := 0 for ; i \u0026lt;= 10; i++ { fmt.Println(i) } } // for循环的特殊写法，省略初始语句和结束语句 func forExp3() { i := 0 for i \u0026lt;= 10 { fmt.Println(i) i++ } } // 通过break跳出for循环 func forExp4() { for i := 0; i \u0026lt;= 10; i++ { if i == 5 { break } fmt.Println(i) } } // 通过continue跳过本次for循环，继续下一次for循环 func forExp5() { for i := 0; i \u0026lt;= 10; i++ { if i == 5 { continue } fmt.Println(i) } } // for无限循环 func forExp6() { i := 1 // 如果 for 循环的头部没有条件语句，那么就会认为条件永远为 ture \tfor { fmt.Printf(\u0026#34;第%v次循环\\n\u0026#34;, i) i++ } } // 定义程序入口main函数 func main() { forExp1() forExp2() forExp3() forExp4() forExp5() }  for range 语句\r#\r\rfor range 结构是Go 语言特有的一种迭代结构，它在许多情况下都非常有用，它可以迭代任何一个集合，包括数组（array）和字典（map），同时可以获得每次迭代所对应的索引和值。一般形式为： for i, v := range iterator {} ，如果只需要 range 里面的索引值，可写成：for i := range iterator {}\npackage main import \u0026#34;fmt\u0026#34; /* Go语言中可以使用for range遍历数组、切片、字符串、map 及通道（channel）。通过for range遍历的返回值有以下规律： 1.数组、切片、字符串返回索引和值。 2.map返回键和值。 3.通道（channel）只返回通道内的值。 */ func traversalArray() { city := [...]string{\u0026#34;北京\u0026#34;, \u0026#34;上海\u0026#34;, \u0026#34;广州\u0026#34;, \u0026#34;深圳\u0026#34;} for _, v := range city { fmt.Println(v) } } func traversalStr() { word := \u0026#34;字符串\u0026#34; for _, v := range word { fmt.Printf(\u0026#34;%c\\n\u0026#34;, v) } } func main() { traversalArray() traversalStr() }  需要注意的是，通过 for range 返回的索引和值，只是迭代集合中索引和值的副本，因此是只读的，对 for range 返回的索引和值所作的任何修改都不会影响到集合中原有的索引和值，如果需要修改集合中原有的索引和值，需要使用指针\n  switch 语句\r#\r\rswitch语句提供多路执行，将表达式或类型说明符与\u0026quot;switch\u0026quot;内的\u0026quot;case\u0026quot;进行比较，以确定执行的分支\npackage main import \u0026#34;fmt\u0026#34; // 使用switch语句可以方便地对大量的值进行条件判断。 func switchExp() { // switch语句基本写法 \tfinger := 1 switch finger { case 1: fmt.Println(\u0026#34;大拇指\u0026#34;) case 2: fmt.Println(\u0026#34;食指\u0026#34;) case 3: fmt.Println(\u0026#34;中指\u0026#34;) case 4: fmt.Println(\u0026#34;无名指\u0026#34;) case 5: fmt.Println(\u0026#34;小拇指\u0026#34;) // 当以上条件都不符合时，进入default，Go语言规定每个switch只能有一个default分支。 \tdefault: fmt.Println(\u0026#34;无效的输入！\u0026#34;) } // switch语句中，一个case分支可以有多个值，多个值中间使用英文逗号分隔。 \tn := 1 switch n { case 1, 3, 5, 7, 9: fmt.Println(\u0026#34;奇数\u0026#34;) case 2, 4, 6, 8, 10: fmt.Println(\u0026#34;偶数\u0026#34;) default: fmt.Println(\u0026#34;无效的输入！\u0026#34;) } // switch语句中，case分支还可以使用表达式，这时候switch语句后面不需要再跟变量 \tscore := 1 switch { case score \u0026gt;= 90: fmt.Println(\u0026#34;A\u0026#34;) case score \u0026gt;= 80: fmt.Println(\u0026#34;B\u0026#34;) case score \u0026gt;= 70: fmt.Println(\u0026#34;C\u0026#34;) case score \u0026gt;= 60: fmt.Println(\u0026#34;D\u0026#34;) case score \u0026lt; 60: fmt.Println(\u0026#34;不及格！\u0026#34;) default: fmt.Println(\u0026#34;无效的输入！\u0026#34;) } // 为了兼容C语言中的case设计的，Go语言的switch语句中，case分支的fallthrough语法可以执行满足条件的case的下一个case。 \ts := \u0026#34;a\u0026#34; switch { case s == \u0026#34;a\u0026#34;: fmt.Println(\u0026#34;a\u0026#34;) fallthrough case s == \u0026#34;b\u0026#34;: fmt.Println(\u0026#34;b\u0026#34;) fallthrough case s == \u0026#34;c\u0026#34;: fmt.Println(\u0026#34;c\u0026#34;) default: fmt.Println(\u0026#34;无效的输入！\u0026#34;) } } func main() { switchExp() }  select 语句\r#\r\rselect 是Go语言中的一个控制结构语句，类似与 switch 语句，主要用于处理异步通道操作，所有情况都会涉及通信操作。因此select会监听分支语句中通道的读写操作，当分支中的通道读写操作为非阻塞状态（即能读写）时，将会触发相应的动作。select 语句会选择一组可以发送或接收的操作中的一个分支继续执行。select 没有条件表达式，一直在等待 case 进入可运行的状态\nfunc main() { var c1, c2, c3 chan int var i1, i2 int select { // 从通道c1中读取到i1 \tcase i1 = \u0026lt;-c1: fmt.Printf(\u0026#34;Received\u0026#34;, i1, \u0026#34;from c1\\n\u0026#34;) // 从通道c2中读取到i2 \tcase i2 = \u0026lt;-c2: fmt.Printf(\u0026#34;Received\u0026#34;, i2, \u0026#34;from c2\\n\u0026#34;) case i3, ok := \u0026lt;-c3: if ok { fmt.Printf(\u0026#34;Received\u0026#34;, i3, \u0026#34;from c3\\n\u0026#34;) } else { fmt.Printf(\u0026#34;c3 is closed\\n\u0026#34;) } // 超时退出 \tcase \u0026lt;-time.After(time.Second * 3): fmt.Println(\u0026#34;request time out\u0026#34;) } }  select 中的 case 语句必须时对通道的操作\nselect 中的 default 语句总是可运行的\n如果有多个分支都可以运行，select 会伪随机公平的选出一个执行，其他分支不会执行\n如果没有可运行的分支，且有 default 语句，那么就会执行 default 的动作\n如果没有可运行的分支，且没有 default 语句，那么 select 将会阻塞，直到某个分支可以运行\n  if 语句\r#\r\rif 语句由表达式（结果为布尔值）后紧跟一个或多个语句组成。注意表达式后不用加（），根据表达式的值指定两个分支的条件执行。如果表达式的布尔值为 true ，则执行 if 分支，否则执行 else 分支\nif 布尔表达式 {\r/* 在布尔表达式为ture时执行 */\r} else {\r/* 在布尔表达式为false时执行 */\r}\rpackage main import \u0026#34;fmt\u0026#34; // 定义函数Exp1 func Exp1() { // if语句基本写法 \tscore := 90 if score \u0026gt;= 90 { fmt.Println(\u0026#34;你的成绩为：A\u0026#34;) } else if score \u0026gt;= 80 { fmt.Println(\u0026#34;你的成绩为：B\u0026#34;) } else if score \u0026gt;= 70 { fmt.Println(\u0026#34;你的成绩为：C\u0026#34;) } else if score \u0026gt;= 60 { fmt.Println(\u0026#34;你的成绩为：D\u0026#34;) } else { fmt.Println(\u0026#34;你的成绩为：不及格\u0026#34;) } } // 定义函数Exp2 func Exp2() { // if语句特殊写法，将变量声明写进if语句中 \tif score := 90; score \u0026gt;= 90 { fmt.Println(\u0026#34;你的成绩为：A\u0026#34;) } else if score \u0026gt;= 80 { fmt.Println(\u0026#34;你的成绩为：B\u0026#34;) } else if score \u0026gt;= 70 { fmt.Println(\u0026#34;你的成绩为：C\u0026#34;) } else if score \u0026gt;= 60 { fmt.Println(\u0026#34;你的成绩为：D\u0026#34;) } else { fmt.Println(\u0026#34;你的成绩为：不及格\u0026#34;) } } // 定义程序入口函数 func main() { Exp1() Exp2() }  在Go语言中，当 if 语句没有进入下一个语句，即正文以 break 、continue 、goto 或 return 结尾时，省略不必要的 else 。\nf, err := os.Open(name) if err != nil { return err }   break 语句\r#\r\rGo语言中 break 语句可以结束 for 、switch 和 select 的代码块，另外 break 语句还可以在语句后面添加标签，表示退出某个标签对应的代码块，标签要求必须定义在对应的 for 、switch 和 select 的代码块上\npackage main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Start\u0026#34;) OUTERLOOP: // 定义 OUTERLOOP 标签 \tfor i := 0; i \u0026lt; 3; i++ { fmt.Println(\u0026#34;i循环：\u0026#34;, i) for j := 0; j \u0026lt; 5; j++ { fmt.Println(\u0026#34;j循环：\u0026#34;, j) switch j { case 0: fmt.Println(\u0026#34;break\u0026#34;) break // break 语句的作用范围为该语句出现的最内部结构，因此只跳出了switch \tcase 2: fmt.Println(\u0026#34;2 OUTERLOOP\u0026#34;) break OUTERLOOP // 结束 OUTERLOOP 标签 \t} fmt.Println(\u0026#34;switch:\u0026#34;, j) } } // 以下语句不在 OUTERLOOP 标签中 \tfmt.Println(\u0026#34;End\u0026#34;) }  continue 语句\r#\r\rGo语言中 continue 语句可以跳过本次循环直接进入下一次循环\npackage main import \u0026#34;fmt\u0026#34; func main() { for i := 0; i \u0026lt; 5; i++ { if i == 3 { continue } fmt.Println(\u0026#34;i:\u0026#34;, i) } }  goto语句\r#\r\rGo语言中 goto 语句是跳转到具有相同函数内相应标签的语句\n Go语言不推荐使用goto语句，因为会导致非常糟糕的程序设计，而且总有更加可读的替代方案来实现相同的功能。\n  作用域\r#\r\r 局部变量与全局变量\r#\r\r 局部变量\r#\r\rGo语言中，在函数体或代码块内声明的变量称为局部变量，它们的作用域只在函数体或代码块内，参数和返回值变量也是局部变量。\n 全局变量\r#\r\rGo语言中，在函数体外声明的变量称为全局变量，它们的作用域都是全局的（在本包的范围内）。全局变量可以在整个包甚至外部包（被导出后）使用。全局变量可以在任何函数中使用。\n 简式变量\r#\r\rGo语言中，使用 := 声明的变量，一般也是局部变量，如果新局部变量与全局变量不在一个作用域。Go语言会在此作用域新定义这个局部变量，而在此作用域中，是优先查找此作用域的局部变量，如果找不到才会查找全局变量。局部变量与全局变量尽量不要重名。\n 四种作用域的理解\r#\r\r变量的声明，除了声明其类型，其声明的位置也有讲究，不同的位置决定了其拥有不同的作用范围，说白了就是我这个变量，在哪里可用，在哪里不可用。\n根据声明位置的不同，作用域可以分为以下四个类型：\n 内置作用域：不需要自己声明，所有的关键字和内置类型、函数都拥有全局作用域 包级作用域：必須函数外声明，在该包内的所有文件都可以访问 文件级作用域：不需要声明，导入即可。一个文件中通过import导入的包名，只在该文件内可用 局部作用域：在自己的语句块内声明，包括函数，for、if 等语句块，或自定义的 {} 语句块形成的作用域，只在自己的局部作用域内可用  以上的四种作用域，从上往下，范围从大到小，为了表述方便，我这里自己将范围大的作用域称为高层作用域，而范围小的称为低层作用域。\n对于作用域，有以下几点总结：\n 低层作用域，可以访问高层作用域 同一层级的作用域，是相互隔离的 低层作用域里声明的变量，会覆盖高层作用域里声明的变量  在这里要注意一下，不要将作用域和生命周期混为一谈。声明语句的作用域对应的是一个源代码的文本区域；它是一个编译时的属性。\n而一个变量的生命周期是指程序运行时变量存在的有效时间段，在此时间区域内它可以被程序的其他部分引用；是一个运行时的概念。\n 显式代码块与隐式代码块\r#\r\r 可见性规则\r#\r\r在Go语言中，标识符如果需要被外部的包使用，必须以大写字母开头，这称之为导出。如果标识符以小写字母开头，则对包外是不可见的，但对于包内是可见且可用的。\nGo语言中规定标识符必须是Unicode定义的字母或数字，标识符是一个或多个Unicode字母和数字的序列，标识符中的第一个字符必须是Unicode字母。\n 命名规范以及语法惯例\r#\r\r当某个函数需要被外部包调用的时候，函数名称需要以大写字母开头，当函数名称由两个或两个以上单词组成时，需要遵循Pascal命名法，即全部单词首字母大写的“大驼峰式命名法”，否则就遵循第一个单词首字母小写，其余单词的首字母大写的“小驼峰式命名法”，函数名称首字母小写，跨包不可调用。\n单词之间不可以通过空格断开，或使用连接号（-）、下划线（_）等符号连接。\n"},{"id":2,"href":"/docs/Linux/Basic-Operation/Rsync/","title":"Rsync","section":"Linux运维基础","content":"Rsync\r#\r\r Rsync是一款开源的、快速的、多功能的、可实现全量及增量的本地或远程数据同步备份的优秀工具。并且可以不进行改变原有数据的属性信息，实现数据的备份迁移特性。Rsync软件适用于Unix/Linux/Windows等多种操作系统平台。\nRsync是一个快速和非常通用的文件复制工具。它能本地复制，远程复制，或者远程守护进程方式复制。它提供了大量的参数来控制其行为的各个方面，并且允许非常灵活的方式来实现文件的传输复制。它以其delta-transfer算法闻名。减少通过网络数据发送数量，利用只发送源文件和目标文件之间的差异信息，从而实现数据的增量同步复制。\nRsync被广泛使用在备份和镜像，以及作为一种改进后的复制命令用于日常应用。\n  提示信息：\n官方链接资料：http://www.samba.org/ftp/rsync/rsync.html\n官方手册资料：man rsync / man rsync.conf\n  Rsync的作用\r#\r\r Rsync英文全称为Remote Synchronization，从软件的名称就可以看出来，Rsync具有可使本地和远程两台主机之间的数据快速复制同步镜像、远程备份的功能，这个功能类似SSH的scp命令，但又优于scp命令的功能，scp每次都是全量拷贝，而rsync可以增量拷贝。当然，Rsync还可以在本地主机的不同分区或目录之间全量及增量的复制数据，这又类似cp命令，但同样也优于cp命令，cp每次都是全量拷贝，而raync可以增量拷贝。\nRsync命令除了作为本地和远程复制命令使用以外，还可以作为删除和查看命令被应用，在某种情况下类似于传统的rm和ls命令。 通过上面文字的介绍，可以总结一下rsync命令的主要作用分为以下4种\n 实现本地数据同步复制（等价 cp 命令）\n# 使用 cp 进行文件拷贝 cp -a /etc/hosts /temp/hosts.bak # 使用 rsync 实现 cp 功能 rsync -a /etc/hosts /temp/hosts.bak # 注意：当使用 rsync 同步目录时如果目录后面带/，则同步的是目录中内容 rsync -a /etc/ /temp/ # 同步的是/etc/下的所有文件到/temp/中 rsync -a /etc /temp/ # 这才是将/etc文件夹备份到/temp/中  实现远程数据同步复制（等价 scp 命令）\n# 使用 scp 实现远程数据复制 scp -rp /etc/hosts 192.168.1.100:/temp/hosts_scp # 使用 rsync 实现 scp 功能 rsync -rp /etc/hosts 192.168.1.100:/temp/hosts_rsync  实现数据信息删除功能（等价 rm 命令）\n# 使用 rm 删除文件 rm -rf /temp/* # 使用 rsync 实现 rm 功能 # 先创建一个空目录 mkdir null # 在将空目录同步到要删除的目录 rsync -a --delete /null/ /temp/  实现数据信息查看功能（等价 ls 命令）\n# 使用ls查看文件夹内容 ls /etc # 使用rsync实现ls功能 rsync /etc  Rsync的特性\r#\r\r Rsync的特性如下（7个特性信息说明）：\n  支持拷贝普通文件与特殊文件，如链接文件，设备等；\n  可以有排除指定文件或目录同步的功能，相当于打包命令tar的排除功能；\n# 在打包/opt/data时排除 temp 命名的目录和文件 tar zcvf data_backup.tar.gz /opt/data   可以做到保持原文件或目录的权限、时间、软硬连接、属主、组等所有属性均不改变(-p)；\n  可以实现增量同步，即只同步发生变化的数据，因此数据传输效率很高（tar -N）；\n# 备份 /home 目录自2008-01-01 以来修改过的文件 tar -N 2008-01-01 -zcvf /backup/inc-backup_$(date + %F).tar.gz /home # 备份 /home 目录昨天以来修改过的文件 tar -N $(date -d yesterday \u0026#34;+%F\u0026#34;) -zcvf /backups/inc-backup_$(date + %F).tar.gz /home # 将所有.gif的文件增加到all.tar的包中。-r表示增加文件的意思 tar -rf all.tar *.gif   可以使用rcp、rsh、ssh等方式来配合进行隧道加密传输文件（rsync本身不对数据加密）；\n  可以通过socket（进程方式）传输文件和数据（服务端和客户端）；\n  支持匿名的或认证（无需系统用户）的进程模式传输，可实现方便安全的进行数据备份及镜像。\n   Rsync的复制原理介绍\r#\r\r 在同步备份数据时，默认情况下，Rsync通过其独特的“Quick Check”算法，它仅同步大小或者修改时间发生变化的文件或目录，当然，也可以根据权限、属主等属性的变化同步，但需要指定相应的参数，甚至可以实现只同步一个文件里有变化的内容部分，所以可以实现快速的同步备份数据，即采用增量复制方法对数据信息进行同步，与传统的cp、scp拷贝命令的全量拷贝复制截然不同，增量同步复制数据，在效率上远远高于全量复制。\n Rsync的使用方法\r#\r\r 一般来说，Rsync大致使用三种主要的传输数据方式。\n 本地数据传输模式\n采用此种方式进行数据同步复制，类似于上文中所提到的 cp 本地复制命令功能。\n采用本地数据传输模式的语法格式信息为：\nrsync [OPTION...] SRC... [DEST] # rsync ---数据备份命令 # [OPTION...] ---命令参数信息 # SRC... ---要进行同步备份的源文件或目录信息 # [DEST] ---将数据备份同步到本地系统中的目的路径  远程Shell数据传输模式\n采用此种方式进行数据同步复制，类似于上文中所提到的 scp 远程复制命令功能。\n采用远程数据传输模式语法格式信息为：\n# Pull（拉） rsync [OPTION...] [USER@]HOST:SRC... [DEST] # rsync ---数据备份命令 # [OPTION...] ---命令参数信息 # [USER@] ---以什么用户身份将数据拉取 # HOST:SRC ---从哪个远程主机上，将指定的数据进行备份 # [DEST] ---将远程主机拉取过来的数据保存到本机的什么路径 # Push（推） rsync [OPTION...] SRC... [USER@]HOST:DEST # rsync ---数据备份命令 # [OPTION...] ---命令参数信息 # [USER@] ---以什么用户身份将数据推送 # SRC ---指定本地要推送给备份的数据信息 # HOST:DEST ---将数据信息推送到指定主机相应的目录中  守护进程传输模式\n（后面详细介绍）\n Rsync守护进程服务部署\r#\r\r 服务端部署\r#\r\r 在服务端和客户端均安装 rsync 服务\n# 检查rsync是否安装 rpm -qa rsync # 在客户端和服务端均安装rsync yum -y install rsync  创建配置文件/etc/rsyncd.conf，并将以下内容写入配置文件\n# rsync_config # created by HuangChao at 2023 # ---rsyncd.conf start--- # -------------------------全局配置（影响所有模块）------------------------- # # 指定rsync服务运行的时候，向磁盘进行读写操作的用户 uid = rsync # 指定用户组 gid = rsync # 安全相关参数 use chroot = no # 最大连接数 max connections = 200 # 超时时间 timeout = 300 # 进程对应的进程号文件，用于存放服务运行时进程的ID号（PID） pid file = /var/run/rsyncd.pid # 进程的锁文件 lock file = /var/run/rsync.lock # 程序运行的日志文件 log file = /var/log/rsyncd.log # -------------------------局部配置（影响本模块）------------------------- # [backup] #模块名称 # 注释信息 comment = \u0026#34;Backup Dir By Mr.Huang\u0026#34; # 模块对应的位置（路径） path = /home/backup # 忽略错误程序 ignore errors # 是否只读 read only = false # 是否可以列表 list = false # 允许访问rsync服务器的IP地址（白名单） hosts allow = 192.168.1.0/24 # 禁止访问rsync服务器的IP地址（黑名单） hosts deny = 0.0.0.0/32 # 认证用户，这些用户操作系统中不存在，仅用于认证 auth users = rsync_backup,rsync_user # 设置进行连接认证的密钥文件，不存在的用户进行认证时的密钥文件 secrets file = /etc/rsync.password  创建一个备份目录的管理用户（虚拟用户）\n# 创建一个备份目录的管理用户 useradd -M -s /sbin/nologin rsync # 查看是否创建成功 id rsync  创建备份目录\n# 在/目录下创建名为backup的备份目录，-p代表命令可以重复执行 mkdir -p /home/backup # 将备份目录的属主和属组改成rsync用户 chown -R rsync.rsync /home/backup  创建认证用户密码文件\n# 将 sync_backup:123456 追加到 /etc/rsync.password 文件的末尾 echo \u0026#34;rsync_backup:123456\u0026#34; \u0026gt;\u0026gt; /etc/rsync.password # 更改文件权限，确保密码文件安全 chmod 600 /etc/rsync.password  启动 rsync 备份服务守护进程\n# 启动rsync守护进程 rsync --daemon # 检查rsync是否启动 ps -ef|grep rsync # 查看服务端口,rsync服务端口默认为873 netstat -lntup|grep rsync  客户端部署\r#\r\r Pull（拉）：从备份服务器上将数据拉取到本地，主要用于数据恢复\nrsync [OPTION...] [USER@]HOST::SRC... [DEST] # rsync ---数据备份命令 # [OPTION...] ---命令参数信息 # [USER@] ---指定进行数据传输的认证用户 # HOST:: ---指定备份服务器的IP地址或主机名称 # SRC... ---指定备份服务器上模块名称 # [DEST] ---将数据同步到本地主机的指定路径 示例：\n# 在本机创建用户认证的密码文件 echo \u0026#34;123456\u0026#34; \u0026gt;\u0026gt; /etc/rsync.password # 修改文件权限，必须修改，如果权限不是600，rsync服务则不读密码文件 chmod 600 /etc/rsync.password # 将192.168.1.100服务器的默认备份目录(backup模块中的存储路径)中的文件拉取到/home/data目录中 rsync -avzP rsync_backup@192.168.1.100::backup /home/data --password-file=/etc/rsync.password  --password-file=/etc/rsync.password：表示自动传输密码，用于定时任务的免交互\n  Push（推）：从本机将数据推送到备份服务器，主要用于数据备份\nrsync [OPTION...] SRC... [USER@]HOST::DEST # rsync ---数据备份命令 # [OPTION...] ---命令参数信息 # SRC... ---指定本地主机上需要备份的数据 # [USER@] ---指定进行数据传输的认证用户 # HOST:: ---指定备份服务器的IP地址或主机名称 # DEST ---指定备份服务器上模块名称 示例：\n# 在本机创建用户认证的密码文件 echo \u0026#34;123456\u0026#34; \u0026gt;\u0026gt; /etc/rsync.password # 修改文件权限，必须修改，如果权限不是600，rsync服务则不读密码文件 chmod 600 /etc/rsync.password # 将/home/data中的文件备份到192.168.1.100服务器的默认备份目录(backup模块中的存储路径)中 rsync -avzP /home/data rsync_backup@192.168.1.100::backup --password-file=/etc/rsync.password  --password-file=/etc/rsync.password：表示自动传输密码，用于定时任务的免交互\n  Rsync命令参数\r#\r\r Rsync常用的同步命令参数如下：\n   命令参数 参数说明     -v（verbose） 详细模式，输出进度等信息   -z（compress） 传输时进行压缩以提高传输效率，\u0026ndash;compress-level=NUM可按级别压缩。局域网中一般不压缩。   -a（archive） 归档模式，表示以递归方式传输文件，并保持所有文件属性   -r（recursive）（归类于-a） 子目录递归传输模式   -t（times）（归类于-a） 保持文件时间（文件修改时间）信息   -o（owner）（归类于-a） 保持文件属主信息   -p（perms）（归类于-a） 保持文件权限   -g（group）（归类于-a） 保持文件属组信息   -l（links）（归类于-a） 保留软连接   -D（devices）（归类于-a） 保持设备文件信息   -P（progress） 显示同步的过程及传输时的进度等信息   -e（rsh=COMMOND） 指定使用哪种信道协议，例如：SSH   \u0026ndash;exclude=PATTERN 指定排除不需要传输的文件信息   \u0026ndash;exclude-from=file 文件名所在的目录文件，既可以排除多个文件   \u0026ndash;bwlimit=RATE 传输数据时进行限速   \u0026ndash;delete 使目标目录和源目录数据一致，即无差异同步数据     Rsync守护进程模式的应用场景\r#\r\r 采用 定时任务 + rsync 服务进行数据备份\n应用场景：主要用于企业内部人员产生的数据备份。\n 采用 实时同步（inotify） + rsync 服务进行数据备份**（推荐）**\n应用场景：主要应用于用户产生的数据备份\n Rsync守护进程企业中的实际应用\r#\r\r Rsync服务端\r#\r\r 安装 rsync 软件\nyum install -y rsync  创建配置文件 /etc/rsyncd.conf，并将以下内容写入到配置文件\nuid = rsync gid = rsync use chroot = no max connections = 200 timeout = 300 pid file = /var/run/rsyncd.pid lock file = /var/run/rsync.lock log file = /var/log/rsyncd.log [backup] comment = \u0026#34;Backup Dir By Mr.Huang\u0026#34; path = /home/backup ignore = errors read only = false list = false hosts allow = 10.10.10.0/24 hosts deny = 0.0.0.0/32 auth users = rsync_backup secrets file = /etc/rsync.password  创建备份目录的管理用户\nuseradd -M -s /sbin/nologin rsync  创建备份目录\nmkdir -p /home/backup 对目录进行授权\nchown -R rsync.rsync /home/backup  创建认证用户密码文件\necho \u0026#34;rsync_backup:123456\u0026#34; \u0026gt;\u0026gt; /etc/rsync.password 修改文件权限，确保密码文件安全\nchmod 600 /etc/rsync.password  启动 rsync 备份服务守护进程\nrsync --daemon  Rsync客户端\r#\r\r 安装 rsync 软件\nyum install -y rsync  在本机创建用户认证文件\necho \u0026#34;123456\u0026#34; \u0026gt;\u0026gt; /etc/rsync.password 修改文件权限，确保密码文件安全\nchmod 600 /etc/rsync.password  在 /opt/scripts/ 中创建备份脚本文件\n#!/bin/bash # Design By HC # 定义变量 IP 接收本地ip地址查询的结果 IP=$(ip address show ens33 | awk -F \u0026#34;[ /]+\u0026#34; \u0026#39;NR==3{print $3}\u0026#39;) # 检查本地备份目录，若没有，则创建 if [ ! -d /home/backup/$IP ] then mkdir -p /home/backup/$IP echo \u0026#34;/home/backup/$IP目录已创建！\u0026#34; else echo \u0026#34;/home/backup/$IP目录已存在！\u0026#34; fi # 将数据打包备份 tar zchf /home/backup/$IP/data_backup_$(date +%F-week%w-%T).tar.gz /home/data \u0026amp;\u0026gt;/dev/null # 清除7天以前的历史数据 find /home/backup/$IP/ -type f -name \u0026#34;*.tar.gz\u0026#34; -mtime +7 -delete # 生成数据验证文件 find /home/backup/$IP/ -mmin -10 -name \u0026#34;*.tar.gz\u0026#34; | xargs md5sum \u0026gt; /home/backup/$IP/check.text # 开始rsync传输 rsync -avzP /home/backup/$IP rsync_backup@10.10.10.100::backup --password-file=/etc/rsync.password  Rsync服务端配置邮件系统\r#\r\r 安装 mailx\nyum install -y mailx  配置邮件服务\ncat \u0026gt; /etc/mail.rc \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; set from=huangchao@cncs.cn set smtp=smtp://smtp.cncs.cn:25 set smtp-auth-user=huangchao@cncs.cn set smtp-auth-password=CNCS@cncs.C0M set smtp-auth=login set ssl-verify=ignore set nss-config-dir=/etc/pki/nssdb EOF  创建脚本的目录\nmkdir -p /opt/scripts  在 /opt/scripts/ 中创建验证脚本文件\n#!/bin/bash # Design By HC # 批量检验数据备份的完整性 find /home/backup/ -type f -name \u0026#34;check.txt\u0026#34; | xargs md5sum -c \u0026gt; /var/log/backup_check.log # 发送校验结果信息 mail -s \u0026#34;backup_check\u0026#34; HC@mail.com \u0026lt; /var/log/backup_check.log # 清理30天前的数据信息 find /home/backup/ -type f -mtime +30 -name \u0026#34;*.tar.gz\u0026#34; -delete  Rsync守护进程排除功能实践\r#\r\r 排除指定文件\n# 同步/data_dir目录数据到备份服务器的/backup目录中,但/data_dir目录中的a，b目录不需要同步，d目录中的2.txt不需要同步 rsync -avzP /data_dir/ --exclude=a --exclude=b --exclude=d/2.txt rsync_backup@192.168.1.100::nfs_backup --password-file=/etc/rsync.password # 同步/data_dir目录数据到备份服务器的/backup目录中,但/data_dir目录中的a，b,c目录不需要同步，d目录中的1.txt不需要同步 rsync -avzP /data_dir/ --exclude={a..c} --exclude=d/2.txt rsync_backup@192.168.1.100::nfs_backup --password-file=/etc/rsync.password  把多个排除的信息放在一个文件中\n# 同步/data_dir目录数据到备份服务器的/backup目录中,但/data_dir目录中的a，b,c目录不需要同步，d目录中的1.txt不需要同步 cd /data_dir/ # 编写排除文件信息 vi exclude.txt a b c d/1.txt exclude.txt # 执行rsync命令 rsync -avzP /data_dir/ --exclude-from=/data_dir/exclude.txt rsync_backup@192.168.1.100::nfs_backup --password-file=/etc/rsync.password  Rsync守护进程创建备份目录\r#\r\r 备份文件时可以创建相应的文件夹以分类\n# 将data_dir文件夹中的文件备份到192.168.1.100服务器中nsf_backup/20190620_backup文件夹中,注意：不能一次性创建多级目录！ rsync -avzP /data_dir/ rsync_backup@192.168.1.100::nfs_backup/20190620_backup --password-file=/etc/rsync.password  Rsync守护进程的访问控制\r#\r\r Rsync配置文件中的访问控制分为三种情况：\n  只有白名单（hosts allow）时，白名单流量允许通过，其余流量的默认规则是阻止；\n  只有黑名单（hosts deny）时，黑名单流量阻止通过，其余流量的默认规则是允许；\n  既有白名单，又有黑名单时，白名单流量允许通过，黑名单流量阻止通过，其余流量的默认规则时允许。\n注意：白名单优先级高于黑名单\n   需求：\n内网网段用户（172.16.1.0/24）可以传输数据到backup目录中\n外网网段用户（10.0.0.0/24）不可以传输数据到backup目录中\n示例：\n创建 /etc/rsyncd.conf 配置文件，并将以下内容写入到配置文件中\n# 以下是rsyncd.conf中编写的内容 # rsync_config # created by HuangChao at 2023 ##rsyncd.conf start## uid = rsync gid = rsync use chroot = no max connections = 200 timeout = 300 pid file = /var/run/rsyncd.pid lock file = /var/run/rsync.lock log file = /var/log/rsyncd.log ignore errors read only = false list = false # ---------------------访问控制---------------------------------- # hosts allow = 172.16.1.0/24 hosts deny = 10.0.0.0/24 #--------------------------------------------------------------- # auth users = rsync_backup,rsync_user secrets file = /etc/rsync.password [nfs_backup] comment = \u0026#34;Backup Dir By NFS\u0026#34; path = /backup/nfs_backup [mysql_backup] comment = \u0026#34;Backup Dir By MySQL\u0026#34; path = /backup/mysql_backup  Rsync守护进程的无差异同步（在企业中慎用！）\r#\r\r 实现本地服务器和备份服务器上的数据信息高度一致，说白了，就是我有你也有，我没有你也不能有。除了实现文件夹内容无差异同步，还能实现文件内容的无差异同步\nrsync -avzP --delete /data_dir/ rsync_backup@192.168.1.100::nfs_backup --password-file=/etc/rsync.password  Rsync守护进程的列表功能\r#\r\r rsyncd.conf配置文件中的 list = true 的作用是让客户端可以通过命令获悉服务端的全部模块信息。（建议将list = false）\nrsync rsync_backup@192.168.1.100::  Rsync软件的深入学习方法\r#\r\r  "},{"id":3,"href":"/docs/Python/Python%E4%B9%8B%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81/","title":"Python之字符编码","section":"Python","content":"字符编码\r#\r\r 字符编码记录的是二进制与字符的对应关系。\n 常见的字符编码\r#\r\r ASCII：包含英文字母、数字和特殊字符与二进制的的对应关系。一个字符占用1个字节。\n示例：a：01000001\n GBK：包含本国文字、英文字母、数字和特殊字符与二进制的对应关系。一个英文字符占用1个字节，一个中文字符占用2个字节。\n示例：\na：01000001\n中：01001001 01000010\n Unicode：也被称作“万国码”，包含全世界的所有文字、数字和特殊字符与二进制的对应关系。一个字符占用4个字节。\n示例：\na：01000001 01000010 01000011 00000001\n中：01001001 01000010 01100011 00000001\n UTF-8：包含全世界所有的文字、数字和特殊字符与二进制的对应关系。一个英文字符占用1个字节，一个欧洲字符占用2两字节，一个亚洲字符占用3个字节。\n示例：\na：01000001\nTo（欧洲字符）：01000001 01000010\n中（亚洲字符）：01001001 01000010 01100011\n  知识点：在计算机内存中，统一使用Unicode编码，当需要将数据保存到硬盘或需要使用网络传输的时候，就转换为非Unicode编码，例如：Linux上的UTF-8编码或者Windows上的GBK编码。Python中所有的数据类型在内存中都使用Unicode编码，当需要存储到硬盘或使用网络传输时，需要将内存中Unicode编码的数据类型转换成非Unicode编码的bytes数据类型\n  "},{"id":4,"href":"/docs/Golang/Go%E8%AF%AD%E8%A8%80WEB%E5%BC%80%E5%8F%91/","title":"Go语言WEB开发","section":"Golang","content":"Go语言WEB开发\r#\r\r Go语言标准库之template\r#\r\rhtml/template  包实现了数据驱动的模板，用于生成安全的、可防止代码注入的HTML内容。它提供了和 text/template 包相同的接口，Go语言中输出HTML的场景都应使用 html/template 这个包。\n Go语言模板与渲染\r#\r\r在一些前后端不分离的Web架构中，我们通常需要在后端将一些数据渲染到HTML文档中，从而实现动态的网页（网页的布局和样式大致一样，但展示的内容并不一样）效果。\n我们这里说的模板可以理解为事先定义好的HTML文档文件，模板渲染的作用机制可以简单理解为文本替换操作–使用相应的数据去替换HTML文档中事先准备好的标记。\n很多编程语言的Web框架中都使用各种模板引擎，比如Python语言中Flask框架中使用的jinja2模板引擎。\n Go语言模板引擎\r#\r\rGo语言内置了文本模板引擎text/template和用于HTML文档的html/template。它们的作用机制可以简单归纳如下：\n  模板文件通常定义为.tmpl和.tpl为后缀（也可以使用其他的后缀），必须使用UTF8编码。\n  模板文件中使用{{和}}包裹和标识需要传入的数据。\n  传给模板这样的数据就可以通过点号（.）来访问，如果数据是复杂类型的数据，可以通过{ { .FieldName }}来访问它的字段。\n  除{{和}}包裹的内容外，其他内容均不做修改原样输出。\n   Go语言模板引擎的使用\r#\r\rGo语言模板引擎的使用可以分为三部分：定义模板、解析模板和渲染模板。\n 定义模板\r#\r\r其中，定义模板文件时需要我们按照相关语法规则去编写，后文会详细介绍。\n 解析模板\r#\r\r定义好了模板文件之后，可以使用下面的常用方法去解析模板文件，得到模板对象：\nfunc (t *Template) Parse(src string) (*Template, error) // 解析字符串中的模板 func ParseFiles(filenames ...string) (*Template, error) // 解析一个或多个文件中的模板 func ParseGlob(pattern string) (*Template, error) // 使用正则匹配解析多个文件中的模板  当然，你也可以使用 func New(name string) *Template 函数创建一个名为 name 的模板，然后对其调用上面的方法去解析模板字符串或模板文件。\n  渲染模板\r#\r\r渲染模板简单来说就是使用数据去填充模板，当然实际上可能会复杂很多。\nfunc (t *Template) Execute(wr io.Writer, data interface{}) error // 渲染一个模板，wr是写到哪里去，data是将数据传进来 func (t *Template) ExecuteTemplate(wr io.Writer, name string, data interface{}) error // 渲染多个模板  基本示例\r#\r\r定义模板\r#\r\r我们按照Go模板语法定义一个hello.tmpl的模板文件，内容如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello {{.}} !\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  解析和渲染模板文件\r#\r\r然后我们创建一个main.go文件，在其中写下HTTP server端代码如下：\n// 使用原生 net/http  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;html/template\u0026#34; ) // 定义 sayHello 函数 func sayHello(w http.ResponseWriter, r *http.Request) { // 解析模板 \tt, err := template.ParseFiles(\u0026#34;./Hello.tmpl\u0026#34;) if err != nil { fmt.Printf(\u0026#34;\u0026#34;) return } // 渲染模板 \terr = t.Execute(w,\u0026#34;Golang\u0026#34;) if err != nil { fmt.Printf(\u0026#34;Render Template Failed, Error:%v\\n\u0026#34;, err) return } } // 定义 mian 函数 func main() { http.HandleFunc(\u0026#34;/\u0026#34;, sayHello) err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) if err != nil { fmt.Printf(\u0026#34;HTTP Server Start Failed, Error:%v\\n\u0026#34;, err) return } }  Go语言模板语法\r#\r\r{{.}}\r#\r\r模板语法都包含在 {{ 和 }} 中间，其中 {{.}} 中的点表示当前对象。\n当我们传入一个结构体对象时，我们可以根据 . 来访问结构体的对应字段。\n// main.go  package main import ( \u0026#34;fmt\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) // 定义 UserInfo 结构体 type UserInfo struct { Name string Gender string Age int } func user(w http.ResponseWriter,r *http.Request) { // 解析指定文件生成模板对象 \ttmpl, err := template.ParseFiles(\u0026#34;./user.tmpl\u0026#34;) if err != nil { fmt.Println(\u0026#34;Create Template Failed, Error:\u0026#34;, err) return } userList := UserInfo{ Name : \u0026#34;Golang\u0026#34;, Gender : \u0026#34;男\u0026#34;, Age : 18, } // 利用给定数据渲染模板，并将结果写入w \ttmpl.Execute(w, userList) } func main() { http.HandleFunc(\u0026#34;/user\u0026#34;, user) err := http.ListenAndServe(\u0026#34;127.0.0.1:8080\u0026#34;,nil) if err != nil { fmt.Println(\u0026#34;HTTP Server Start Failed, Error:\u0026#34;, err) return } } 模板文件 user.tmpl 内容如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;姓名：{{.Name}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;性别：{{.Gender}}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;年龄：{{.Age}}\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  同理，当我们传入的变量是map时，也可以在模板文件中通过 . 根据key来取值\n  注释\r#\r\r注释，执行时会忽略。可以多行。注释不能嵌套，并且必须紧贴分界符始止\n{{/* a comment */}}\r pipeline\r#\r\rpipeline 是指产生数据的操作。比如 {{.}} 、 {{.Name}} 等。Go的模板语法中支持使用管道符号 | 链接多个命令，用法和unix下的管道类似： | 前面的命令会将运算结果(或返回值)传递给后一个命令的最后一个位置\n **注意：**并不是只有使用了|才是 pipeline 。Go的模板语法中，pipeline 的概念是传递数据，只要能产生数据的，都是 pipeline\n  变量\r#\r\r可以在模板中声明变量，用来保存传入模板的数据或其他语句生成的结果\n$obj := {{.}}\r 移除空格\r#\r\r有时候我们在使用模板语法的时候会不可避免的引入一下空格或者换行符，这样模板最终渲染出来的内容可能就和我们想的不一样，这个时候可以使用 {{- 语法去除模板内容左侧的所有空白符号， 使用 -}} 去除模板内容右侧的所有空白符号\n{{- .Name -}}\r 注意：-要紧挨{{和}}，同时与模板值之间需要使用空格分隔。\n  条件判断\r#\r\rGo模板语法中的条件判断有以下几种:\n{{if pipeline}} T1 {{end}}\r{{if pipeline}} T1 {{else}} T2 {{end}}\r{{if pipeline}} T1 {{else if pipeline}} T2 {{end}}\r range\r#\r\rGo的模板语法中使用range关键字进行遍历，有以下两种写法，其中pipeline的值必须是数组、切片、字典或者通道\n{{range pipeline}} T1 {{end}}\r 如果 pipeline 的值其长度为 0，不会有任何输出\n {{range pipeline}} T1 {{else}} T2 {{end}}\r 如果 pipeline 的值其长度为 0，则会执行 T2\n  with\r#\r\rGo的模板语法中使用 with 可以制造局部作用域，有以下两种写法\n{{with pipeline}} T1 {{end}}\r 如果 pipeline 为 empty 不产生输出，否则将 . 设为 pipeline 的值并执行 T1。不修改外面的 .\n {{with pipeline}} T1 {{else}} T0 {{end}}\r 如果 pipeline 为 empty ，不改变 . 并执行 T0，否则 . 设为 pipeline 的值并执行 T1\n  预定义函数\r#\r\r执行模板时，函数从两个函数字典中查找：首先是模板函数字典，然后是全局函数字典。一般不在模板内定义函数，而是使用Funcs方法添加函数到模板里\n预定义的全局函数如下：\n   预定义全局函数 作用     and 函数返回它的第一个empty参数或者最后一个参数；就是说\u0026quot;and x y\u0026quot;等价于\u0026quot;if x then y else x\u0026quot;；所有参数都会执行。   or 返回第一个非empty参数或者最后一个参数；即\u0026quot;or x y\u0026quot;等价于\u0026quot;if x then x else y\u0026quot;；所有参数都会执行。   not 返回它的单个参数的布尔值的否定。   len 返回它的参数的整数类型长度。   index 执行结果为第一个参数以剩下的参数为索引/键指向的值；如\u0026quot;index x 1 2 3\u0026quot;返回x[1][2][3]的值；每个被索引的主体必须是数组、切片或者字典。   print 即fmt.Sprint   printf 即fmt.Sprintf   println 即fmt.Sprintln   html 返回与其参数的文本表示形式等效的转义HTML；这个函数在html/template中不可用。   urlquery 以适合嵌入到网址查询中的形式返回其参数的文本表示的转义值；这个函数在html/template中不可用。   js 返回与其参数的文本表示形式等效的转义JavaScript。   call 执行结果是调用第一个参数的返回值，该参数必须是函数类型，其余参数作为调用该函数的参数；如\u0026quot;call .X.Y 1 2\u0026quot;等价于go语言里的dot.X.Y(1, 2)； 其中Y是函数类型的字段或者字典的值，或者其他类似情况；call的第一个参数的执行结果必须是函数类型的值（和预定义函数如print明显不同）； 该函数类型值必须有1到2个返回值，如果有2个则后一个必须是error接口类型；如果有2个返回值的方法返回的error非nil，模板执行会中断并返回给调用模板执行者该错误。     比较函数\r#\r\r布尔函数会将任何类型的零值视为假，其余视为真。\n下面是定义为函数的二元比较运算的集合：\n   模板语言的比较运算符 解释     eq 如果arg1 == arg2则返回真   ne 如果arg1 != arg2则返回真   lt 如果arg1 \u0026lt; arg2则返回真   le 如果arg1 \u0026lt;= arg2则返回真   gt 如果arg1 \u0026gt; arg2则返回真   ge 如果arg1 \u0026gt;= arg2则返回真     自定义函数\r#\r\rGo语言的模板中支持自定义函数：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func customTemp(w http.ResponseWriter, r *http.Request) { // 自定义模板 \tt := template.New(\u0026#34;customTemp.tmpl\u0026#34;) // 自定义函数 \tcustomFunc := func(arg string) (string, error){ return arg + \u0026#34;欢迎回来！\u0026#34;, nil } // 告诉模板引擎，现在多了一个自定义的函数customFunc \tt.Funcs(template.FuncMap{ \u0026#34;customFunc\u0026#34; : customFunc, }) // 解析模板 \t_, err := t.ParseFiles(\u0026#34;./customTemp.tmpl\u0026#34;) if err != nil { fmt.Println(\u0026#34;ParseFile Failed,Error:\u0026#34;, err) return } // 渲染模板 \tname := \u0026#34;客官\u0026#34; t.Execute(w, name) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, customTemp) err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) if err != nil { fmt.Println(\u0026#34;HTTP Server Start Failed,Error:\u0026#34;, err) return } } 模板文件 customTemp.tmpl 内容如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;{{ customFunc . }}\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  模板嵌套\r#\r\r我们可以在template中嵌套其他的template。这个template可以是单独的文件，也可以是通过define定义的template。\n举个例子： t.tmpl文件内容如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;tmpl test\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;测试嵌套template语法\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; {{template \u0026#34;ul.tmpl\u0026#34;}} \u0026lt;hr\u0026gt; {{template \u0026#34;ol.tmpl\u0026#34;}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{ define \u0026#34;ol.tmpl\u0026#34;}} \u0026lt;ol\u0026gt; \u0026lt;li\u0026gt;吃饭\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;睡觉\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;打豆豆\u0026lt;/li\u0026gt; \u0026lt;/ol\u0026gt; {{end}} ul.tmpl文件内容如下：\n\u0026lt;ul\u0026gt; \u0026lt;li\u0026gt;注释\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;日志\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;测试\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; 我们注册一个templDemo路由处理函数:\nhttp.HandleFunc(\u0026#34;/tmpl\u0026#34;, tmplDemo) tmplDemo函数的具体内容如下：\nfunc tmplDemo(w http.ResponseWriter, r *http.Request) { tmpl, err := template.ParseFiles(\u0026#34;./t.tmpl\u0026#34;, \u0026#34;./ul.tmpl\u0026#34;) if err != nil { fmt.Println(\u0026#34;create template failed, err:\u0026#34;, err) return } user := UserInfo{ Name: \u0026#34;客官\u0026#34;, Gender: \u0026#34;男\u0026#34;, Age: 18, } tmpl.Execute(w, user) }  注意：在解析模板时，被嵌套的模板一定要在后面解析，例如上面的示例中t.tmpl模板中嵌套了ul.tmpl，所以ul.tmpl要在t.tmpl后进行解析\n  模板继承\r#\r\r{{block \u0026#34;name\u0026#34; pipeline}} T1 {{end}} block 是定义模板 {{define \u0026quot;name\u0026quot;}} T1 {{end}} 和执行 {{template \u0026quot;name\u0026quot; pipeline}} 的缩写，典型的用法是定义一组根模板，然后通过在其中重新定义块模板进行自定义。\n定义一个根模板 templates/base.tmpl ，内容如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Go Templates\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container-fluid\u0026#34;\u0026gt; {{block \u0026#34;content\u0026#34; . }}{{end}} \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 然后定义一个 templates/index.tmpl 继承 base.tmpl ：\n{{/*注意：继承的模板名称后要加 . ，因为模板中传入了 . ,因此这里也需要用 . 进行接收*/}} {{template \u0026#34;base.tmpl\u0026#34; .}} {{define \u0026#34;content\u0026#34;}} \u0026lt;div\u0026gt;Hello {{.}} !\u0026lt;/div\u0026gt; {{end}} 使用 template.ParseGlob 按照正则匹配规则解析模板文件，然后通过 ExecuteTemplate 渲染指定的模板：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;text/template\u0026#34; ) func index(w http.ResponseWriter, r *http.Request) { // 定义模板 \t// 解析模板 \ttmpl, err := template.ParseGlob(\u0026#34;*.tmpl\u0026#34;) if err != nil { fmt.Println(\u0026#34;The Template Parse Failed,Error:\u0026#34;, err) return } // 渲染模板 \tname := \u0026#34;Golang\u0026#34; err = tmpl.ExecuteTemplate(w, \u0026#34;index.tmpl\u0026#34;, name) fmt.Println(\u0026#34;The template Execute Failed,Error:\u0026#34;, err) return } func main() { http.HandleFunc(\u0026#34;/index\u0026#34;, index) err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) if err != nil { fmt.Println(\u0026#34;HTTP Server Start Failed,Error:\u0026#34;, err) return } }  如果我们的模板名称冲突了，例如不同业务线下都定义了一个index.tmpl模板，我们可以通过下面两种方法来解决。\n 在模板文件开头使用{{define 模板名}}语句显式的为模板命名。 可以把模板文件存放在templates文件夹下面的不同目录中，然后使用template.ParseGlob(\u0026quot;templates/**/*.tmpl\u0026quot;)解析模板。    修改模板的默认标识符\r#\r\rGo标准库的模板引擎使用的花括号{{和}}作为标识，而许多前端框架（如Vue和 AngularJS）也使用{{和}}作为标识符，所以当我们同时使用Go语言模板引擎和以上前端框架时就会出现冲突，这个时候我们需要修改标识符，修改前端的或者修改Go语言的。这里演示如何修改Go语言模板引擎默认的标识符：\ntemplate.New(\u0026quot;test\u0026quot;).Delims(\u0026quot;{[\u0026quot;, \u0026quot;]}\u0026quot;).ParseFiles(\u0026quot;./t.tmpl\u0026quot;)\r text/template与html/tempalte的区别\r#\r\rhtml/template 针对的是需要返回HTML内容的场景，在模板渲染过程中会对一些有风险的内容进行转义，以此来防范跨站脚本攻击。\n例如，我定义下面的模板文件 xss.tmpl ：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{ . }} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 这个时候传入一段JS代码并使用html/template去渲染该文件，会在页面上显示出转义后的JS内容。 \u0026lt;script\u0026gt;alert('xss注入成功！')\u0026lt;/script\u0026gt; 这就是html/template为我们做的事。\n但是在某些场景下，我们如果相信用户输入的内容，不想转义的话，可以自行编写一个safe函数，手动返回一个template.HTML类型的内容。示例如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func xss(w http.ResponseWriter, r *http.Request) { // 定义模板 \t// 解析模板 \ttmpl, err := template.New(\u0026#34;xss.tmpl\u0026#34;).Funcs(template.FuncMap{ \u0026#34;safe\u0026#34; : func(s string) template.HTML { return template.HTML(s) }, }).ParseFiles(\u0026#34;xss.tmpl\u0026#34;) if err != nil { fmt.Println(\u0026#34;Creat Template Failed, Error:\u0026#34;, err) } // 渲染模板 \tjsStr := \u0026#34;\u0026lt;script\u0026gt;alert(\u0026#39;xss注入成功！\u0026#39;)\u0026lt;/script\u0026gt;\u0026#34; err = tmpl.Execute(w, jsStr) if err != nil { println(err) } } func main() { http.HandleFunc(\u0026#34;/xss\u0026#34;, xss) err := http.ListenAndServe(\u0026#34;127.0.0.1:8080\u0026#34;, nil) if err != nil { fmt.Println(\u0026#34;HTTP Server Start Failed,Error:\u0026#34;, err) return } } 这样我们只需要在模板文件不需要转义的内容后面使用我们定义好的safe函数就可以了。\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;ie=edge\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{. | safe}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Gin框架\r#\r\rGin是一个用Go语言编写的web框架。它是一个类似于martini但拥有更好性能的API框架, 由于使用了httprouter，速度提高了近40倍。 如果你是性能和高效的追求者, 你会爱上Gin。\n Gin框架介绍\r#\r\rGo世界里最流行的Web框架，\rGithub上有32K+star。 基于\rhttprouter开发的Web框架。 中文文档齐全，简单易用的轻量级框架。\n Gin框架的安装\r#\r\r下载并安装Gin:\ngo get -u github.com/gin-gonic/gin\r Gin框架的使用\r#\r\rpackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { // 创建一个默认的路由引擎 \tr := gin.Default() // GET：请求方式；/hello：请求的路径 \t// 当客户端以GET方法请求/hello路径时，会执行后面的匿名函数 \tr.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { // c.JSON：返回JSON格式的数据 \tc.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;Hello world!\u0026#34;, }) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 \tr.Run(\u0026#34;:8080\u0026#34;) }  将上面的代码保存并编译执行，然后使用浏览器打开127.0.0.1:8080/hello就能看到一串JSON字符串。\n  RESTful API\r#\r\rREST与技术无关，代表的是一种软件架构风格，REST是Representational State Transfer的简称，中文翻译为“表征状态转移”或“表现层状态转化”。\n推荐阅读\r阮一峰 理解RESTful架构\n简单来说，REST的含义就是客户端与Web服务器之间进行交互的时候，使用HTTP协议中的4个请求方法代表不同的动作。\n GET用来获取资源 POST用来新建资源 PUT用来更新资源 DELETE用来删除资源。  只要API程序遵循了REST风格，那就可以称其为RESTful API。目前在前后端分离的架构中，前后端基本都是通过RESTful API来进行交互。\n例如，我们现在要编写一个管理书籍的系统，我们可以查询对一本书进行查询、创建、更新和删除等操作，我们在编写程序的时候就要设计客户端浏览器与我们Web服务端交互的方式和路径。按照经验我们通常会设计成如下模式：\n   请求方法 URL 含义     GET /book 查询书籍信息   POST /create_book 创建书籍记录   POST /update_book 更新书籍信息   POST /delete_book 删除书籍信息    同样的需求我们按照RESTful API设计如下：\n   请求方法 URL 含义     GET /book 查询书籍信息   POST /book 创建书籍记录   PUT /book 更新书籍信息   DELETE /book 删除书籍信息    Gin框架支持开发RESTful API的开发：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { r := gin.Default() r.GET(\u0026#34;/book\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;GET\u0026#34;, }) }) r.POST(\u0026#34;/book\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;POST\u0026#34;, }) }) r.PUT(\u0026#34;/book\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;PUT\u0026#34;, }) }) r.DELETE(\u0026#34;/book\u0026#34;, func(c *gin.Context) { c.JSON(200, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;DELETE\u0026#34;, }) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 \tr.Run(\u0026#34;:8080\u0026#34;) }  Gin框架基本示例\r#\r\r定义模板文件\r#\r\r我们首先定义一个存放模板文件的templates文件夹，然后在其内部按照业务分别定义一个posts文件夹和一个users文件夹。\nposts/index.html文件的内容如下：\n{{define \u0026#34;posts/index.html\u0026#34;}} \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{.title}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{end}} users/index.html文件的内容如下：\n{{define \u0026#34;users/index.html\u0026#34;}} \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; {{.title}} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; {{end}}  解析和渲染模板文件\r#\r\rmain.go文件内容如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建一个默认的路由引擎 \tr := gin.Default() // 解析模板 \t// Gin框架中使用LoadHTMLGlob()或者LoadHTMLFiles()方法进行模板解析。 \tr.LoadHTMLGlob(\u0026#34;templates/**/*\u0026#34;) // **代表文件夹，*代表文件 \t//r.LoadHTMLFiles(\u0026#34;templates/posts/index.html\u0026#34;, \u0026#34;templates/users/index.html\u0026#34;)  // 渲染模板 \t// 当访问/posts/index时，返回渲染后的posts/index.html模板文件 \tr.GET(\u0026#34;/posts/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;posts/index.html\u0026#34;, gin.H{ \u0026#34;title\u0026#34;: \u0026#34;This is posts/index\u0026#34;, }) }) // 当访问/users/index时，返回渲染后的users/index.html模板文件 \tr.GET(\u0026#34;/users/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;users/index.html\u0026#34;, gin.H{ \u0026#34;title\u0026#34;: \u0026#34;This is users/index\u0026#34;, }) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 \tr.Run() }  Gin框架自定义模板函数\r#\r\r定义一个不转义内容的safe模板函数：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建一个默认的路由引擎 \tr := gin.Default() // 在解析模板之前给模板自定义函数 \tr.SetFuncMap(template.FuncMap{ \u0026#34;safe\u0026#34;: func(str string) template.HTML { return template.HTML(str) }, }) // 解析模板 \t// Gin框架中使用LoadHTMLGlob()或者LoadHTMLFiles()方法进行模板解析。 \t//r.LoadHTMLGlob(\u0026#34;templates/**/*\u0026#34;) // **代表文件夹，*代表文件 \tr.LoadHTMLFiles(\u0026#34;templates/login.html\u0026#34;) // 渲染模板 \tr.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;login.html\u0026#34;, \u0026#34;\u0026lt;a href=\u0026#39;https://baidu.com\u0026#39;\u0026gt;百度\u0026lt;/a\u0026gt;\u0026#34;) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 \tr.Run() }  Gin框架静态文件服务\r#\r\r当渲染的HTML文件中引用了静态文件（css、js、image等文件）时，我们只需要在解析页面前调用gin.Static方法即可\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;html/template\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建一个默认的路由引擎 \tr := gin.Default() // 加载静态文件，当访问/assets/css时去./templates/assets/css中查找 \tr.Static(\u0026#34;/assets/css\u0026#34;, \u0026#34;./templates/assets/css\u0026#34;) // 解析模板 \t// Gin框架中使用LoadHTMLGlob()或者LoadHTMLFiles()方法进行模板解析。 \t//r.LoadHTMLGlob(\u0026#34;templates/**/*\u0026#34;) // **代表文件夹，*代表文件 \tr.LoadHTMLFiles(\u0026#34;templates/login.html\u0026#34;) // 渲染模板 \tr.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;login.html\u0026#34;, nil) }) // 启动HTTP服务，默认在0.0.0.0:8080启动服务 \tr.Run() }  Gin框架模板继承\r#\r\rGin框架默认都是使用单模板，如果需要使用block template功能，可以通过\u0026quot;github.com/gin-contrib/multitemplate\u0026quot;库实现，具体示例如下：\n首先，假设项目目录下的templates文件夹下有以下模板文件，其中home.tmpl和index.tmpl继承了base.tmpl：\ntemplates\r├── includes\r│ ├── home.tmpl\r│ └── index.tmpl\r├── layouts\r│ └── base.tmpl\r└── scripts.tmpl\r然后定义一个loadTemplates函数如下：\nfunc loadTemplates(templatesDir string) multitemplate.Renderer { r := multitemplate.NewRenderer() layouts, err := filepath.Glob(templatesDir + \u0026#34;/layouts/*.tmpl\u0026#34;) if err != nil { panic(err.Error()) } includes, err := filepath.Glob(templatesDir + \u0026#34;/includes/*.tmpl\u0026#34;) if err != nil { panic(err.Error()) } // 为layouts/和includes/目录生成 templates map \tfor _, include := range includes { layoutCopy := make([]string, len(layouts)) copy(layoutCopy, layouts) files := append(layoutCopy, include) r.AddFromFiles(filepath.Base(include), files...) } return r } 在main函数中\nfunc indexFunc(c *gin.Context){ c.HTML(http.StatusOK, \u0026#34;index.tmpl\u0026#34;, nil) } func homeFunc(c *gin.Context){ c.HTML(http.StatusOK, \u0026#34;home.tmpl\u0026#34;, nil) } func main(){ r := gin.Default() r.HTMLRender = loadTemplates(\u0026#34;./templates\u0026#34;) r.GET(\u0026#34;/index\u0026#34;, indexFunc) r.GET(\u0026#34;/home\u0026#34;, homeFunc) r.Run() }  Gin框架JSON渲染\r#\r\rfunc main() { r := gin.Default() // 方式一：自己拼接JSON（用于临时返回JSON） \tr.GET(\u0026#34;/oneJSON\u0026#34;, func(c *gin.Context) { // gin.H 是map[string]interface{}的缩写 \tc.JSON(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Hello world!\u0026#34;}) }) // 方法二：使用结构体（项目中常用的返回JSON的方式） \tr.GET(\u0026#34;/twoJSON\u0026#34;, func(c *gin.Context) { // 定义结构体 msg \tvar msg struct { Name string `json:\u0026#34;name\u0026#34;`\t// 结构体的tag \tMessage string Age int } msg.Name = \u0026#34;小王子\u0026#34; msg.Message = \u0026#34;Hello world!\u0026#34; msg.Age = 18 c.JSON(http.StatusOK, msg) }) r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架XML渲染\r#\r\rfunc main() { r := gin.Default() // 方式一：自己拼接JSON \tr.GET(\u0026#34;/someXML\u0026#34;, func(c *gin.Context) { // gin.H 是map[string]interface{}的缩写 \tc.XML(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;Hello world!\u0026#34;}) }) // 方法二：使用结构体 \tr.GET(\u0026#34;/moreXML\u0026#34;, func(c *gin.Context) { // 定义结构体 MessageRecord \ttype MessageRecord struct { Name string Message string Age int } // 注意使用定义变量 msg 初始化 MessageRecord 结构体类型 \tvar msg MessageRecord msg.Name = \u0026#34;小王子\u0026#34; msg.Message = \u0026#34;Hello world!\u0026#34; msg.Age = 18 c.XML(http.StatusOK, msg) }) r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架YMAL渲染\r#\r\rr.GET(\u0026#34;/YAML\u0026#34;, func(c *gin.Context) { c.YAML(http.StatusOK, gin.H{\u0026#34;message\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;status\u0026#34;: http.StatusOK}) })  Gin框架protobuf渲染\r#\r\rr.GET(\u0026#34;/someProtoBuf\u0026#34;, func(c *gin.Context) { reps := []int64{int64(1), int64(2)} label := \u0026#34;test\u0026#34; // protobuf 的具体定义写在 testdata/protoexample 文件中。 \tdata := \u0026amp;protoexample.Test{ Label: \u0026amp;label, Reps: reps, } // 请注意，数据在响应中变为二进制数据 \t// 将输出被 protoexample.Test protobuf 序列化了的数据 \tc.ProtoBuf(http.StatusOK, data) })  Gin框架获取querystring参数\r#\r\rquerystring指的是前端URL中?后面携带的参数，例如：/user/search?name=张三\u0026amp;age=18\u0026amp;info=SB。 获取请求的querystring参数的方法如下：\nfunc main() { // Default返回一个默认的路由引擎 \tr := gin.Default() r.GET(\u0026#34;/user/search\u0026#34;, func(c *gin.Context) { // name := c.Query(\u0026#34;name\u0026#34;)  // DefaultQuery 当取不到值的时候可以指定默认值 \tname := c.DefaultQuery(\u0026#34;name\u0026#34;, \u0026#34;默认值\u0026#34;)\t// 第一种方式 \tage := c.Query(\u0026#34;age\u0026#34;)\t// 第二种方式 \tinfo, ok := c.GetQuery(\u0026#34;info\u0026#34;)\t// 第三种方式  if !ok { // 当取不到值的的时候  info = \u0026#34;啥也没有！\u0026#34; } // 输出json结果给调用方 \tc.JSON(http.StatusOK, gin.H{ \u0026#34;name\u0026#34;: name, \u0026#34;age\u0026#34;: age, \u0026#34;info\u0026#34;: info, }) }) r.Run() }  Gin框架获取form参数\r#\r\r登录页面login.html代码如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Login\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;/login\u0026#34; method=\u0026#34;post\u0026#34; novalidate autocomplete=\u0026#34;off\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for=\u0026#34;username\u0026#34;\u0026gt;用户名：\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;username\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;label for=\u0026#34;password\u0026#34;\u0026gt;密码：\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; id=\u0026#34;password\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;登录\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 当用户输入用户名和密码，点击登录后跳转到home.html页面代码如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;欢迎！{{ .Username }}, 您的密码是：{{ .Password }}\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 负责逻辑处理的main.go代码如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建默认路由引擎  r := gin.Default() // 解析模板  r.LoadHTMLFiles(\u0026#34;./login.html\u0026#34;, \u0026#34;./home.html\u0026#34;) // 渲染模板(一次请求对应一次响应)  r.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;login.html\u0026#34;, nil) }) // 接收以 POST 方式提交的数据  r.POST(\u0026#34;/login\u0026#34;, func(c *gin.Context) { username := c.PostForm(\u0026#34;username\u0026#34;) password := c.PostForm(\u0026#34;password\u0026#34;) c.HTML(http.StatusOK, \u0026#34;home.html\u0026#34;, gin.H{ \u0026#34;Username\u0026#34;: username, \u0026#34;Password\u0026#34;: password, }) }) // 在8080端口启动服务  r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架获取path参数\r#\r\r前端请求的参数通过URL路径传递，例如：127.0.0.1:8080/blog/2020/1/，想要查询博客中2020年1月的所有文章，获取请求URL路径中的参数的方式如下。\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建默认路由引擎 \tr := gin.Default() r.GET(\u0026#34;/blog/:year/:month\u0026#34;, func(c *gin.Context) { // 通过 Param 获取 path 中的参数 \tyear := c.Param(\u0026#34;year\u0026#34;) month := c.Param(\u0026#34;month\u0026#34;) // 将获取的 path 参数通过JSON返回给浏览器 \tc.JSON(http.StatusOK, gin.H{ \u0026#34;year\u0026#34;: year, \u0026#34;month\u0026#34;: month, }) }) r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架获取json参数\r#\r\r当前端请求的数据通过JSON提交时，例如向/json发送一个POST请求，则获取请求参数的方式如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建默认路由引擎 \tr := gin.Default() r.POST(\u0026#34;/json\u0026#34;, func(c *gin.Context) { // 注意：下面为了举例子方便，暂时忽略了错误处理 \tb, _ := c.GetRawData() // 从c.Request.Body读取请求数据 \t// 定义map或结构体  var m map[string]interface{} // 反序列化 \t_ = json.Unmarshal(b, \u0026amp;m) c.JSON(http.StatusOK, m) }) r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架参数绑定\r#\r\r为了能够更方便的获取请求相关参数，提高开发效率，我们可以基于请求的Content-Type识别请求数据类型，并利用反射机制自动提取请求中QueryString、form表单、JSON、XML等参数到结构体中。 下面的示例代码演示了.ShouldBind()强大的功能，它能够基于请求自动提取JSON、form表单和QueryString类型的数据，并把值绑定到指定的结构体对象。\n// Binding from JSON type Login struct { User string `form:\u0026#34;user\u0026#34; json:\u0026#34;user\u0026#34; binding:\u0026#34;required\u0026#34;` Password string `form:\u0026#34;password\u0026#34; json:\u0026#34;password\u0026#34; binding:\u0026#34;required\u0026#34;` } func main() { router := gin.Default() // 绑定JSON的示例 ({\u0026#34;user\u0026#34;: \u0026#34;q1mi\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;123456\u0026#34;}) \trouter.POST(\u0026#34;/loginJSON\u0026#34;, func(c *gin.Context) { var login Login if err := c.ShouldBind(\u0026amp;login); err == nil { fmt.Printf(\u0026#34;login info:%#v\\n\u0026#34;, login) c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // 绑定form表单示例 (user=q1mi\u0026amp;password=123456) \trouter.POST(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 \tif err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // 绑定QueryString示例 (/loginQuery?user=q1mi\u0026amp;password=123456) \trouter.GET(\u0026#34;/loginForm\u0026#34;, func(c *gin.Context) { var login Login // ShouldBind()会根据请求的Content-Type自行选择绑定器 \tif err := c.ShouldBind(\u0026amp;login); err == nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;user\u0026#34;: login.User, \u0026#34;password\u0026#34;: login.Password, }) } else { c.JSON(http.StatusBadRequest, gin.H{\u0026#34;error\u0026#34;: err.Error()}) } }) // Listen and serve on 0.0.0.0:8080 \trouter.Run(\u0026#34;:8080\u0026#34;) }  ShouldBind会按照下面的顺序解析请求中的数据完成绑定：\n 如果是 GET 请求，只使用 Form 绑定引擎（query）。 如果是 POST 请求，首先检查 content-type 是否为 JSON 或 XML，然后再使用 Form（form-data）。    Gin框架处理文件上传请求\r#\r\r单文件上传示例\r#\r\r前端上传文件页面 index.html 代码如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;单文件上传示例\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;/upload\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;file\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;上传\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 后端 gin 框架代码如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;path\u0026#34; ) func main() { // 创建默认路由引擎 \tr := gin.Default() // 处理前端multipart forms提交文件时默认的内存限制是32 MiB，可以通过 r.MaxMultipartMemory = 8 \u0026lt;\u0026lt; 20 进行修改  // 加载HTML文件 \tr.LoadHTMLFiles(\u0026#34;./index.html\u0026#34;) // 当通过 GET 请求访问 /index 时，执行匿名函数，将 index.html 页面返回给浏览器 \tr.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;index.html\u0026#34;, nil) }) // 当通过 POST 请求访问 /upload 时，执行匿名函数，读取文件内容，并将文件内容保存至本地 \tr.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // 从请求中读取文件 \tf, err := c.FormFile(\u0026#34;file\u0026#34;) if err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;error\u0026#34;: err, }) } // 定义文件存储路径为 ./upload 文件夹 \tfileDstPath := path.Join(\u0026#34;./upload\u0026#34;, f.Filename) // 将读取的文件内容并保存至指定路径 \terr = c.SaveUploadedFile(f, fileDstPath) // 如果保存文件失败，则将错误信息通过JSON返回给浏览器 \tif err != nil { c.JSON(http.StatusOK, gin.H{ \u0026#34;error\u0026#34;: err, }) } // 如果保存文件成功，则将OK信息通过JSON返回给浏览器 \tc.JSON(http.StatusOK, gin.H{ \u0026#34;status\u0026#34;: \u0026#34;OK\u0026#34;, }) }) // 在8080端口启动服务 \tr.Run(\u0026#34;:8080\u0026#34;) }  多文件上传示例\r#\r\r前端上传文件页面 index.html 代码如下：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;多文件上传示例\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form action=\u0026#34;/upload\u0026#34; method=\u0026#34;post\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;!--多文件上传要加 multiple--\u0026gt; \u0026lt;input type=\u0026#34;file\u0026#34; name=\u0026#34;file\u0026#34; multiple\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;上传\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 后端 gin 框架代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建默认路由引擎  r := gin.Default() // 加载HTML文件  r.LoadHTMLFiles(\u0026#34;./index.html\u0026#34;) // 添加 GET 方式到 /index 的路由  r.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;index.html\u0026#34;, nil) }) // 添加 post 方式到 /upload 的路由  r.POST(\u0026#34;/upload\u0026#34;, func(c *gin.Context) { // 从前端页面接收文件  f, err := c.MultipartForm() if err != nil { c.JSON(http.StatusBadRequest, gin.H{ \u0026#34;err\u0026#34;: err, }) } files := f.File[\u0026#34;file\u0026#34;] for index, file := range files { log.Println(file.Filename) // 格式化输出文件保存路径  dstFilePath := fmt.Sprintf(\u0026#34;./upload/%d_%s\u0026#34;, index, file.Filename) // 保存接收的文件到指定的路径  c.SaveUploadedFile(file, dstFilePath) } c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: fmt.Sprintf(\u0026#34;%d files uploaded!\u0026#34;, len(files)), }) }) r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架请求重定向\r#\r\rHTTP重定向\r#\r\rGin框架下实现HTTP 重定向非常简单，并且支持内、外部重定向。示例代码 mian.go 内容如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建默认路由引擎 \tr := gin.Default() // 定义路由test \tr.GET(\u0026#34;/test\u0026#34;, func(c *gin.Context) { // 使用 Redirect 重定向HTTP \tc.Redirect(http.StatusMovedPermanently, \u0026#34;https://www.baidu.com\u0026#34;) }) // 在8080端口运行服务 \tr.Run(\u0026#34;:8080\u0026#34;) }  路由重定向\r#\r\rGin框架使用HandleContext来实现路由重定向。路由重定向一般用于首页跳转到登录页，登录成功之后再从登录页跳转到首页上。示例代码 mian.go 内容如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { // 创建默认路由引擎  r := gin.Default() // 定义路由a  r.GET(\u0026#34;/a\u0026#34;, func(c *gin.Context) { // 重定向URI，跳转到路由 b  c.Request.URL.Path = \u0026#34;/b\u0026#34; // 重新输入已重写的 Context  r.HandleContext(c) }) // 定义路由b  r.GET(\u0026#34;/b\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \u0026#34;info\u0026#34;: \u0026#34;This is b!\u0026#34;, }) }) // 在8080端口运行服务  r.Run(\u0026#34;:8080\u0026#34;) }  Gin框架路由\r#\r\r普通路由\r#\r\rr.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) {...}) r.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) {...}) r.POST(\u0026#34;/login\u0026#34;, func(c *gin.Context) {...})  特殊路由\r#\r\r使用 Any 可以匹配所有请求方法（GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、CONNECT、TRACE）：\nr.Any(\u0026#34;/test\u0026#34;, func(c *gin.Context) {...}) 在没有匹配到路由的时候，可以通过 NoRoute 进行默认路由处理，例如：在没有匹配到路由的时候，默认返回 404 页面\nr.NoRoute(func(c *gin.Context) { c.HTML(http.StatusNotFound, \u0026#34;views/404.html\u0026#34;, nil) })  路由组\r#\r\r可以将具有共同URL或URI前缀的路由划分为一个路由组，习惯上将同一个路由组的路由包裹在 {} 内，不适用 {} 不会影响功能。\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { r := gin.Default() // 定义 userGroup 路由组 \tuserGroup := r.Group(\u0026#34;/user\u0026#34;) { userGroup.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) {...}) userGroup.GET(\u0026#34;/login\u0026#34;, func(c *gin.Context) {...}) userGroup.POST(\u0026#34;/login\u0026#34;, func(c *gin.Context) {...}) } // 定义 shopGroup 路由组 \tshopGroup := r.Group(\u0026#34;/shop\u0026#34;) { shopGroup.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) {...}) shopGroup.GET(\u0026#34;/cart\u0026#34;, func(c *gin.Context) {...}) shopGroup.POST(\u0026#34;/checkout\u0026#34;, func(c *gin.Context) {...}) } // 默认会在8080端口启动服务 \tr.Run() } 路由组也是支持嵌套的，例如：\nshopGroup := r.Group(\u0026#34;/shop\u0026#34;) { shopGroup.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) {...}) shopGroup.GET(\u0026#34;/cart\u0026#34;, func(c *gin.Context) {...}) shopGroup.POST(\u0026#34;/checkout\u0026#34;, func(c *gin.Context) {...}) // 嵌套路由组 \txx := shopGroup.Group(\u0026#34;xx\u0026#34;) xx.GET(\u0026#34;/oo\u0026#34;, func(c *gin.Context) {...}) }  通常在划分业务逻辑或划分API版本时会使用到路由组\n  路由原理\r#\r\rGin框架中的路由使用的是 httprouter 这个库。其基本原理就是构造一个路由地址的前缀树。\n 中间件\r#\r\rGin框架允许开发者在处理请求的过程中，加入自己的钩子（Hook）函数，这个钩子函数就叫中间件，中间件适合处理一些公共的业务逻辑，比如：登录认证、权限校验、数据分页、记录日志、耗时统计等。\n 定义中间件\r#\r\rGin中的中间件必须是一个gin.HandlerFunc类型。下面的代码是定义一个统计请求耗时的中间件。\n// StatCost 是一个统计耗时请求耗时的中间件 func StatCost() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Set(\u0026#34;name\u0026#34;, \u0026#34;Golang\u0026#34;) // 可以通过c.Set在请求上下文中设置值，后面的处理函数（HandlerFunc）能够取到该值 \tc.Next() // 调用该请求后面的处理函数（HandlerFunc） \t// 不调用该请求后面的处理函数（HandlerFunc）时使用：c.Abort() \tcost := time.Since(start) // 计算耗时 \tlog.Println(cost) } }  注册中间件\r#\r\r在gin框架中，我们可以为每个路由添加任意数量的中间件。\n为指定路由注册中间件，示例代码如下：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) // indexHandler 是一个访问 /index 时的处理函数（HandlerFunc） func indexHandler(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\u0026#34;msg\u0026#34;:\u0026#34;index\u0026#34;}) } // StatCost 是定义一个统计耗时请求耗时的中间件 func StatCost() gin.HandlerFunc { return func(c *gin.Context) { fmt.Println(\u0026#34;in\u0026#34;) start := time.Now() c.Set(\u0026#34;name\u0026#34;, \u0026#34;Golang\u0026#34;) // 可以通过c.Set在请求上下文中设置值，后面的处理函数（HandlerFunc）能够取到该值（跨中间件取值）  c.Next() // 调用该请求后面的处理函数（HandlerFunc）  // 不调用该请求后面的处理函数（HandlerFunc）时使用：c.Abort()  cost := time.Since(start) // 计算耗时  log.Println(cost) fmt.Println(\u0026#34;out\u0026#34;) } } func main() { // 创建默认路由引擎  r := gin.Default() // 定义index路由  r.GET(\u0026#34;/index\u0026#34;, StatCost(), indexHandler) // 在默认端口8080上启动服务  r.Run() } 为全局路由注册中间件，示例代码如下：\npackage main import ( \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; ) // homeHandler 是一个访问 /home 时的处理函数（HandlerFunc） func homeHandler(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\u0026#34;msg\u0026#34;:\u0026#34;home\u0026#34;}) } // shopHandler 是一个访问 /home 时的处理函数（HandlerFunc） func shopHandler(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\u0026#34;msg\u0026#34;:\u0026#34;shop\u0026#34;}) } // indexHandler 是一个访问 /video 时的处理函数（HandlerFunc） func videoHandler(c *gin.Context) { c.JSON(http.StatusOK, gin.H{\u0026#34;msg\u0026#34;:\u0026#34;video\u0026#34;}) } // StatCost 是定义一个统计耗时请求耗时的中间件 func StatCost() gin.HandlerFunc { return func(c *gin.Context) { start := time.Now() c.Set(\u0026#34;name\u0026#34;, \u0026#34;Golang\u0026#34;) // 可以通过c.Set在请求上下文中设置值，后面的处理函数（HandlerFunc）能够取到该值  c.Next() // 调用该请求后面的处理函数（HandlerFunc）  // 不调用该请求后面的处理函数（HandlerFunc）时使用：c.Abort()  cost := time.Since(start) // 计算耗时  log.Println(cost) } } func main() { // 新建一个没有任何默认中间件的路由  r := gin.New() // 注册一个全局中间件  r.Use(StatCost()) // 定义home路由  r.GET(\u0026#34;/home\u0026#34;, homeHandler) // 定义shop路由  r.GET(\u0026#34;/shop\u0026#34;, shopHandler) // 定义index路由  r.GET(\u0026#34;/video\u0026#34;, videoHandler) // 在默认端口8080上启动服务  r.Run() }  为路由组注册中间件\r#\r\r为路由组注册中间件有两种写法\n写法1：\nshopGroup := r.Group(\u0026#34;/shop\u0026#34;, StatCost()) { shopGroup.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) {...}) ... } 写法2：\nshopGroup := r.Group(\u0026#34;/shop\u0026#34;) shopGroup.Use(StatCost()) { shopGroup.GET(\u0026#34;/index\u0026#34;, func(c *gin.Context) {...}) ... }  中间件注意事项\r#\r\rGin框架默认路由引擎中的中间件\r#\r\rgin.Default()默认使用了Logger和Recovery中间件，其中：\n Logger中间件将日志写入gin.DefaultWriter，即使配置了GIN_MODE=release。 Recovery中间件会recover任何panic。如果有panic的话，会写入500响应状态码。  如果不想使用上面两个默认的中间件，可以使用gin.New()新建一个没有任何默认中间件的路由。\n Gin框架中间件中使用goroutine\r#\r\r当在中间件或handler中启动新的goroutine时，不能使用原始的上下文(c *gin.Context)，为了保证数据的安全，必须使用其只读副本(c.Copy())。\n Gin框架下运行多个服务\r#\r\rGin框架可以在多个端口启动服务\npackage main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;golang.org/x/sync/errgroup\u0026#34; ) var ( g errgroup.Group ) func router01() http.Handler { e := gin.New() e.Use(gin.Recovery()) e.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.JSON( http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: http.StatusOK, \u0026#34;error\u0026#34;: \u0026#34;Welcome server 01\u0026#34;, }, ) }) return e } func router02() http.Handler { e := gin.New() e.Use(gin.Recovery()) e.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.JSON( http.StatusOK, gin.H{ \u0026#34;code\u0026#34;: http.StatusOK, \u0026#34;error\u0026#34;: \u0026#34;Welcome server 02\u0026#34;, }, ) }) return e } func main() { server01 := \u0026amp;http.Server{ Addr: \u0026#34;:8080\u0026#34;, Handler: router01(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, } server02 := \u0026amp;http.Server{ Addr: \u0026#34;:8081\u0026#34;, Handler: router02(), ReadTimeout: 5 * time.Second, WriteTimeout: 10 * time.Second, } // 借助errgroup.Group或者自行开启两个goroutine分别启动两个服务 \tg.Go(func() error { return server01.ListenAndServe() }) g.Go(func() error { return server02.ListenAndServe() }) if err := g.Wait(); err != nil { log.Fatal(err) } }  "},{"id":5,"href":"/docs/Linux/Basic-Operation/NFS/","title":"NFS","section":"Linux运维基础","content":"NFS\r#\r\r  NFS(Network File System)网络文件系统\n  NFS的优缺点\r#\r\r 优点\r#\r\r  简单、稳定、可靠   缺点\r#\r\r  存在单点故障，如果NFS Server宕机所有客户端均不能访问共享目录，可通过负载均衡和高可用方案弥补； 在大数据高并发的场合，NFS的效率和性能有限（一般几千万PV以下不是瓶颈，除非网站架构太差，WEB、数据库、存储前都没有缓存机制）； 客户端认证时基于IP地址和主机名称，权限是根据ID识别，安全性一般（用于局域网中问题不大）； NFS数据是明文的，NFS本身对数据不做验证； 多台客户端挂载一个NFS服务器时，管理维护麻烦（耦合度高），尤其是NFS服务端出问题后，所有NFS客户端都会挂掉   安装NFS和RPC服务\r#\r\r 在服务端和客户端上，安装NFS和RPC服务\nyum -y install nfs-utils rpcbind  在服务端和客户端上，检查安装的NFS、RPC服务\nrpm -aq nfs-utils rpcbind  启动NFS、RPC服务\r#\r\r 先启动RPC服务，一定要先启动RPC服务！\n# /etc/init.d/rpcbind start systemctl start rpcbind.service  检查RPC服务启动状态\n# /etc/init.d/rpcbind status systemctl status rpcbind.service  查看占用端口的服务，RPC主端口为：111\n# lsof -i :111 netstat -lntup | grep rpcbind  设置NFS开机自启动，建议将启动命令写在/etc/rc.local文件中（默认情况下rpcbind会随系统启动）\n# chkconfig rpcbind on systemctl enable rpcbind.service  检查NFS开机自启动状态\nsystemctl list-unit-files | grep enabled  然后启动NFS服务\n# /etc/init.d/nfs start systemctl start nfs  检查NFS服务启动状态\n# /etc/init.d/nfs status systemctl status nfs  查看占用端口的服务，NFS主端口为：2049\n# lsof -i :2049 netstat -lntup|grep 2049  设置NFS开机自启动，建议将启动命令写在/etc/rc.local文件中\n# chkconfig nfs on systemctl enable nfs  检查NFS开机自启动状态\nchkconfig --list nfs  查看RPC信息池\nrpcinfo -p localhost  NFS重要文件说明\r#\r\r /etc/exports # NFS主配置文件 /usr/sbin/exportfs # NFS服务的管理命令。还可以直接配置NFS共享目录，无需配置exports就可以实现共享 /usr/sbin/exportfs -rv # 加载NFS配置生效 /usr/sbin/showmount # 查看NFS配置及挂载结果的命令 /var/lib/nfs/etab # NFS服务端详细配置参数 /proc/mounts # 客户端挂载参数  配置NFS服务端\r#\r\r 创建共享目录、临时文件目录和日志目录\nmkdir -p /nfs/{tmp,data,logs}  配置文件，默认是空的，若没有exports，手动创建\nvim /etc/exports  exports配置文件格式\n\u0026lt;共享的目录\u0026gt; \u0026lt;客户端1的IP或网段/子网掩码(访问权限,用户映射,其他)\u0026gt; \u0026lt;客户端2的IP或网段/子网掩码(rw,sync,all_squash)\u0026gt; # 示例 /nfs/tmp *(rw,sync,no_subtree_check,no_root_squash) /nfs/data *(rw,sync,no_subtree_check,no_root_squash) /nfs/logs *(rw,sync,no_subtree_check,no_root_squash)  /etc/exprots中的权限参数主要有如下几个：\nrw : 该目录共享的权限是读写。\nro : 该目录共享的权限是只读 但最终能不能读写还是与文件系统的权限和身份有关。\nsync : 数据会同步写入到内存和硬盘中。\nasync : 数据会暂存于内存而不写入硬盘。\nno_root_squash : 开放客户端使用root使用来操作文件系统，也就是说让root写入的文件仍然具有root权限。\nroot_squash : 默认客户端的root用户被会压缩为nfsnobody，这样对服务器系统较有保障。\nall_squash : 不论登录NFS服务器的客户端用户身份是什么，默认都会被压缩为匿名用户（nobody或者nfsnobody）。\nanonuid : 这个值一般是结合all_squash一起使用的，它是指匿名用户中的UID的设置值，用这个anonuid可以自行设置UID的值，注意：这个UID必须要存在与/etc/passwd中。\nanongid : 组的GID。\n  使配置生效\nexportfs -r  服务端查看共享的记录\nshowmount -e 127.0.0.1  查看NFS配置文件的完整参数设定\ncat /var/lib/nfs/etab  查看anonuid的匿名用户名称\ngrep 65534 /etc/passwd  更改共享目录的所属用户权限\nchown -R nfsnobody \u0026lt;共享目录路径\u0026gt;  检查\nls -ld \u0026lt;共享目录路径\u0026gt;  客户端连接NFS服务端\r#\r\r 启动RPC服务\n# /etc/init.d/rpcbind start systemctl start rpcbind.service  查询NFS服务器的相关信息\nshowmount -e \u0026lt;NFS服务端IP\u0026gt;  挂载服务端共享目录 ，并将此命令添加到/etc/rc.local中\nmount -t nfs \u0026lt;服务端IP地址\u0026gt;:\u0026lt;服务端共享目录\u0026gt; /mnt  挂载服务端共享目录（手动增加参数）\nmount -t nfs -o bg,hard,intr,rsize=131072,wsize=131072 \u0026lt;服务端IP地址\u0026gt;:\u0026lt;服务端共享目录\u0026gt; /mnt  检查\ndf -h  NFS客户端挂载优化\r#\r\r  企业生产环境挂载NFS性能优化\n 安全挂载参数、禁止更新目录及文件时间戳\nmount -t nfs -o nosuid,noexec,nodev,noatime,nodiratime,intr,rw \u0026lt;服务端IP地址\u0026gt;:\u0026lt;服务端共享目录\u0026gt; /mnt  "},{"id":6,"href":"/docs/Python/Python%E4%B9%8B%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/","title":"Python之文件操作","section":"Python","content":"文件操作\r#\r\r 在Python中，可以使用内置函数open()对文件进行操作。\n文件操作需要如下几个参数：\n 文件路径：path 打开方式：mode， 打开方式有读、写、追加、读写 编码方式：encoding，UTF-8、GBK、GB2312等，内置函数open()中如果不声明encoding，则默认的编码方式与操作系统相同。   Python文件操作需要注意的是，以什么样的编码保存的，就必须以什么样的编码打开。\n  文件操作的读\r#\r\r r 模式：读文件\r#\r\r  操作文本类文件，有五种读取方式\n  方式一：将文件内容一次性全部读取到文件句柄，文件句柄是一个迭代器（★）\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;)\t# encoding只是声明编码方式 content = f.read()\t# f称之为“文件句柄”，对文件的任何操作都需要通过 文件句柄. 的方式 print(content) f.close()  方式二：按照指定的字符个数读取文件内容\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) content = f.read(10) # f.read(10)表示读取文件的前10个字符 print(content) f.close()  方式三：按照行读取文件内容，读取一行\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) content = f.readline() # 注意，每一行内容后都有一个隐藏的换行符：\\n print(content) f.close()  方式四：按照行读取文件内容，读取多行\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) l = f.readlines() # readlines()返回一个列表，列表的每一个元素是文件中的一行。 print(content) f.close()  方式五：使用for循环读取文件的每一行，此方法适合操作大文件（★）\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) for line in f: print(line) f.close()  rb 模式：以bytes类型读文件\r#\r\r  操作非文本类文件（图片、音频、视频），不用声明 encoding，与 \u0026lsquo;r ' 模式一样，也有五种方式\n  方式一：将文件内容一次性全部读取到文件句柄，文件句柄是一个迭代器（★）\nf = open(r\u0026#39;非文本文件的路径\u0026#39;, mode = \u0026#39;rb\u0026#39;) content = f.read()\t# f称之为“文件句柄”，对文件的任何操作都需要通过 文件句柄. 的方式 print(content) f.close()  方式二：按照指定的字符个数读取文件内容\n略\n 方式三：按照行读取文件内容，读取一行\n略\n 方式四：按照行读取文件内容，读取多行\n略\n 方式五：使用for循环读取文件的每一行，此方法适合操作大文件（★）\nf = open(r\u0026#39;非文本文件的路径\u0026#39;, mode = \u0026#39;rb\u0026#39;) for line in f: print(line) f.close()  r+模式：读写文件\r#\r\r  可以对文件进行读、写两种操作\n  先读后写：读完文件，光标会移至文件内容的最后，写入时，会将内容写入到文件的最后，类似于文件的追加。\nf = open(r\u0026#39;读写文件的路径\u0026#39;, mode=\u0026#39;r+\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) content = f.read() f.write(\u0026#39;读完文件后，需要写入文件的内容\u0026#39;) f.close()  先写后读：会先用写的内容覆盖文件的内容，然后再读。不要这样做！\n r+b模式：以bytes类型读写文件\r#\r\r 文件操作的写\r#\r\r w 模式：写文件\r#\r\r  操作文本类文件，若文件不存在，先创建文件再写入；若文件存在，先清空文件再写入\n  f = open(r\u0026#39;待写入的文件路径及文件名\u0026#39;, mode = \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) f.write(\u0026#39;写入一段字符串\u0026#39;) f.close()  wb 模式：以bytes类型写文件\r#\r\r  可以操作文本类的文件，但主要用于操作非文本类的文件，用于文件的复制\n  # 先以bytes类型读取非文本文件内容 f_1 = open(r\u0026#39;非文本类型文件路径\u0026#39;, mode=\u0026#39;rb\u0026#39;) content = f_1.read() f_1.close() # 再把读取到的数据以bytes类型写入一个新文件，即完成文件的复制 f = open(r\u0026#39;待写入的文件路径及文件名\u0026#39;, mode = \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) f.write(content) f.close()  w+模式：读写文件\r#\r\r 略\n w+b模式：以bytes类型读写文件\r#\r\r 略\n 文件操作的追加\r#\r\r 'a' 模式：文件的追加\r#\r\r  没有文件，创建文件，追加内容；有文件，在文件最后追加内容\n  f = open(r\u0026#39;追加文件的路径\u0026#39;, mode=\u0026#39;a\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) f.write(\u0026#39;需要追加的内容\u0026#39;) f.close()  ab模式：以bytes类型进行文件的追加\r#\r\r 略\n a+模式：文件追加并可读\r#\r\r 略\n a+b模式：以bytes类型进行追加并可读\r#\r\r 略\n 文件操作的其他模式\r#\r\r tell() 获取光标的位置，单位是字节。可以与用断点续传等功能。\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) content = f.readline() # 注意，每一行内容后都有一个隐藏的换行符：\\n print(f.tell())\t# 可以获取到光标的位置，单位是字节 f.close()  seek() 调整光标位置，单位是字节。可以与用断点续传等功能。\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) f.seek(30)\t# 光标从开的0，想后移动30个字节 f.write(\u0026#39;需要写入的内容\u0026#39;) f.close()  flush() 强制刷新（强制保存）\nf = open(r\u0026#39;文本文件的路径\u0026#39;, mode = \u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) f.write(\u0026#39;需要写入的内容\u0026#39;) f.flush() f.close()  打开文件的另一种方式（★）\r#\r\r 使用 with 的方式打开文件\n# 打开一个文件 with open(\u0026#39;需要打开的文件路径\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: print(f.read()) # 打开多个文件 with open(\u0026#39;文件1的路径\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f1,open(\u0026#39;文件2的路径\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f2: print(f1.read()) print(f2.read())  优点：\n 不用手动关闭文件句柄f.close()，文件句柄会自动在一定时间内自动关闭。 可同时打开多个文件，且不用关闭句柄。   文件操作的改（★）\r#\r\r 现存所有的软件，对文件修改都要经历如下五个步骤：\n 以读的模式打开原文件； 以写的模式创建一个新文件； 将原文件的内容读出来修改成新内容，写入新文件； 将原文件在内存中删除； 将新文件重命名为原文件。   改文件的示例代码\n# 改小文件可以通过以下方式 import os # 以读的模式开打一个原文件，以写的模式打开一个新文件 with open(\u0026#39;原文件\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f1,open(\u0026#39;新文件\u0026#39;, mode=\u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f2: # 将原文件的内容读出来，修改成新内容 old_content = f1.read() new_content = old_content.replace(\u0026#39;新内容\u0026#39;,\u0026#39;旧内容\u0026#39;) # 写入新文件 f2.write(new_content) # 将原文件删除 os.remove(\u0026#39;原文件\u0026#39;) # 将新文件重命名成原文件 os.rename(\u0026#39;新文件\u0026#39;, \u0026#39;原文件\u0026#39;) # 改大文件，为了节省内存，可以通过以下方式 import os # 以读的模式开打一个原文件，以写的模式打开一个新文件 with open(\u0026#39;原文件\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f1, open(\u0026#39;新文件\u0026#39;, mode=\u0026#39;w\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f2: # 对原文件一行一行的读 for line in f1: # 对读出来的一行，若是有需要替换的内容，就用新内容替换 new_line = line.replace(\u0026#39;新内容\u0026#39;,\u0026#39;旧内容\u0026#39;) # 改好的行写入新文件 f2.write(new_line) # 没有关闭文件句柄，写文件时不会清空文件 # 将原文件删除 os.remove(\u0026#39;原文件\u0026#39;) # 将新文件重命名成原文件 os.rename(\u0026#39;新文件\u0026#39;, \u0026#39;原文件\u0026#39;) "},{"id":7,"href":"/docs/Golang/Go%E8%AF%AD%E8%A8%80%E7%9A%84ORM%E6%A1%86%E6%9E%B6/","title":"Go语言的ORM框架","section":"Golang","content":"Go语言的ORM框架\r#\r\r GORM简介\r#\r\rGORM是一个使用Go语言编写的ORM框架。它文档齐全，对开发者友好，支持主流数据库。\n中文官方网站：https://gorm.io/zh_CN/\n官方中文文档：https://gorm.io/zh_CN/docs/\n GORM安装\r#\r\r// 安装 GORM 框架 go get -u gorm.io/gorm // 安装 MySQL 数据库驱动 go get -u gorm.io/driver/mysql // 安装 SQL Server 数据库驱动 go get -u gorm.io/driver/mssql // 安装 PostgreSQL 数据库驱动 go get -u gorm.io/driver/postgres // 安装 SQLite 数据库驱动 go get -u gorm.io/driver/sqlite // 安装 Oracle 数据库驱动 go get github.com/CengSin/oracle  GORM连接数据库\r#\r\rGORM连接MySQL\r#\r\rimport ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/mysql\u0026#34; ) // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情 dsn := \u0026#34;username:password@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { panic(err) } defer gormDB.close()  想要正确的处理 time.Time ，您需要带上 parseTime 参数， (\r更多参数) 要支持完整的 UTF-8 编码，您需要将 charset=utf8 更改为 charset=utf8mb4 查看 此文章 获取详情\n MySQL 驱动程序提供了一些[高级配置](\rGitHub - go-gorm/mysql: GORM mysql driver)可以在初始化过程中使用，例如：\nimport ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) db, err := gorm.Open(mysql.New(mysql.Config{ DSN: \u0026#34;username:password@tcp(127.0.0.1:3306)/dbname?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;, // DSN data source name  DefaultStringSize: 256, // string 类型字段的默认长度  DisableDatetimePrecision: true, // 禁用 datetime 精度，MySQL 5.6 之前的数据库不支持  DontSupportRenameIndex: true, // 重命名索引时采用删除并新建的方式，MySQL 5.7 之前的数据库和 MariaDB 不支持重命名索引  DontSupportRenameColumn: true, // 用 `change` 重命名列，MySQL 8 之前的数据库和 MariaDB 不支持重命名列  SkipInitializeWithVersion: false, // 根据当前 MySQL 版本自动配置 }), \u0026amp;gorm.Config{}) GORM 允许通过 DriverName 选项自定义 MySQL 驱动，例如：\nimport ( \u0026#34;gorm.io/gorm\u0026#34; _ \u0026#34;example.com/my_mysql_driver\u0026#34; ) db, err := gorm.Open(mysql.New(mysql.Config{ DriverName: \u0026#34;my_mysql_driver\u0026#34;, DSN: \u0026#34;username:password@tcp(localhost:9910)/dbname?charset=utf8\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34;, // Data Source Name，参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name }), \u0026amp;gorm.Config{}) GORM 允许通过一个现有的数据库连接来初始化 *gorm.DB\nimport ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;database/sql\u0026#34; ) sqlDB, err := sql.Open(\u0026#34;mysql\u0026#34;, \u0026#34;mydb_dsn\u0026#34;) gormDB, err := gorm.Open(mysql.New(mysql.Config{Conn: sqlDB,}), \u0026amp;gorm.Config{})  GORM连接SQL Server\r#\r\rimport ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/sqlserver\u0026#34; ) // 参考 https://github.com/denisenkom/go-mssqldb 获取详情 dsn := \u0026#34;sqlserver://username:password@localhost:9930?database=dbname\u0026#34; db, err := gorm.Open(sqlserver.Open(dsn), \u0026amp;gorm.Config{})  GORM连接PostgreSQL\r#\r\rimport ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/postgres\u0026#34; ) dsn := \u0026#34;host=localhost user=username password=password dbname=dbname port=9920 sslmode=disable TimeZone=Asia/Shanghai\u0026#34; db, err := gorm.Open(postgres.Open(dsn), \u0026amp;gorm.Config{}) GORM使用 pgx 作为 postgres 的 database/sql 驱动，默认情况下，它会启用 prepared statement 缓存，你可以这样禁用它：\nimport ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/postgres\u0026#34; ) // https://github.com/go-gorm/postgres db, err := gorm.Open(postgres.New(postgres.Config{ DSN: \u0026#34;user=username password=password dbname=dbname port=9920 sslmode=disable TimeZone=Asia/Shanghai\u0026#34;, PreferSimpleProtocol: true, // disables implicit prepared statement usage }), \u0026amp;gorm.Config{})  GORM连接SQLite\r#\r\rimport ( \u0026#34;gorm.io/gorm\u0026#34; \u0026#34;gorm.io/driver/sqlite\u0026#34; ) // github.com/mattn/go-sqlite3 db, err := gorm.Open(sqlite.Open(\u0026#34;dbname.db\u0026#34;), \u0026amp;gorm.Config{})  GORM基本示例\r#\r\r创建数据库\r#\r\rcreate database \u0026lt;数据库名称\u0026gt; charset utf8mb4;  GORM操作数据库\r#\r\rpackage main import ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) // 1.定义模型 type UserInfo struct { gorm.Model Username string Password string MobilPhone uint Status bool RoleID uint } func main() { // 2.连接 MySQL 数据库 \tdsn := \u0026#34;root:Capjet.CN@tcp(10.0.0.100:3306)/testDB?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { panic(err) } // 3.把模型与数据库中的表对应起来 \tdb.AutoMigrate(\u0026amp;UserInfo{}) // 4.对数据库的增、删、改、查 }  GORM操作数据库之增\r#\r\rpackage main import ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) // 1.定义模型 type UserInfo struct { gorm.Model Username string Password string MobilPhone uint Status bool RoleID uint } func main() { // 2.连接 MySQL 数据库 \tdsn := \u0026#34;root:Capjet.CN@tcp(10.0.0.100:3306)/testDB?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { panic(err) } // 3.把模型与数据库中的表对应起来 \tdb.AutoMigrate(\u0026amp;UserInfo{}) // 4.创建记录 \t// 创建模型（结构体）实例 \tuser := UserInfo{Username: \u0026#34;HC\u0026#34;, Password: \u0026#34;123456\u0026#34;, MobilPhone: 13888888888, Status: true, RoleID: 1} // 在数据库中新增一条数据 \tdb.Create(\u0026amp;user) }  GORM操作数据库之查\r#\r\r一般查询\r#\r\rpackage main import ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) // 1.定义模型 type UserInfo struct { gorm.Model Username string Password string MobilPhone uint Status bool RoleID uint } func main() { // 2.连接 MySQL 数据库 \tdsn := \u0026#34;root:Capjet.CN@tcp(10.0.0.100:3306)/testDB?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) if err != nil { panic(err) } // 3.把模型与数据库中的表对应起来 \tdb.AutoMigrate(\u0026amp;UserInfo{}) // 4.一般查询 \tvar user UserInfo // 定义变量 user 为 UserInfo 类型  // 根据主键查询第一条记录 \tdb.First(\u0026amp;user) // 将查询到的结果写入到变量 user 中，因此 user 需要取地址  // 根据主键查询最后一条记录 \tdb.Last(\u0026amp;user) // 根据主键查询指定的某条记录(仅当主键为整型时可用) \tdb.First(\u0026amp;user, 100) // 查询所有的记录 \tvar users []UserInfo db.Find(\u0026amp;users) // 查看查询所用的SQL语句 \tdb.Debug().Find(\u0026amp;users) } 条件查询\r#\r\r参考：https://gorm.io/zh_CN/docs/query.html\n"},{"id":8,"href":"/docs/Linux/Basic-Operation/Nginx/","title":"Nginx","section":"Linux运维基础","content":"安装环境依赖\r#\r\r 安装PCRE\r#\r\r 检查PCRE是否安装\nrpm -qa pcre pcre-devel 安装PCRE和PCRE库（正则表达式兼容模块），一般来说安装pcre-devel即可\nyum install -y pcre pcre-devel  安装OpenSSL\r#\r\r 检查openssl是否安装\nrpm -qa openssl openssl-devel 安装openssl和openssl库（实现https访问），一般来说安装openssl-devel即可\nyum install -y openssl openssl-devel  安装其他依赖\r#\r\r yum install -y gcc gcc-c++ kernel-devel  安装Nginx\r#\r\r 检查Nginx是否安装\nrpm -qa nginx 进入opt目录\ncd /opt/ 下载Nginx安装包\nwget http://nginx.org/download/nginx-1.16.1.tar.gz 解压Nginx安装包\ntar -zxvf nginx-1.16.0.tar.gz 创建Nginx的软连接\nln -s /opt/nginx-1.16.0 /opt/nginx 进入Nginx文件夹\ncd /opt/Nginx 创建nginx用户和组\nuseradd nginx -M -s /sbin/nologin 检查创建的用户\nid nginx 查看configure可选参数\n./configure --help 指定安装路径、用户和所需模块\n./configure --prefix=/opt/Nginx --user=nginx --group=nginx --with-http_ssl_module --with-http_stub_status_module 编译及编译安装Nginx\nmake \u0026amp;\u0026amp; make install 检查安装\necho $? 防火墙开启80端口\nfirewall-cmd --zone=public --add-port=80/tcp --permanent firewall-cmd --reload  启动Nginx\r#\r\r 检查Nginx语法\n/opt/Nginx/sbin/nginx -t 启动Nginx服务\n/opt/Nginx/sbin/nginx 重启Nginx服务\n/opt/Nginx/sbin/nginx -s reload 停止Nginx服务\n/opt/Nginx/sbin/nginx -s stop  Nginx目录结构\r#\r\r   目录 目录作用 目录中重要文件 文件作用   html 站点目录（分类管理网站内容） 无 无   logs 日志文件 错误日志 记录错误信息   访问日志 记录访问信息   进程PID 判断Nginx有没有启动   sbin 程序命令 nginx 启动服务命令：nginx   停止服务命令：nginx -s stop   平滑重启服务命令：nginx -s reload   检查语法：nginx -t    Nginx配置文件\r#\r\r  Nginx安装目录下的conf中的nginx.conf为配置文件\n  Nginx配置域名\r#\r\r server{……}区块中的server_name，是配置域名的参数\n Nginx配置站点目录\r#\r\r server{……}区块下location /{……}区块中的root，是配置站点目录的参数\n Nginx配置静态页面\r#\r\r server{……}区块下location /{……}区块中的index，是配置静态页面的参数\n Nginx配置多个虚拟主机\r#\r\r  所谓虚拟主机，在Web服务里就是一个独立的网站站点，这个站点对应独立的域名（也可能是IP或端口），具有独立的程序及资源目录，可以独立地对外提供服务。\n这个独立的站点在配置里是由一定格式的标签段标记的，对于Apache软件来说，一个虚拟主机的标签段通常被包含在内，而Nginx软件则使用一个server{}标签来表示一个虚拟主机。一个Web服务里可以有多个虚拟主机标签对，即可以同时支持多个虚拟主机站点。\n常见的虚拟主机有如下几种类型：\n  基于域名的虚拟主机\n  基于端口的虚拟主机\n  基于IP的虚拟主机（只要配置文件涉及IP地址修改，不能平滑重启，必须真正重启Nginx）\n  配置方法：\n  修改配置文件，一个server{……}区块就是一个虚拟主机\n  创建站点目录\n  检查配置文件语法\n  重启nginx服务\n    常见问题总结\r#\r\r 403错误出现的原因：\n 配置了禁止访问 指定站点目录下没有首页文件 编译安装pcre软件时，gcc不全导致报错  无法访问Nginx\n 关闭SELinux 关闭防火墙   Nginx企业扩展功能应用\r#\r\r  规范虚拟主机配置文件\n  生成虚拟主机文件及虚拟主机文件保存目录，将不同虚拟主机拆分成多个文件，放在一个目录中\n# 将nginx.conf中10行到16行的内容重定向到ectra_conf/www.conf中 sed -n \u0026#39;10,16p\u0026#39; nginx.conf \u0026gt;ectra_conf/www.conf # 将nginx.conf中17行到22行的内容重定向到ectra_conf/bbs.conf中 sed -n \u0026#39;17,22p\u0026#39; nginx.conf \u0026gt;ectra_conf/bbs.conf # 将nginx.conf中23行到28行的内容重定向到ectra_conf/blog.conf中 sed -n \u0026#39;18,28p\u0026#39; nginx.conf \u0026gt;ectra_conf/blog.conf #将nginx.conf中的server{……}区块删除，使用incloude调用配置文件 使用虚拟主机别名功能，通过负载均衡访问指定的Web服务器\n#配置Nginx虚拟主机配置文件 在server{……}区块中的server_name参数中加入别名  Nginx状态信息功能\r#\r\r Nginx status介绍\r#\r\r Nginx软件功能模块中有一个ngx_http_stub_status_module模块，这个模块得主要功能是记录Nginx的基本访问状态信息，让使用者了解Nginx的工作状态，例如：连接数信等信息。要使用状态模块，再编译Nginx时必须增加http_stub_status_module模块来支持。\n可通过如下方法检查编译安装Nginx时是否设定了上述模块：\n# 检查编译安装时设置的编译参数 /opt/Nginx/sbin/nginx -V  "},{"id":9,"href":"/docs/Python/Python%E4%B9%8B%E5%90%8D%E7%A7%B0%E7%A9%BA%E9%97%B4%E4%B8%8E%E4%BD%9C%E7%94%A8%E5%9F%9F/","title":"Python之名称空间与作用域","section":"Python","content":"名称空间\r#\r\r 名称空间(Namespace)是从名称到对象的映射，大部分的命名空间都是通过 Python 字典来实现的。\n名称空间提供了在项目中避免名字冲突的一种方法。各个命名空间是独立的，没有任何关系的，所以一个命名空间中不能有重名，但不同的命名空间是可以重名而没有任何影响。\nPython中存在三种名称空间：\n 内置名称空间：Python内置名称，如内置函数：print、hash、input和异常名称BaseException、Exception等等。 全局名称空间：模块中定义的名称，记录了模块的变量，包括函数、类、其它导入的模块、模块级的变量和常量。即一个python文件中的所有名称。 局部名称空间：函数中定义的名称，记录了函数的变量，包括函数的参数和局部定义的变量（类中定义的也是如此）。局部名称空间是一个临时的名称空间，调用函数或类的时后产生，函数或类内部的代码执行完毕后，局部名称空间随着函数或类的结束而消失。   名称空间的顺序\r#\r\r 名称空间的加载顺序：内置名称空间 -\u0026gt; 全局名称空间 -\u0026gt; 局部名称空间（执行函数时）\n名称空间的取值顺序：局部空间 -\u0026gt; 全局名称空间 -\u0026gt; 内置名称空间。遵循就近取值原则\n 作用域\r#\r\r 作用域就是一个 Python 程序可以直接访问名称空间的区域。\nPython 中存在两种作用域：\n 全局作用域：内置名称空间 + 全局名称空间。使用globals() 函数会以字典类型返回当前位置的全部全局变量。 局部作用域：局部名称空间。使用locals() 函数会以字典类型返回当前位置的全部局部变量。   作用域的访问规则\r#\r\r Python 中，程序的变量并不是在哪个位置都可以访问的，访问权限决定于这个变量是在哪里赋值的。局部作用域可以访问全局作用域的变量，但不能修改全局作用域的变量（可变数据类型，例如列表、字典等可以更改），而全局作用域的变量不能访问局部作用域的变量。\n 全局变量与局部变量的转换\r#\r\r global：将局部变量转换成全局变量，并且可以修改全局变量。\ndef func(): name = \u0026#39;Python\u0026#39; print(name) # 可以打印 func() print(name)\t# 报错！在全局作用域中找不到局部作用域中的变量 # 使用global声明，将局部变量转换成全局变量 def func(): global name name = \u0026#39;Python\u0026#39; print(name) func() print(name)\t# 可以打印，通过global name将name变为了全局变量。 # 使用global声明，在函数内部修改全局变量 count = 1 def func(): global count count += 1 print(count)\t# 输出结果：1 func() print(count)\t# 输出结果：2  nonlocal：不能操作全局变量。用于局部作用域中内层函数对外层函数的局部变量进行修改。\ndef outer(): count = 1 def inner(): nonlocal count\t# 使用nonlocal将内层函数局部变量count声明成外层函数的局部变量 count += 1 print(count)\t# 输出结果：1 inner() print(count)\t# 输出结果：2 outer()  常见错误示例\r#\r\r 在函数中可以使用全局作用域的变量，但不能改变。\ncount = 1 def func(): count += 1 print(count) func() # 输出结果：UnboundLocalError: local variable \u0026#39;count\u0026#39; referenced before assignment  在一个函数中，如果引用了全局作用域的的变量后，再进行同名变量的定义赋值，解释器会认为局部作用域修改全局作用域的变量，会报错。\ncount = 1 def func(): print(count) count = 2 func() # 输出结果：UnboundLocalError: local variable \u0026#39;count\u0026#39; referenced before assignment "},{"id":10,"href":"/docs/Python/Python%E4%B9%8B%E5%87%BD%E6%95%B0/","title":"Python之函数","section":"Python","content":"什么是函数\r#\r\r 函数是组织好的，可重复使用的，用来实现单一或相关联功能的代码段。\n 为什么要用函数\r#\r\r 函数能提高应用的模块性和代码的重复利用率。\n 如何定义函数\r#\r\r 函数代码块以 def 关键词开头，后接函数标识符名称和圆括号()，圆括号之间可以用于定义参数；\n函数内容以冒号起始，并且缩进；\n函数的第一行语句一般使用多行注释来阐述函数的作用；\nreturn [表达式]结束函数，选择性地返回一个值给调用方。返回值可以是单个值，也可以是被元组包裹的多个值，不带表达式的return相当于返回None。\n函数内尽量避免使用print()。\ndef func(): \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass  函数的调用\r#\r\r 当定义一个函数后，函数内的所有代码都不会执行，只有调用函数时函数才会被执行\ndef func(): \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func()\t# 只有调用函数的时候，函数内的代码才会执行  函数的参数\r#\r\r 函数的参数分为实参和形参，实参是调用函数时传入的参数，形参是定义函数时定义的参数。\ndef func(a):\t# a就是形参 \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func(\u0026#39;实参\u0026#39;)  函数的实参分为3种：位置实参、关键字实参和混合实参。\n 位置实参：安照顺序传值，从左到右，与形参一一对应\ndef func(a, b):\t# a = 1，b = 2 \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func(1, 2)\t# 位置形参安照顺序传值，从左到右，与形参一一对应  关键字实参：按照关键字对形参进行传值\ndef func(a, b, c):\t# a = 1, b = 2, c = 3 \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func(c=3, a=1, b=2)\t# 按照关键字对形参进行传值  混合实参：位置实参与关键实参混合使用，关键字实参一定要放在位置实参之后\ndef func(a, b, c, d):\t# a = 1, b = 2, c = 3, d = 4 \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func(1, 2, d=4, c=3)\t# 当使用混合参数时，关键字实参一定要放在位置实参之后  函数的形参分为4种：位置形参、默认形参、仅限关键字形参和万能形参\n 位置形参：按照位置从左到右接收实参传入的对象。\n 默认形参：将经常使用的参数，设置一个默认值，调用函数的时候，可以省略给默认形参传值。\ndef func(a, b, c=3):\t# c = 3 就是默认形参 \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func(1, 2) # 默认参数的陷阱 count = 1 def func(a,b=[]): b.append(a) return b ret1 = func(10) print(ret1)\t# [10] ret2 = func(20) print(ret2)\t# [10, 20] # 如果函数中的默认参数是一个可变数据类型，那么无论调用多少次这个函数，使用的都是同一个内存地址的数据。 count = 1 def func(a,b=[]): b.append(a) return b ret1 = func(10) ret2 = func(20) print(ret1)\t# [10, 20] print(ret2)\t# [10, 20]  仅限关键字形参：当希望函数的某些参数强制使用关键字参数时，可以将强制关键字参数放到某个*后面就能得到这种效果\n 万能形参：可以接收任何形式的参数\ndef func(*args, **kwargs): \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; pass func(1, \u0026#39;任意值\u0026#39;, c=[2,3], d=4) 万能形参之所以可以接收任何形式的参数，奥秘在于变量args前面的*和变量kwargs前面的**;\n在定义函数时，args前面的*可以聚合传入的一切位置实参，将传入的所有位置实参生成一个元组；而kwargs前面的**可以聚合传入的一切关键字实参，将传入的所有关键字实参生成一个字典。\ndef func(*args, **kwargs): \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; print(args)\t# args = (1, \u0026#39;任意值\u0026#39;) print(kwargs) kwargs = {\u0026#39;c\u0026#39;: [2, 3], \u0026#39;d\u0026#39;: 4} func(1, \u0026#39;任意值\u0026#39;, c=[2,3], d=4) 在调用函数时，使用*则会打散位置实参传入的一切可迭代对象，并生成一个元组；使用**会将字典打散后聚合成一个字典。\ndef func(*args, **kwargs): \u0026#39;\u0026#39;\u0026#39; 描述一下这个函数是干什么的 :return: \u0026#39;\u0026#39;\u0026#39; print(args)\t# (1, \u0026#39;任\u0026#39;, \u0026#39;意\u0026#39;, \u0026#39;值\u0026#39;, 2, 3, 4, 5) print(kwargs)\t# {\u0026#39;a\u0026#39;: 6, \u0026#39;b\u0026#39;: 7} func(1, *\u0026#39;任意值\u0026#39;, *[2,3], *(4,5), **{\u0026#39;a\u0026#39;:6}, **{\u0026#39;b\u0026#39;:7})  形参的顺序：位置参数，*args，默认参数，仅限关键字参数，**kwargs。\n  函数的名称\r#\r\r 函数名指向的是函数的内存地址\ndef func(): print(\u0026#39;函数变量名\u0026#39;) print(func)\t# 输出结果： \u0026lt;function func at 0x000001797CDD93A0\u0026gt;  函数名本质上就是一个变量\ndef func1(): print(\u0026#39;func1\u0026#39;) def func2(): print(\u0026#39;func2\u0026#39;) func1 = func2 func1()\t# 输出结果：func2  函数名可以作为容器数据类型（元组、列表、字典等）的元素\ndef func1(): print(\u0026#39;func1\u0026#39;) def func2(): print(\u0026#39;func2\u0026#39;) def func3(): print(\u0026#39;func3\u0026#39;) l = [func1, func2, func3] for i in l: i() \u0026#39;\u0026#39;\u0026#39; 输出结果: func1 func2 func3 \u0026#39;\u0026#39;\u0026#39;  函数名可以作为函数的参数\ndef func1(): print(\u0026#39;func1\u0026#39;) def func2(x): x() print(\u0026#39;func2\u0026#39;) func2(func1) \u0026#39;\u0026#39;\u0026#39; 输出结果: func1 func2 \u0026#39;\u0026#39;\u0026#39;  函数名可以作为函数的返回值\ndef func1(): print(\u0026#39;func1\u0026#39;) def func2(x): print(\u0026#39;func2\u0026#39;) return x ret = func2(func1) ret() \u0026#39;\u0026#39;\u0026#39; 输出结果： func2 func1 \u0026#39;\u0026#39;\u0026#39;  三元运算\r#\r\r 如果一个函数中有且仅有一个 if...else 条件判断语句，那么这个函数可以简写成如下的三元运算：\na = 1 b = 2 if a \u0026gt; b: c = a else: c = b # 可以简写成： a = 1 b = 2 c = a if a \u0026gt; b else b # 写比较两个值大小的函数，输出较大的值 def func(a, b): if a \u0026gt; b: return a else: return b ret = func(1,2) print(ret) # 使用三元运算可以写成如下形式： def func(a, b): return a if a \u0026gt; b else b ret = func(1,2) print(ret)  匿名函数\r#\r\rlambda（匿名函数）就是一句话函数，使用lambda关键字创建匿名函数，函数冒号前面的是形参，冒号后面的表达式有且只能有一个。匿名函数自带return，而return的结果就是表达式的计算后的结果。\n# 普通函数 def func(a, b): return a + b func(1,2)\t# 输出结果：3 # 匿名函数 func = lambda a, b: a + b print(func(1,2))\t# 输出结果：3 # 匿名函数与三元表达式结合 func = lambda a, b: print(a) if a \u0026gt; b else print(b) func(1,2)\t# 输出结果：2  内置函数\r#\r\r Python将一些常用的功能封装成了内置函数，需要直接调用，避免了重复造轮子的过程。\n \rPython标准库中的内置函数（点击查看）\n 以下介绍一些常用的内置函数：\neval()将字符串内的表达式拿出来运行一下，并拿到该表达式的运行结果。在网络传输、用户输入和SQL注入时绝对不要使用！有可能会遭到黑客攻击！\ns_1 = \u0026#39;1 + 2\u0026#39; s_2 = \u0026#39;{\u0026#34;a\u0026#34;:1, \u0026#34;b\u0026#34;:2}\u0026#39; print(eval(s_1))\t# 3 print(eval(s_2))\t# {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2}  exec()与eval()相似都会执行储存在字符串或文件中的 Python 语句，但exec()用于处理字符串中的代码流。\nmsg = \u0026#39;\u0026#39;\u0026#39; for i in range(10): print(i) \u0026#39;\u0026#39;\u0026#39; exec(msg)\t# 会执行msg中的代码  min():返回给定参数的最小值，参数可以为序列。\n# 求出dic中最小的值 dic = {\u0026#39;a\u0026#39;:1,\u0026#39;b\u0026#39;:2,\u0026#39;c\u0026#39;:3} result = min(dic,key=lambda value: dic[value]) print(result)  max()：返回给定参数的最大值，参数可以为序列。\n sorted()：对所有可迭代的对象进行排序操作。\n# 求出sults_list中的人按照成绩从高到低进行排序 sults_list = [(\u0026#39;a\u0026#39;, 72), (\u0026#39;b\u0026#39;, 83), (\u0026#39;c\u0026#39;, 98), (\u0026#39;d\u0026#39;, 92)] result = sorted(sults_list, key=lambda value: value[1], reverse=True) print(result)\t# [(\u0026#39;c\u0026#39;, 98), (\u0026#39;d\u0026#39;, 92), (\u0026#39;b\u0026#39;, 83), (\u0026#39;a\u0026#39;, 72)]  filter()：用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。\n# 筛选出列表l中大于5的数字 l = [2,4,5,7,3,9,6,8] # print([i for i in l if i \u0026gt; 3]) # 通过列表推导式也可以筛选出来 # filter()循环列表l，将l中的每个元素放到lambda函数中，var \u0026gt; 3 为True的留下。 result = filter(lambda var: var \u0026gt; 3, l) # 返回的是迭代器 print(list(result)) # [4, 5, 7, 9, 6, 8]  map()：会根据提供的函数对指定序列做映射。\n# 计算列表中各个元素的平方 l = [2,4,5,7,3,9,6,8] result = map(lambda var: var ** 2, l) print(list(result)) # [4, 16, 25, 49, 9, 81, 36, 64]  abs()：取绝对值\n all()：括号中传入可迭代的对象，在传入的可迭代对象当中的所有值都为Ture，返回的布尔值才为Ture；如果可迭代的对象为空，则返回Ture。\n any()：括号中传入可迭代的对象，在传入的可迭代对象中只要有一个值为Ture，返回的布尔值就为Ture；如果可迭代的对象为空，则返回False。\n bin()：将十进制转换成二进制。\n oct()：将十进制转换成八进制。\n hex()：将十进制转换成16进制。\n bool()：制造布尔值，其中0、None、空为False。\n bytes()：制造bytes类型\nres = ‘Hello’.encoding(\u0026#39;utf-8\u0026#39;) 等同于 res = bytes（‘Hello’,encoding=\u0026#39;utf-8\u0026#39;）  callable()：判断一个对象是否可以调用\n chr()：把数字按照ascii码表转成字符。\n ord() ：把字符按照ascii码表转换成数字。\n dir()：查看（）内对象能够通过.调用哪些方法。\n divmod(x,y)：计算x除以y的商与余\n enumerate()：用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据序号，一般用在 for 循环当中。\n globals()：查看全局作用域中的名字与值的绑定关系。\n locals()：查看局部作用域中的名字与值的绑定关系。\n hash()：检测数据类型是可变还是不可变；可hash的类型相当于不可变的类型，不可hash的类型相当于可变类型。\n help()：查看函数的帮助信息。\n id()：用于获取对象的内存地址。\n len()：返回对象（字符、列表、元组等）长度或项目个数。\n iter()：相当于.iter()\n next()： 相当于.next()\n open()；用于打开一个文件，创建一个file对象，相关的方法才可以调用它进行读写。\n pow()：pow(x,y,z) 表示x的y次方对z取余.\n range()：可创建一个整数列表，一般用在 for 循环中。\n reversed()：返回一个反转的迭代器。\n round() ： 四舍五入。\n slice()：实现切片对象，主要用在切片操作函数里的参数传递。\n sum()：进行求和计算.\n vars()：如果不传值等同于locals(),传值后等同于object.dict\n zip()：拉链函数，函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的对象，这样做的好处是节约了不少的内存。可以使用 list() 转换来输出列表。如果各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 ***** 号操作符，可以将元组解压为列表。\ns = \u0026#39;ABCDEF\u0026#39; tu = (\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;d\u0026#39;,\u0026#39;e\u0026#39;) l = [1,2,3,4] obj = zip(s,tu,l) print(obj)\t# \u0026lt;zip object at 0x00000241044AFD00\u0026gt; print(list(obj))\t# [(\u0026#39;A\u0026#39;, \u0026#39;a\u0026#39;, 1), (\u0026#39;B\u0026#39;, \u0026#39;b\u0026#39;, 2), (\u0026#39;C\u0026#39;, \u0026#39;c\u0026#39;, 3), (\u0026#39;D\u0026#39;, \u0026#39;d\u0026#39;, 4)]  面向对象里的重点内置函数：\n  classmethod() staticmethod() property() delattr() hasattr() getattr() setattr() isinstance() issubclass() object() super()   注意：凡是有默认形参key=None的内置函数，将key赋值后key=函数名称，它会自动将可迭代对象的每一个元素按照顺序传入key的函数中\n  高阶函数\r#\r\r 函数在Python中是第一类对象，第一类对象的特性有：\n可以被引用\ndef bar(): print(\u0026#39;form bar\u0026#39;) f = bar  可以当做参数传入\ndef bar(): print(\u0026#39;form bar\u0026#39;) def wrapper(func): func() wrapper(bar)  可以当做函数的返回值\ndef bar(): print(\u0026#39;form bar\u0026#39;) def foo(func): return func f = foo(bar) print(f)  可以当作容器类型的元素\ndef get(): print(\u0026#39;form get\u0026#39;) def put(): print(\u0026#39;form get\u0026#39;) l = [get,put] l[0]() l[1]()  Python中函数为什么可以嵌套或者调用？因为在Python中一切皆对象！\n  开放封闭原则\r#\r\r 开放封闭原则是指对功能的拓展是开放的，对源码的修改是封闭的。\n 闭包函数\r#\r\r 闭包函数是一种函数的嵌套，当内层函数引用或使用外层函数的非全局变量时就会产生闭包，被引用的外层非全局变量称之为自由变量，这个自由变量会与内层函数产生绑定关系，故而自由变量不会随着函数的执行完毕消失。闭包主要用于保证函数的安全。\n 装饰器\r#\r\r 在不改变原函数代码、调用方式以及返回值的前提下，为其增加新功能，这就是装饰器。装饰器本质是闭包函数，装饰器遵循开放封闭原则。\ndef func_1(name): \u0026#39;\u0026#39;\u0026#39; 这是一个实现某个功能函数，内部拥有大量的代码，使用pass代替 :return: \u0026#39;\u0026#39;\u0026#39; pass time.sleep(1) # 模拟函数执行的时间 print(F\u0026#39;func_1执行完毕！参数为：{name}\u0026#39;) return 1 def func_2(name_1,name_2): \u0026#39;\u0026#39;\u0026#39; 这是一个实现某个功能函数，内部拥有大量的代码，使用pass代替 :return: \u0026#39;\u0026#39;\u0026#39; pass time.sleep(2) # 模拟函数执行的时间 print(F\u0026#39;func_2执行完毕！，参数为：{name_1}，{name_2}\u0026#39;) return 2 # 将func_1和func_2加入计算运行时间的功能。要求：不改变原函数代码以及调用方式 import time # 导入时间模块 def omputation_time(var): # 定义一个新功能的函数 \u0026#39;\u0026#39;\u0026#39; 这是一个计算运行时间的函数 :param args: :return: \u0026#39;\u0026#39;\u0026#39; # var = func_1 # var = func_2 def inner(*args,**kwargs): # 为了不改变被装饰函数的调用方式，需要再定义一个内部函数 start_time = time.time() ret = var(*args,**kwargs)\t# 调用函数时，*会将传入的元组打散 end_time = time.time() print(f\u0026#39;函数执行用时：{end_time - start_time}\u0026#39;) return ret # 将被装饰函数的返回值返回给omputation_time，确保被装饰函数的返回值不变 return inner # 返回inner()的函数名 # func_1 = omputation_time(func_1) @omputation_time # 语法糖会将下面func_1函数名作为参数传入到omputation_time(args)函数中 def func_1(name): \u0026#39;\u0026#39;\u0026#39; 这是一个实现某个功能函数，内部拥有大量的代码，使用pass代替 :return: \u0026#39;\u0026#39;\u0026#39; pass time.sleep(1) # 模拟函数执行的时间 print(F\u0026#39;func_1执行完毕！参数为：{name}\u0026#39;) return 1 ret_1 = func_1(\u0026#39;parameter\u0026#39;) # 调用函数传入参数,并获取返回值 print(ret_1) \u0026#39;\u0026#39;\u0026#39; 执行结果： func_1执行完毕！参数为：parameter 函数执行用时：1.0006012916564941 1 \u0026#39;\u0026#39;\u0026#39; @omputation_time # 语法糖会将下面func_2函数名作为参数传入到omputation_time(args)函数中 def func_2(name_1,name_2): \u0026#39;\u0026#39;\u0026#39; 这是一个实现某个功能函数，内部拥有大量的代码，使用pass代替 :return: \u0026#39;\u0026#39;\u0026#39; pass time.sleep(2) # 模拟函数执行的时间 print(F\u0026#39;func_2执行完毕！，参数为：{name_1}，{name_2}\u0026#39;) return 2 func_2(\u0026#39;parameter_1\u0026#39;, \u0026#39;parameter_2\u0026#39;) # 调用函数传入参数,并获取返回值 \u0026#39;\u0026#39;\u0026#39; 执行结果： func_2执行完毕！，参数为：parameter_1，parameter_2 函数执行用时：2.0002026557922363 \u0026#39;\u0026#39;\u0026#39;  装饰器的标准语法\ndef wapper(f): # f表示被装饰的函数名传入时的形参 def inner(*args, **kwargs): # 定义函数阶段*args, **kwargs会将被装饰函数的参数聚合 pass # 可以添加任意代码，完成调用函数之前的功能 ret = f(*args, **kwargs) # 调用函数阶段*args, **kwargs会将被装饰函数的参数打散 pass # 可以添加任意代码，完成调用函数之后的功能 return ret # 返回被装饰函数的执行后的返回值 return inner()  带参数的装饰器\r#\r\r 在装饰器的外面再套一层函数。\ndef outter(*args) # 此时就可以任意使用*args传进来的参数了，也可以用一个变量接收*args，a = *args def wapper(f): # f表示被装饰的函数名传入时的形参 def inner(*args, **kwargs): # 定义函数阶段*args, **kwargs会将被装饰函数的参数聚合 pass # 可以添加任意代码，完成调用函数之前的功能 ret = f(*args, **kwargs) # 调用函数阶段*args, **kwargs会将被装饰函数的参数打散 pass # 可以添加任意代码，完成调用函数之后的功能 return ret # 返回被装饰函数的执行后的返回值 return inner return wapper  装饰器的应用\r#\r\r 多用于登录认证\nimport time user_info = {} def wapper(f): def inner(*args, **kwargs): if user_info.get(\u0026#39;login_status\u0026#39;): ret = f(*args, **kwargs) return ret else: login() return inner def login(): count = 0 while count \u0026lt; 3: print(\u0026#39;*用户登录*\u0026#39;.center(50, \u0026#39;=\u0026#39;)) user_input_name = input(\u0026#39;请输入登录用户名：\u0026#39;.strip()) user_input_password = input(\u0026#39;请输入登录用户密码：\u0026#39;.strip()) if user_input_name == user_info.get(\u0026#39;user_name\u0026#39;,\u0026#39;没有此用户名\u0026#39;) and \\ user_input_password == user_info.get(\u0026#39;user_password\u0026#39;, \u0026#39;没有此密码\u0026#39;): user_info.update(login_status = True) # print(user_info) print(\u0026#39;登录成功！\u0026#39;) break else: print(\u0026#39;登录失败！请重新登录\u0026#39;) count += 1 def register(): while 1: print(\u0026#39;*用户注册*\u0026#39;.center(50, \u0026#39;=\u0026#39;)) user_name = input(\u0026#39;请输入需要注册用户名：\u0026#39;).strip() user_password = input(\u0026#39;请输入登陆密码：\u0026#39;).strip() user_password_cofirm = input(\u0026#39;请再次输入登录密码：\u0026#39;).strip() if user_name.isalnum(): if user_password == user_password_cofirm: user_info.update(user_name = user_name, user_password = user_password, login_status = False ) print(\u0026#39;注册成功！\u0026#39;) break else: print(\u0026#39;两次输入的密码不一致，请重新输入\u0026#39;) continue else: print(\u0026#39;用户名只能由字母或数字组成，请重新输入！\u0026#39;) @wapper def my_cart(): print(f\u0026#39;您已成功访问购物车！\u0026#39;) time.sleep(3) @wapper def personal(): print(f\u0026#39;您已成功访问个人中心！\u0026#39;) time.sleep(3) def index(): while 1: print(\u0026#39;*首页*\u0026#39;.center(50, \u0026#39;=\u0026#39;)) print(f\u0026#39;{user_info.get(\u0026#34;user_name\u0026#34;), user_info.get(\u0026#34;login_status\u0026#34;)}\u0026#39;) print(\u0026#39;\u0026#39;\u0026#39; 1. 用户登录 2. 用户注册 3. 购物车 4. 个人中心 5. 退出程序 \u0026#39;\u0026#39;\u0026#39;) user_choice = input(\u0026#39;请您输入相关功能序号：\u0026#39;.strip()) if user_choice.isdecimal(): if user_choice == \u0026#39;1\u0026#39;: login() elif user_choice == \u0026#39;2\u0026#39;: register() elif user_choice == \u0026#39;3\u0026#39;: my_cart() elif user_choice == \u0026#39;4\u0026#39;: personal() elif user_choice == \u0026#39;5\u0026#39;: break else: print(\u0026#39;输入错误，请重新输入！\u0026#39;) \u0026#39;\u0026#39;\u0026#39; 使用装饰器完成功能： 访问 my_cart() 和 personal() 之前对对用户进行认证，认证成功可以访问，认证不成功不得访问 \u0026#39;\u0026#39;\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: index()  递归函数\r#\r\r 如果一个函数在内部调用函数本身，这个函数就是递归函数。递归实际上时两个过程，一个递的过程，和一个归的过程。\ncount = 0 def func(): global count count += 1 print(count) func() print(\u0026#39;Hey!\u0026#39;) func()  Python递归函数的深度，官方设置的最大深度是1000层。但C语言中递归没有限制。\n通过sys.setrecursionlimit(n)可以修改递归的最大深度。但日常开发时不要修改默认最大深度。\n使用递归函数要尽量控制递归的深度，需要很多层递归才能解决的问题，就需要考虑使用递归函数是否适用。\n递归和循环的关系：递归比循环更占用内存，如果能不使用递归尽量不要使用递归。\n  要想结束一个递归函数，必须在递归函数内加上一个可达到的条件，然后执行return。\ncount = 0 def func(): global count count += 1 print(count) if count == 3: return func() print(\u0026#39;Hey!\u0026#39;) func() \u0026#39;\u0026#39;\u0026#39; 执行结果： 1 2 3 Hey! Hey! \u0026#39;\u0026#39;\u0026#39; # 想一想为什么会有两个Hey!  递归函数的传参\ndef func(count): count += 1 print(count) if count == 5: return count ret = func(count) print(\u0026#39;count:\u0026#39;, ret) func(0) \u0026#39;\u0026#39;\u0026#39; 输出结果： 1 2 3 4 5 count: 5 count: None count: None count: None \u0026#39;\u0026#39;\u0026#39;  递归函数的返回值\ndef func(count): count += 1 print(count) if count == 3: return count ret = func(count) return ret func(0) \u0026#39;\u0026#39;\u0026#39; 输出结果： 1 2 3 \u0026#39;\u0026#39;\u0026#39;  计算n的阶乘\n# 使用循环 def factorial(n): for i in range(1,n): n = n * i print(n) # 使用递归 def factorial(n): if n == 1: return n else: return n * factorial(n-1)  "},{"id":11,"href":"/docs/Python/Python%E4%B9%8B%E8%BF%AD%E4%BB%A3%E5%99%A8/","title":"Python之迭代器","section":"Python","content":"可迭代对象\r#\r\r 内部含有__iter__方法的对象，称之为可迭代对象。\n 通过dir()获取一个对象内部的所有方法\ns = \u0026#39;Python\u0026#39; print(dir(s))\t# 返回对象s内部的所有方法 \u0026#39;\u0026#39;\u0026#39; 输出结果： [\u0026#39;__add__\u0026#39;, \u0026#39;__class__\u0026#39;, \u0026#39;__contains__\u0026#39;, \u0026#39;__delattr__\u0026#39;, \u0026#39;__dir__\u0026#39;, \u0026#39;__doc__\u0026#39;, \u0026#39;__eq__\u0026#39;, \u0026#39;__format__\u0026#39;, \u0026#39;__ge__\u0026#39;, \u0026#39;__getattribute__\u0026#39;, \u0026#39;__getitem__\u0026#39;, \u0026#39;__getnewargs__\u0026#39;, \u0026#39;__gt__\u0026#39;, \u0026#39;__hash__\u0026#39;, \u0026#39;__init__\u0026#39;, \u0026#39;__init_subclass__\u0026#39;, \u0026#39;__iter__\u0026#39;, \u0026#39;__le__\u0026#39;, \u0026#39;__len__\u0026#39;, \u0026#39;__lt__\u0026#39;, \u0026#39;__mod__\u0026#39;, \u0026#39;__mul__\u0026#39;, \u0026#39;__ne__\u0026#39;, \u0026#39;__new__\u0026#39;, \u0026#39;__reduce__\u0026#39;, \u0026#39;__reduce_ex__\u0026#39;, \u0026#39;__repr__\u0026#39;, \u0026#39;__rmod__\u0026#39;, \u0026#39;__rmul__\u0026#39;, \u0026#39;__setattr__\u0026#39;, \u0026#39;__sizeof__\u0026#39;, \u0026#39;__str__\u0026#39;, \u0026#39;__subclasshook__\u0026#39;, \u0026#39;capitalize\u0026#39;, \u0026#39;casefold\u0026#39;, \u0026#39;center\u0026#39;, \u0026#39;count\u0026#39;, \u0026#39;encode\u0026#39;, \u0026#39;endswith\u0026#39;, \u0026#39;expandtabs\u0026#39;, \u0026#39;find\u0026#39;, \u0026#39;format\u0026#39;, \u0026#39;format_map\u0026#39;, \u0026#39;index\u0026#39;, \u0026#39;isalnum\u0026#39;, \u0026#39;isalpha\u0026#39;, \u0026#39;isascii\u0026#39;, \u0026#39;isdecimal\u0026#39;, \u0026#39;isdigit\u0026#39;, \u0026#39;isidentifier\u0026#39;, \u0026#39;islower\u0026#39;, \u0026#39;isnumeric\u0026#39;, \u0026#39;isprintable\u0026#39;, \u0026#39;isspace\u0026#39;, \u0026#39;istitle\u0026#39;, \u0026#39;isupper\u0026#39;, \u0026#39;join\u0026#39;, \u0026#39;ljust\u0026#39;, \u0026#39;lower\u0026#39;, \u0026#39;lstrip\u0026#39;, \u0026#39;maketrans\u0026#39;, \u0026#39;partition\u0026#39;, \u0026#39;replace\u0026#39;, \u0026#39;rfind\u0026#39;, \u0026#39;rindex\u0026#39;, \u0026#39;rjust\u0026#39;, \u0026#39;rpartition\u0026#39;, \u0026#39;rsplit\u0026#39;, \u0026#39;rstrip\u0026#39;, \u0026#39;split\u0026#39;, \u0026#39;splitlines\u0026#39;, \u0026#39;startswith\u0026#39;, \u0026#39;strip\u0026#39;, \u0026#39;swapcase\u0026#39;, \u0026#39;title\u0026#39;, \u0026#39;translate\u0026#39;, \u0026#39;upper\u0026#39;, \u0026#39;zfill\u0026#39;] \u0026#39;\u0026#39;\u0026#39;  判断一个对象是不是一个可迭代对象（检查一个对象中是否含有__iter__方法）\ns = \u0026#39;Python\u0026#39; print(\u0026#39;__iter__\u0026#39; in dir(s)) # 返回 True 即为可迭代对象  可迭代对象的优缺点\n优点：\n 存储的数据可以直观的显示出来 内置的方法较多  缺点：\n 占用内存 不能一个一个的直接取值（for循环通过内部迭代器转化后才实现的直接取值）   迭代器\r#\r\r 内部含有__iter__和__next__方法的对象就是迭代器，也正是因为有__next__方法，才使得可迭代对象可以通过for循环直接取值。\n 迭代器的作用\r#\r\r 迭代是Python中最强大的功能之一，当处理一个远大于内存容量的数据时，需要找到一种节省内存的惰性获取数据项的方式，即按需一次获取一个数据项，以达到节省内存的作用，这就是迭代器模式。\n 判断一个对象是不是一个迭代器\r#\r\r 判断一个对象是不是一个迭代器，可以检查一个对象中是否同时含有__iter__和__next__方法\nwith open(r\u0026#39;file_path\u0026#39;, mode=\u0026#39;r\u0026#39;) as f: print(\u0026#39;__iter__\u0026#39; in dir(f) and \u0026#39;__next__\u0026#39; in dir(f)) # 返回 True 即为迭代器 将可迭代对象转化成迭代器\r#\r\r 通过内置函数iter()将可迭代对象转化成迭代器，也可以通过可迭代对象.__iter__()的方式进行转化\n 迭代器的取值\r#\r\r 通过内置函数next()可以对一个迭代器取值，一个next()取一个值，也可以通过可迭代对象.__next__()的方式取值\n 迭代器的优缺点\r#\r\r 优点：\n 惰性机制，next()一次，取一个值，绝不多取，因此非常节省内存  缺点：\n 速度慢，以时间换空间 单向取值时不能反向取值   可迭代对象与迭代器的区别\r#\r\r 可迭代对象的操作方法较多，存储的数据能够直观的全部显示出来的一个数据集；当侧重于对数据可以灵活处理，并且内存空间足够（8G内存大约能够支撑可迭代对象中的几百万个数据），将数据集设置为可迭代对象是很好的选择。\n迭代器是一个只有next()方法，存储的数据不能直观的全部显示出来的一个数据集，当数据集中的数据量过于庞大，超出了内存可以使用的范围时，或不确定数据集中的数据量的时候，将数据集设置为迭代器是很好的选择。这就是文件句柄为什么设置为迭代器的原因。\n while循环模拟for循环的机制\r#\r\r 方式一：\nl = [1,2,3,4,5,6,7,8,9] # 将可迭代对象转换为迭代器 obj = iter(l) count = 0 # 对迭代器循环取值 while count \u0026lt; len(l): data_elements = next(obj) print(data_elements) count += 1  方式二：（利用异常处理）\nl = [1,2,3,4,5,6,7,8,9] # 将可迭代对象转换为迭代器 obj = iter(l) # 对迭代器循环取值 while 1: try: data_elements = next(obj) print(data_elements) "},{"id":12,"href":"/docs/Python/Python%E4%B9%8B%E7%94%9F%E6%88%90%E5%99%A8/","title":"Python之生成器","section":"Python","content":"生成器\r#\r\r 在Python社区，生成器和迭代器被看作一种工具，生成器的本质就是迭代器。唯一的区别就是生成器是开发人员自己用Python代码构建的数据结构，而迭代器是Python内置提供或转化而来的。\n 生成器和迭代器的区别\r#\r\r 生成器是我们用Python代码构建的数据结构。而迭代器都是Python提供或者转换得来的。\n 获取生成器\r#\r\r 获取生成器有3种方式：通过生成器函数获取生成器、通过生成器表达式获取生成器和Python内置函数或模块\n 通过生成器函数获取生成器\n只要函数中使用了yield关键字，这个函数就是生成器函数，生成器函数使用函数名称()不执行生成器函数。在生成器函数内部，通过关键字yield生成需要返回的值；生成器函数外，通过next(调用生成器函数)来获取一个yield的值，获取yield值的过程中，执行yield关键字之上的所有代码，直到遇到yield停止代码的执行（但不会结束函数），返回yield的值，注意，使用一个next(调用函数)，对应获取一个yield值。\ndef func(): print(\u0026#39;Python\u0026#39;) yield \u0026#39;第一个yield\u0026#39; print(\u0026#39;生成器\u0026#39;) yield \u0026#39;第二个yield\u0026#39; a = 1 b = 2 c = a + b print(c) yield \u0026#39;第三个yield\u0026#39; ret = func() print(next(ret)) # 输出结果：第一个yield print(next(ret)) \u0026#39;\u0026#39;\u0026#39; 输出结果： Python生成器 第二个yield \u0026#39;\u0026#39;\u0026#39; print(next(ret)) \u0026#39;\u0026#39;\u0026#39; 输出结果： 3 第三个yield \u0026#39;\u0026#39;\u0026#39; # 如果next()和yield的调用次数不对应，会报错！\u0026#39;StopIteration(停止迭代)\u0026#39; # yiled form def func(): l = [1,2,3,4,5] yield from l # l将作为子生成器为next(ret)返回列表中的单一元素 ret = func() print(next(ret)) print(next(ret)) print(next(ret)) print(next(ret)) print(next(ret)) print(next(ret)) \u0026#39;\u0026#39;\u0026#39; 输出结果： 1 2 3 4 5 Traceback (most recent call last): File \u0026#34;C:/Users/BDHT/OneDrive/Python/Python3.8/test.py\u0026#34;, line 14, in \u0026lt;module\u0026gt; print(next(ret)) StopIteration \u0026#39;\u0026#39;\u0026#39;  return和yield的区别：\nreturn：函数中只存在一个return，用来结束函数，并且给函数的执行提供返回值。\nyield：只要函数中有yield那么他就是生成器函数而不是函数。生成器函数中可以存在多个yield，yield不会结束生成器函数，一个yield对应一个next。\n  通过生成器表达式获取生成器\n生成器表达式与列表推导式的写法几乎一摸一样，将列表推导式的[]换成()就是生成器表达式，生成器表达式也有循环模式和筛选模式，多层循环构建。\n列表推导式与生成器表达式的区别在于，生成器表达式更省内存。\n# 使用列表推导式生成一个1到10的列表 l = [i for i in range(1,11)] print(l)\t# [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] # 使用生成器表达式生成一个生成器（迭代器） l = (i for i in range(1,11)) print(l)\t# \u0026lt;generator object \u0026lt;genexpr\u0026gt; at 0x000002004151AA50\u0026gt; for i in l: print(i) \u0026#39;\u0026#39;\u0026#39; 输出结果： 1 2 3 4 5 6 7 8 9 10 \u0026#39;\u0026#39;\u0026#39;  "},{"id":13,"href":"/docs/OceanBase/","title":"OceanBase","section":"Docs","content":"内容待整理\r#\r\r \r"},{"id":14,"href":"/docs/Python/Python%E4%B9%8B%E6%A8%A1%E5%9D%97/","title":"Python之模块","section":"Python","content":"模块\r#\r\r Python模块(Module)，本质就是一个Python文件，以 .py 结尾，包含了Python对象定义和Python语句，是封装语句的最小单位。一个模块就是就是包含了一组功能的Python文件，比如spam.py，模块名为spam，可以通过 import spam 调用模块。模块不宜过大，不便于维护。\n 模块的分类\r#\r\r 在Python中，模块的使用方法都是一样的，可以细分为四个通用类别：\n 使用Python编写的.py文件 已被编译为共享库或DLL的C或C++扩展 把一系列模块组织到一起的文件夹（注：该文件夹下有一个 __init__.py 文件，该文件夹称之为包，导入一个包相当于执行了这个包下的__init__.py文件，并不是把这个包下的所有文件都导入进来） 使用C语言编写，并链接到Python解释器的内置模块   使用模块的意义\r#\r\r 模块让你能够有逻辑地组织你的 Python 代码段；把相关的代码分配到一个模块里能让你的代码更好用，更易懂；模块能定义函数，类和变量，模块里也能包含可执行的代码；拿来主义，提升开发效率。\n 自定义模块\r#\r\r 本质就是创建一个Python文件。自定义模块开头应注释说明自定义模块的作用，以下是time模块的注释说明\n# encoding: utf-8 # module time # from (built-in) # by generator 1.147 \u0026#34;\u0026#34;\u0026#34; This module provides various functions to manipulate time values. There are two standard representations of time. One is the number of seconds since the Epoch, in UTC (a.k.a. GMT). It may be an integer or a floating point number (to represent fractions of seconds). The Epoch is system-defined; on Unix, it is generally January 1st, 1970. The actual value can be retrieved by calling gmtime(0). The other representation is a tuple of 9 integers giving local time. The tuple items are: year (including century, e.g. 1998) month (1-12) day (1-31) hours (0-23) minutes (0-59) seconds (0-59) weekday (0-6, Monday is 0) Julian day (day in the year, 1-366) DST (Daylight Savings Time) flag (-1, 0 or 1) If the DST flag is 0, the time is given in the regular time zone; if it is 1, the time is given in the DST time zone; if it is -1, mktime() should guess based on the date and time. \u0026#34;\u0026#34;\u0026#34; # no imports # Variables with simple values  自定义模块中出现的变量、可执行语句、函数定义等称之为模块的成员。\n  模块的运行方式\r#\r\r 脚本方式：直接使用解释器执行，或PyCharm等软件中直接运行\n 模块方式：被其他模块导入执行，为导入它的模块提供资源（变量、函数定义和类定义等）。当自定义模块被其它模块导入时，其中的可执行语句会立即执行。在Python中， __name__ 是属于 python 中的内置类属性，代表对应程序名称。当模块以脚本方式运行时，__name__等于__main__，当模块以导入方式运行时，__name__等于模块的名字。通过这一特性可以解决模块被导入方式运行时，可执行语句会立即执行的问题。\n# 在自定义模块中，通常可执行程序放在下面这条判断语句之下，而成员定义放在这条判断语句之上。 user = \u0026#39;Python\u0026#39; def func_1(): pass def func_2(): pass # 通常会将所有可执行的语句放在一个测试函数内，在开发阶段调用这个函数执行本模块功能测试 def main(): func_1() func_2() if __name__ == \u0026#39;__main__\u0026#39;:\t# 在Pycharm中输入main按回车可以快速生成 main()  系统导入模块的路径\r#\r\r 内存中：如果成功导入过模块，直接使用已经存在的模块。\n内置路径中：Python解释器安装路径下的Lib文件夹。\nsys.path：是一个路径列表，可以动态修改。\nimport sys print(sys.path) # 如果自定义模块与调用模块不在同一路径下，需要将自定义模块的路径添加到sys.path中 # 将路径添加到sys.path中 sys.path.append(r\u0026#39;自定义模块的绝对路径\u0026#39;) # 使用os模块获取一个路径的父路径 import os os.path.dirname(__file__) + r\u0026#39;自定义模块所在的文件夹\u0026#39;\t# __file__ 获取当前文件的绝对路径 # 因此，将一个模块的路径添加到sys.path中可以这样写 sys.path.append(os.path.dirname(__file__ + \u0026#39;自定义模块所在的文件夹\u0026#39;))  模块的导入方式\r#\r\r 方式1：导入模块的所有成员，调用成员时必须使用模块名称.成员名称的方式\nimport 模块名称  首次导入模块发生的三件事：\n 创建一个模块的名称空间； 执行模块对应文件，将产生的名字存放于创建的名称空间中； 在当前执行文件中拿到一个模块名，该模块名指向创建的名称空间。  注意：多次调用模块只会引用第一次调用时导入的结果，不会重复执行模块；且实行模块中的功能，始终以模块的名称空间为准。\n  方式2：一次性导入多个模块的成员\nimport 模块名称1,模块名称2,模块名称3,……\t# 不建议这么写，最好分开写  方式3：从一个模块中导入某个成员\nfrom 模块名称 import 成员名称\t# 好处是节省内存空间  首次导入模块发生的三件事：\n 创建一个模块的名称空间； 执行模块对应文件，将产生的名字存放于创建的名称空间中； 在当前名称空间中直接拿到模块中的名字，可以直接使用，不用加任何模块名前缀。  注意：多次调用模块只会引用第一次调用时导入的结果，不会重复执行模块；且实行模块中的功能，始终以模块的名称空间为准。此方式有可能与当前名称空间的名字冲突。\n  区别：\n import 模块名 的方式调用模块时,需要以模块名.模块中功能或方法的名字使用。 from 模块名 import 模块中功能的名字的方式调用模块时,直接用模块中功能或方法的名字使用。    方式4：从一个模块中导入多个个成员\nfrom 模块名称 import 成员名称1,成员名称2,成员名称3  方式5：从一个模块中导入所有成员，调用时直接使用成员名称，但容易导致命名冲突\nfrom 模块名称 import *  方式6：使用别名alias（缩写为：as）避免命名冲突\n# 为模块起别名 import 模块名称1 as 模块名称2 # 为成员起别名 from 模块名称 import 成员名称1 as 成员名称2  方式7：控制from 模块名称 import *成员的导入\n__all__是一个列表，用于表示本模块可以被外界使用的成员。元素是成员名字的字符串。此方式只针对from 模块名称 import *的导入方式生效。\n__all__ = [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;] a = 1 b = 2 c = 3 # 成员d不会被导入 d = 4  方式8：相对导入。针对一个项目中的不同模块间的导入（可以在不同的文件夹下），称之为相对导入。主要用于隐藏同项目中导入的其他模块。\n\u0026#39;\u0026#39;\u0026#39; 文件结构： d d_1 d_1_f.py d_2 d_2_f1.py d_2_f2.py \u0026#39;\u0026#39;\u0026#39; # 如果d_2_f1.py需要相对导入d_2_f2.py from . import d_2_f2.py # 如果d_1_f.py作为项目入口，需要调用d_2_f1.py # .表示相对路径 # ..表示父路径 # ...表示父路径的父路径 from .. d_2.d_2_f1 import *  常用模块\r#\r\r random模块\r#\r\r  提供了获取伪随机数相关的方法\n  random.random()：获取一个[0,1)范围内的随机浮点数。\nrandom.randint(a, b)：获取一个[a, b]范围内的随机整数。\nrandom.uniform(a, b)：获取一个[a, b]范围内的随机浮点数。\nrandom.shuffle(x)：将x中的元素顺序随机打乱，参数x必须是一个可变数据类型。\nrandom.sample(x, k)：从x中随机抽取k个数据，组成一个列表返回。\n time模块\r#\r\r  提供了获取时间戳相关的方法\n  time.time()：获取当前的时间戳（从计算机元年1970年1月1日0点0分0秒到现在经过的秒数）。\ntime.gmtime()：获取GMT格式化时间对象，默认参数为当前时间戳。\ntime.localtime()：获取本地格式化时间对象，默认参数为当前时间戳。\ntime.mktime()格式化时间对象转换成时间戳。\nimport time print(time.mktime(time.localtime())) time.strftime()：格式化时间对象转换成字符串，默认参数为当前时间戳。\nimport time print(time.strftime(\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;))\t# 2020-02-18 22:18:58 time.strptime()：字符串转换成格式化时间对象。\nimport time print(time.strptime(\u0026#39;2020-02-18 22:18:58\u0026#39;,\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;)) # 输出结果：time.struct_time(tm_year=2020, tm_mon=2, tm_mday=18, tm_hour=22, tm_min=18, tm_sec=58, tm_wday=1, tm_yday=49, tm_isdst=-1) time.sleep(secs)：暂停当前线程，睡眠secs秒\n datetime 模块\r#\r\r  日期时间模块。封装了和日期、时间相关的类，主要用于数学计算。\n  datetime中的date类：格式化输出：年-月-日\nimport datetime d = datetime.date(2020,1,1) print(d)\t# 2020-01-01 print(d.year)\t# 获取date对象的year属性：2010 print(d.month)\t# 获取date对象的month属性：1 print(d.day)\t# # 获取date对象的day属性：1 datetime中的time类：格式化输出：时：分：秒\nimport datetime t = datetime.time(10,59,59) print(t)\t# 10:59:59 print(t.hour)\t# 获取time对象的hour属性：10 print(t.minute)\t# 获取time对象的miute属性：59 print(t.second)\t# 获取time对象的second属性：59 datetime中的datetime类：格式化输出：年-月-日 时：分：秒\nimport datetime dt = datetime.datetime(2020,1,1,10,59,59) print(dt) print(dt.year) print(dt.month) print(dt.day) print(dt.hour) print(dt.minute) print(dt.second) datetime中的timedelta类：输出时间的变化量，用于时间的运算，运算的结果类型和操作数保持一致。\nimport datetime dt = datetime.timedelta(days=1) print(dt)\t# 1 day, 0:00:00 d = datetime.date(2020,1,1) res = d + dt print(res)\t# 2020-01-02 # 根据用户输入的年份判断是否是闰年，闰年2月有29天，平年2月有28天 # 计算方法：使用datetime模块，首先创建指定的年份的3月1日，往前走一天 import datetime while 1: year = input(\u0026#39;请输入年份：\u0026#39;).strip() year = int(year) # 将用户输入的字符串类型转换成整数类型 d = datetime.date(year,3,1) td = datetime.timedelta(days=1) res = d - td if res.day == 29: print(f\u0026#39;{year}年是闰年！\u0026#39;) else: print(f\u0026#39;{year}年是平年。\u0026#39;) 注意：只有date、datetime、timedelta类才能与timedelta类之间可以进行运算，并且会产生进位；而time类不能与timedelta类进行运算。\n os 模块\r#\r\r  提供了文件操作的常用方法。（自动化运维常用的模块为shutil）\n  os.remove()：删除文件\nos.rename()：修改文件名称\nos.removedirs()：删除空目录，只能删除空目录。\nos.path：path模块是os模块的子模块，封装了很多文件路径的操作方法。\nos.system('command')：执行系统的command命令\n sys 模块\r#\r\r  提供了和Python解释器相关的操作。\n   sys.argv：在程序中获取Python文件通过命令行运行后时后面的参数，sys.argv[0]获取的是文件名，sys.argv[1]获取文件名后的第一个参数，sys.argv[2]获取文件名后的第二个参数。 sys.path：以列表的形式返回解释器寻找模块的路径。sys.path中的第一个元素总是当前执行这个文件的父目录。 sys.modules：以字典的形式返回系统已经加载的模块。   json 模块\r#\r\r  将数据转换成字符串，用于数据存储和传输。结构化数据不能直接写入文件，只有非结构化的线性数据才可以。json已经成为一种简单通用的数据交换格式（可以跨语言数据交互）。\n  序列化 (Serialization)：将内存中的数据，转换成字节，用以保存在文件或通过网络传输，称之为序列化过程（把数据从内存中拿出去）。可json序列化的数据类型有数值、字符串、列表、元组、字典等，但集合不可被json序列化，同时，元组被序列化后，会变成列表形式的字符串。\njson.dump(obj, f)：将指定的对象存储到文件中，从内存到硬盘。\nimport json with open(r\u0026#39;test.txt\u0026#39;, mode=\u0026#39;wt\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f:\t# 注意：以text类型写入 json.dump([1,2,3,4,5],f) json.dumps(obj)：将指定的对象转换成json格式的字符串，从内存到内存。\nimport json res = json.dumps([1,2,3]) print(res,type(res))\t# [1, 2, 3] \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; # json文件通常是一次性写，但通过多次序列化的方式可以实现多次写 import json with open(r\u0026#39;test.txt\u0026#39;, mode=\u0026#39;at\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: f.write(json.dumps([1, 2, 3]) + \u0026#39;\\n\u0026#39;) f.write(json.dumps([4, 5, 6]) + \u0026#39;\\n\u0026#39;)  反序列化 (Deserialization)：从文件、网络中获取的数据转换成内存中原来的数据类型，称之为反序列化过程。（把数据拿到内存中）\njson.load(f)：将文件中的字符串数据转换成序列化前的数据类型。\nimport json with open(r\u0026#39;test.txt\u0026#39;, mode=\u0026#39;rt\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: b = json.load(f) print(b,type(b))\t# [1, 2, 3, 4, 5] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; json.loads(s)：将内存中的字符串数据转换成序列化前的数据类型。\nimport json res = json.dumps([1,2,3]) l = json.loads(res) print(l,type(l))\t# [1, 2, 3] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; # json文件通常是一次性读，但通过多次反序列化的方式i可以实现多次读 import json with open(r\u0026#39;test.txt\u0026#39;, mode=\u0026#39;rt\u0026#39;, encoding=\u0026#39;UTF-8\u0026#39;) as f: for i in f: res = json.loads(i.strip(\u0026#39;\\n\u0026#39;))  pickle 模块\r#\r\r  可以将Python中所有的数据类型进行序列化与反序列化的过程，将数据类型与字节相互转换。可以多次对同一个文件进行序列化，但pickle序列化的数据只能用于Python！\n  序列化：相较于json模块，pickle 模块序列化的更彻底，直接将数据类型转换成的是字节，而不是字符串。\npickle.dump：把pickle序列化内容从内存写入到硬盘文件。\nimport pickle with open(r\u0026#39;test.txt\u0026#39;, mode=\u0026#39;wb\u0026#39;) as f: # 注意：以bytes类型写入  pickle.dump([1,2,3],f) pickle.dumps：把pickle序列化内容从内存写入到内存。\nimport pickle res = pickle.dumps(10) print(res,type(res))\t# b\u0026#39;\\x80\\x04K\\n.\u0026#39; \u0026lt;class \u0026#39;bytes\u0026#39;\u0026gt;  反序列化：将字节文件转换成序列化前的数据类型。\npickle.load：将硬盘文件中的字节写到内存中，并转换成序列化前的数据类型\nimport pickle with open(r\u0026#39;test.txt\u0026#39;, mode=\u0026#39;rb\u0026#39;) as f: res = pickle.load(f) print(res,type(res))\t# [1, 2, 3] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; pickle.loads：将内存中的字节写到内存中，并转换成序列化前的数据类型\nimport pickle res = pickle.dumps(10) l = pickle.loads(res) print(l,type(l))\t# 10 \u0026lt;class \u0026#39;int\u0026#39;\u0026gt;  hashlib 模块\r#\r\r  封装一些用于加密的类。加密的目的是用来验证文件，而非解密文件。\n  特点：\n 将一个数据切片后，对每片数据进行加密，所有数据片组装后的加密结果与直接对文件加密的结果一致； 单向加密不可逆； 原始数据的微小变化，将导致加密结果的雪崩式差异； 无论文件多大，hash值的长度是固定的。不同加密算法，加密结果的长度不同； 只能对字节进行加密。   使用：生成一个文件的hash值\nimport hashlib # 获取一个加密对象 user_file = hashlib.md5() user_file_path = input(\u0026#39;请输入您需要验证程序或文件的路径：\u0026#39;.strip()) with open(f\u0026#39;{user_file_path}\u0026#39;, mode=\u0026#39;rb\u0026#39;) as f: # 以binary（二进制）方式读 for line in f: # 使用加密对象的update方法，把值传给md5算法进行加密 user_file.update(line) # 通过hexdigest()方法获取加密结果,返回一个十六进制的字符串 hash_value = user_file.hexdigest() print(f\u0026#39;您程序或文件的hash值为：{hash_value}\u0026#39;) # 注意：以下写法的值是一样的 # 写法1 import hashlib m = hashlib.md5(b\u0026#39;abc\u0026#39;) print(m.hexdigest())\t# 900150983cd24fb0d6963f7d28e17f72 # 写法2 m = hashlib.md5() m.update(b\u0026#39;abc\u0026#39;) print(m.hexdigest())\t# 900150983cd24fb0d6963f7d28e17f72  验证两个文件的hash值是否相同，用以判断两个文件的原文是否相同。\n  加盐：为了防止黑客通过彩虹表根据哈希值反推原始口令，在计算哈希的时候，不能仅针对原始输入计算，需要增加一个salt来使得相同的输入也能得到不同的哈希，这样，大大增加了黑客破解的难度。如果salt是我们自己随机生成的，通常我们计算MD5时采用md5(message + salt)。但实际上，把salt看做一个“口令”，加salt的哈希就是：计算一段message的哈希时，根据不通口令计算出不同的哈希。要验证哈希值，必须同时提供正确的口令。\nimport hashlib # 获取一个加密对象 user_file = hashlib.md5(b\u0026#39;salt\u0026#39;)\t# 加盐 user_file_path = input(\u0026#39;请输入您需要验证程序或文件的路径：\u0026#39;.strip()) with open(f\u0026#39;{user_file_path}\u0026#39;, mode=\u0026#39;rb\u0026#39;) as f: # 以binary（二进制）方式读 for line in f: # 使用加密对象的update方法，把值传给md5算法进行加密 user_file.update(line) # 通过hexdigest()方法获取加密结果,返回一个十六进制的字符串 hash_value = user_file.hexdigest() print(f\u0026#39;您程序或文件的hash值为：{hash_value}\u0026#39;) #4795d80f956d95feab5f1dedc7b51792  hmac 模块\r#\r\r  Keyed-Hashing for Message Authentication 它通过一个标准算法，在计算哈希的过程中，把key混入计算过程中。\n  与hashlib加salt算法不同，hmac算法针对所有哈希算法都通用，无论是MD5还是SHA-1。采用hmac替代我们自己的salt算法，可以使程序算法更标准化，也更安全。Python自带的hmac模块实现了标准的hmac算法。我们来看看如何使用hmac实现带key的哈希。\nimport hmac message = b\u0026#39;Hello, world!\u0026#39; key = b\u0026#39;secret\u0026#39; h = hmac.new(key, message, digestmod=\u0026#39;MD5\u0026#39;) # 如果消息很长，可以多次调用h.update(msg) h.hexdigest()  subprocess 模块\r#\r\r Python 2.4 中新增的一个模块，它允许你生成新的进程，连接到它们的 input/output/error 管道，并获取它们的返回（状态）码。这个模块的目的在于替换几个旧的模块和方法，如：os.system，os.spawn\nimport subprocess obj=subprocess.Popen(\u0026#39;yum -y update\u0026#39;,shell=True,stdout=subprocess.PIPE,stderr=subprocess.PIPE) # shell=True 表示使用解释器解释命令； # stdout=subprocess.PIPE 表示将正确的结果往stdout管道丢； # stderr=subprocess.PIPE 表示将错误的结果往stderr管道丢； # PIPE就是管道的意思 res_stdout=obj.stdout.read() # 通过管道读取正确的结果，而且，结果只能取一次，取走了就没有了 print(res_stdout.decode(\u0026#39;utf-8\u0026#39;)) res_stderr=obj.stderr.read() # 通过管道读取错误的结果，而且，结果只能取一次，取走了就没有了 print(res_stderr.decode(\u0026#39;utf-8\u0026#39;))  configparser 模块\r#\r\r 该基本配置语言提供的结构类似于Microsoft Windows INI文件中的结构。用于生成和修改常见配置文档。\n shutil 模块\r#\r\r  高级的文件、文件夹、压缩包处理模块。\n  拷贝文件：\nimport shutil shutil.copy2(\u0026#39;src\u0026#39;, \u0026#39;dst\u0026#39;)  拷贝目录：\nimport shutil shutil.copytree(\u0026#39;src\u0026#39;, \u0026#39;dst\u0026#39;, ignore=shutil.ignore_patterns(\u0026#39;*.mp4\u0026#39;)) # ignore=shutil.ignore_patterns(\u0026#39;*.mp4\u0026#39;)可以指定哪些文件不拷贝，根据自己需求，可以不用写  删除目录：\nimport shutil shutil.rmtree(\u0026#39;src\u0026#39;, ignore_errors=True)  移动文件或目录：\nimport shutil shutil.move(\u0026#39;src\u0026#39;, \u0026#39;dst\u0026#39;, copy_function=shutil.copy2)  获取磁盘使用空间：\nimport shutil total, used, free = shutil.disk_usage(r\u0026#39;c:/\u0026#39;) print(F\u0026#39;总大小：{total/1024/1024/1024}GB，可使用大小：{used/1024/1024/1024}GB，剩余大小：{free/1024/1024/1024}GB\u0026#39;)  压缩文件：\nimport shutil shutil.make_archive(\u0026#39;test.txt\u0026#39;, \u0026#39;zip\u0026#39;, \u0026#39;root_dir\u0026#39;)  解压文件：\nimport shutil shutil.unpack_archive(\u0026#39;filename\u0026#39;, \u0026#39;extract_dir\u0026#39;)  logging 模块\r#\r\r  日志模块，一般用来trouble shooting和数据分析。但无论希望日志里打印哪些内容，都得自己写，没有自动生成日志这种事儿。\n  导入日志模块\nimport logging logging.debug(\u0026#39;debug message\u0026#39;) logging.info(\u0026#39;info message\u0026#39;) logging.warning(\u0026#39;warning message\u0026#39;) logging.error(\u0026#39;error message\u0026#39;) logging.critical(\u0026#39;critical message\u0026#39;)  定义日志基本配置\nimport logging logging.basicConfig( format=\u0026#39;%(asctime)s- %(filename)s- [line:%(lineno)d] - %(levelname)s: %(message)s\u0026#39;, datefmt=\u0026#39;%Y-%m-%d%H:%M:%S\u0026#39;, filename=\u0026#39;parser_result.log\u0026#39;, filemode=\u0026#39;a\u0026#39; ) logging.debug(\u0026#39;debug message\u0026#39;) logging.info(\u0026#39;info message\u0026#39;) logging.warning(\u0026#39;warning message\u0026#39;) logging.error(\u0026#39;error message\u0026#39;) logging.critical(\u0026#39;critical message\u0026#39;)   logging.basicConfig函数各参数:\n filename: 指定日志文件名 filemode: 和file函数意义相同，指定日志文件的打开模式，\u0026lsquo;w\u0026rsquo;或\u0026rsquo;a\u0026rsquo; format: 指定输出的格式和内容，format可以输出很多有用信息，如上例所示:  %(levelno)s: 打印日志级别的数值 %(levelname)s: 打印日志级别名称 %(pathname)s: 打印当前执行程序的路径，其实就是sys.argv[] %(filename)s: 打印当前执行程序名 %(funcName)s: 打印日志的当前函数 %(lineno)d: 打印日志的当前行号 %(asctime)s: 打印日志的时间 %(thread)d: 打印线程ID %(threadName)s: 打印线程名称 %(process)d: 打印进程ID %(message)s: 打印日志信息 datefmt: 指定时间格式，同time.strftime() level: 设置日志级别，默认为logging.WARNING stream: 指定将日志的输出流，可以指定输出到sys.stderr,sys.stdout或者文件，默认输出到sys.stderr，当stream和filename同时指定时，stream被忽略      "},{"id":15,"href":"/docs/Python/Python%E4%B9%8B%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","title":"Python之正则表达式","section":"Python","content":"什么是正则表达式\r#\r\r 正则表达是一套匹配字符串的通用规则，很多开发语言中都有。\n 为什么要用正则表达式\r#\r\r 检测一个字符串是否合法。在用户输入一个内容的时候，应该对用户输入的内容做检测，这样才能规避因用户的错误或恶意输入，对程序和服务器造成的资源浪费。多用于在Web项目开发时，用于表单验证。\n高效的内容匹配。从一个大文件当中快速的找到所有符合规则的内容。多用于爬虫的日志分析。\n 正则表达式怎么用\r#\r\r 正则表达式永远都是从左到右依据规则进行匹配的，正则表达式没有逻辑，只认规则！有逻辑的永远是正则表达式的设计者！\n 字符组\r#\r\r 字符组是整个正则表达式中描述最细腻的方式，可以精准的匹配到任何内容。\n[]：一个中括号内放入需要匹配的的字符，只要被匹配的字符串内单个字符位置含有中括号里的ASCII字符，就算匹配成功。中括号内可以写一个、多个、一个范围或者多个范围的字符，字符的范围需根据ASCII码值中从小到大，不能从大到小。\n[Python]\t# 匹配P，y，t，h，o，n这6个字母，只匹配一个字符位 [a-z]\t# 匹配a到z所有的字母，由于根据ASCII码进行匹配，因此范围需要ACSII码从小到大，不能z-a [A-z]\t# 匹配A到Z所有的字母 [0-9]\t# 匹配0到9所有的数字 [0-9a-zA-Z]\t# 匹配所有大小写字母与数字，可以写多个范围  非字符组\r#\r\r [^]：一个中括号，第一位是^，表示非字符组。\n[^Python]\t# 只要匹配内容中不是P，y，t，h，o，n这6个字母，那个字节位就算匹配成功  元字符\r#\r\r 在正则表达式中表示匹配的内容符号（字符组、\\d、\\w、\\s等）都是元字符。表示能匹配那些内容，一个元字符只能表示一个字符位置上的字符。\n\\d：表示匹配一位任意数字字符，等同于 [0-9]。d表示digit。\n\\w：表示匹配一位任意数字字符、字母和下划线，等同于 [0-9a-zA-Z_]。w表示word。\n\\s：表示匹配一位任意空字符（空格： ，制表符：\\t，回车：\\n）。\n\\D：表示匹配一位任意非数字字符。\n\\w：表示匹配一位任意非数字、字母和下划线字符。\n\\S：表示匹配一位任意非空白字符。\n\\b：表示以一个单词为边界匹配任意数字、字母和下划线结尾的字符。\n.：表示匹配一位除换行符以外的任意字符。但可以通过设置使其能够匹配换行符。注意，如果匹配的字符串中含有.比如：www.google.com，那么需要在规则的.之前加上\\进行转义：\\.，否则.所占的字符位就会匹配除换行符以外的任意字符。\n[\\d\\D]、[\\w\\W]、[\\d\\D]：表示匹配一位任意字符。\n^：匹配字符串的开始。注意：^只能出现在开始的位置，且只从字符串的开始位置进行匹配，进行匹配时，空白字符由于看到不，经常会被忽略，所以要格外注意，空白字符也要算上。\n$：匹配字符串的结尾。注意：$只能出现在结束的位置，且只从字符串的结束位置进行匹配，进行匹配时，空白字符由于看到不，经常会被忽略，所以要格外注意，空白字符也要算上。\n^和$组合使用：约束了在^和\u0026amp;之间的所有字符和字符位，被匹配字符串必须和^ \u0026amp;之间的字符一模一样才算匹配成功。主要用于判断用户输入内容的合法性检查。\n|：表示“或”，匹配|左右两边的内容，但是要注意，由于正则表达式是从左往右进行的规则匹配，如果左边匹配成功了，就不会再匹配右边，因此左右两边如果有重叠内容，一定要把更长的内容写在左边。\n()：表示分组，用于约束某一个元字符的作用范围。\nwww\\.baidu\\.com|www\\.google\\.com # 可以写成 www\\.(baidu|google)\\.com\t# 表示|只在括号内生效  量词\r#\r\r 表示一个元字符匹配多少次。单独使用不生效，必须跟在一个元字符的后面，并且只能约束前面的一个元字符。\n{n}：表示匹配n次。\n# 匹配手机号，要求第1位数字必须以1开头，第2位数字是3到9，必须只能是11位的数字 1[3-9]\\d{9} # 判断用户输入的手机号是否合法 ^1[3-9]\\d{9}$\t# 严格约束^和$之间的内容 {n,}：表示至少匹配n次。\n{n,m}：表示至少匹配n次，至多匹配m次。\n?：表示匹配0次或1次。等同于：{0,1}。也就是说可以表示某一个位置上的值可出现也可不出现。\n+：表示1次或多次。等同于：{1,}\n# 匹配一个任意整数: \\d+ # 匹配一个任意浮点数： \\d+\\.\\d+ *：表示0次或多次。等同于：{0,}，也就是所有。\n# 匹配一个任意整数或浮点数 \\d+(\\.\\d+)?  贪婪匹配\r#\r\r 贪婪匹配的现象表现在量词允许的范围内，会尽量多的匹配内容。例如：{n,m} 正则表达式会匹配m次。\n# 匹配一串数字，当遇到9的时候停止 \\d{1,}9 17892190915509876554\t# 匹配结果：17892190915509 # 为什么匹配到最后一个9才停止呢？其中除了涉及到贪婪匹配，还涉及到了回溯算法。计算机是这样读正则表达式的：看到 \\d 就知道要匹配一个任意数字字符，看到 {} 里面有个 1，先读 \\d 后面的 1 位，然后又看了个逗号，并且逗号后面什么也没有，就开始一直匹配数字直到没有数字为止，结果又看到了个 9 ，此时开始从数字的末尾往回走找 9 ，找到 9 后匹配完毕，因此找到的就是最后一个 9 ，这，就是回溯算法。  .*x：表示匹配任意字符、任意次数，遇到最后一个x才下来。\n  非贪婪（惰性）匹配\r#\r\r 惰性匹配实在量词后面加上一个?，表示在量词范围内进行最少匹配。例如：{n,m}？ 正则表达式会匹配n次。\n\\d{1,}?9 17892190915509876554 \u0026#39;\u0026#39;\u0026#39; 匹配结果： 1789 219 09 15509 \u0026#39;\u0026#39;\u0026#39;  .*?x：表示匹配任意字符、任意次数，一旦遇到x就停下来。\n  转义符\r#\r\r 有特殊意义或功能的字符，需要表达它符号本身的时候，就需要转义。正则表达式中的转义分为两种：\n\\：在表达式中，任何有特殊意义或功能的字符前面加个\\都会丧失其特殊意义或功能。\n[]：在字符组中，所有的量词均丧失其特殊意义，变为普通字符，但-在两个数值之间却表示一个范围，在其他位置才表示其本身。\n "},{"id":16,"href":"/docs/Python/Python%E4%B9%8Bre%E6%A8%A1%E5%9D%97/","title":"Python之re模块","section":"Python","content":"re模块介绍\r#\r\r re  模块使 Python 语言拥有全部的正则表达式功能。\n re模块的内置方法\r#\r\r re.findall()\r#\r\r对字符串进行正则表达式的全文匹配，把所有符合正则表达式的结果以列表的形式返回，如果正则表达式中有分组，虽然匹配的时候按照正则表达式进行匹配的，但是只返回分组中的正则内容。\nimport requests s = \u0026#39;\u0026lt;h1\u0026gt;Python之re模块findall方法\u0026lt;/h1\u0026gt;\u0026#39; # 通过正则只取出结果：\u0026#39;Python之re模块findall方法\u0026#39; ret = re.findall(\u0026#39;\u0026lt;h1\u0026gt;(.*?)\u0026lt;/h1\u0026gt;\u0026#39;,s)\t# 有分组()时，返回结果只会显示分组内容 print(ret)\t# [\u0026#39;Python之re模块findall方法\u0026#39;]  re.search()\r#\r\r对字符串进行正则表达式的全文匹配，只取第一个符合正则表达式条件的结果，得到的结果是一个变量，通过.group(n)可以获取到第n个分组中匹配到的内容。主要用来寻找字符串中是否含有满足条件的子内容。\nimport requests s = \u0026#39;4-2*(4+6)\u0026#39; # 通过正则计算s中4+6的值 ret = re.search(\u0026#39;(\\d+)[+](\\d+)\u0026#39;,s) ret_1 = int(ret.group(1)) ret_2 = int(ret.group(2)) print(ret_1 + ret_2)  re.split()\r#\r\r以正则表达式为条件，切分字符串内容，并将内容以列表的形式返回。若正则表达式中有分组，则保留匹配的切分条件。\n# 不含分组 import re s = \u0026#39;54Python432re78split\u0026#39; ret = re.split(\u0026#39;\\d+\u0026#39;,s) print(ret, type(ret))\t# [\u0026#39;\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;re\u0026#39;, \u0026#39;split\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; # 含有分组 import re s = \u0026#39;54Python432re78split\u0026#39; ret = re.split(\u0026#39;(\\d+)\u0026#39;,s) print(ret, type(ret)) # [\u0026#39;\u0026#39;, \u0026#39;54\u0026#39;, \u0026#39;Python\u0026#39;, \u0026#39;432\u0026#39;, \u0026#39;re\u0026#39;, \u0026#39;78\u0026#39;, \u0026#39;split\u0026#39;] \u0026lt;class \u0026#39;list\u0026#39;\u0026gt;  re.sub()\r#\r\r以正则表达式为条件，用指定的字符串替换符合正则表达式内容的字符串，并且可以指定替换的次数。\n# 不指定替换次数，默认全部替换 import re s = \u0026#39;Python432re78sub\u0026#39; ret = re.sub(\u0026#39;\\d+\u0026#39;, \u0026#39;_\u0026#39;, s) print(ret, type(ret))\t# Python_re_sub \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; # 指定替换次数 import re s = \u0026#39;Python432re78sub\u0026#39; ret = re.sub(\u0026#39;\\d+\u0026#39;, \u0026#39;_\u0026#39;, s, 1)\t# 指定替换次数1 print(ret, type(ret))\t# Python_re78sub \u0026lt;class \u0026#39;str\u0026#39;\u0026gt;  re.subn()\r#\r\r以正则表达式为条件，用指定的字符串替换符合正则表达式内容的字符串，并且统计出替换的次数，并以元组的形式返回结果。\nimport re s = \u0026#39;Python432re78sub\u0026#39; ret = re.subn(\u0026#39;\\d+\u0026#39;, \u0026#39;_\u0026#39;, s) print(ret, type(ret))\t# (\u0026#39;Python_re_sub\u0026#39;, 2) \u0026lt;class \u0026#39;tuple\u0026#39;\u0026gt;  re.math()\r#\r\r从开头进行匹配，相当于添加了^，使用方法同search()。一般用来规定用户输入信息必须是什么样的。\nimport re while 1: user_input = input(\u0026#39;请输入您的手机号:\u0026#39;).strip() # 要求用户输入的手机好必须是第一位是1开头，第二位是3到9的11位数字 ret = re.match(\u0026#39;1[3-9]\\d{9}\u0026#39;, user_input) if re.match(\u0026#39;1[3-9]\\d{9}\u0026#39;, user_input) == None: print(\u0026#39;请输入合法的手机号\u0026#39;) else: break  re.compile()\r#\r\r可以将正则表达式一次编译多次使用，避免重复编译正则表达式。是一个提升代码执行效率的工具。\nimport requests s_1 = \u0026#39;\u0026lt;h1\u0026gt;page1\u0026lt;/h1\u0026gt;\u0026#39; s_2 = \u0026#39;\u0026lt;h1\u0026gt;page2\u0026lt;/h1\u0026gt;\u0026#39; s_3 = \u0026#39;\u0026lt;h1\u0026gt;page3\u0026lt;/h1\u0026gt;\u0026#39; ret = re.compile(\u0026#39;\u0026lt;h1\u0026gt;(.*?)\u0026lt;/h1\u0026gt;\u0026#39;) res_1 = ret.findall(s_1) res_2 = ret.findall(s_2) res_3 = ret.findall(s_3) print(res_1) print(res_2) print(res_3)  re.finditer()：\r#\r\r不同于re.findall()直接返回一个列表，re.finditer()返回的是一个迭代器，通过迭代器一个一个的取值，可以节省内存空间。\nimport requests s = \u0026#39;477h314kh3h532kjh589kjh523h5kj2h3jh6957kj4h6kj\u0026#39; ret = re.finditer(\u0026#39;\\d+\u0026#39;,s) for i in ret: print(i.group())  在爬虫中re.compile()经常与re.finditer()连用。即能节省时间，也能节省空间。\n  re模块的使用\r#\r\r 分组命名\r#\r\r当正则表达式中存在很多个分组，为避免对分组取值时一个一个的去数分组的情况发生，一般都会给分组进行命名，命名的方法实在括号内的最前面添加（?P\u0026lt;分组的名称\u0026gt;）。\nimport requests s = \u0026#39;477h314kh3h532kjh589\u0026#39; ret = re.search(\u0026#39;(?P\u0026lt;取数字\u0026gt;\\d+)(?P\u0026lt;取字母\u0026gt;\\w+?)\u0026#39;,s) print(ret.group(\u0026#39;取数字\u0026#39;)) # 477 print(ret.group(\u0026#39;取字母\u0026#39;)) # h  分组的引用\r#\r\r当正则表达式中的两个分组内容相同，可以通过分组名称进行分组内容的引用，注意，通过分组名称引用的并不是正则表达式，而是正则表达式匹配的内容。\nimport re s = \u0026#39;\u0026lt;h1\u0026gt;Python之re模块findall方法\u0026lt;/h1\u0026gt;\u0026#39; ret = re.search(\u0026#39;\u0026lt;(?P\u0026lt;tag\u0026gt;\\w+)\u0026gt;(.*?)\u0026lt;/(?P=tag)\u0026gt;\u0026#39;,s) print(ret) # 正则表达式中的\\1表示第一个分组，因此也可以写成 import re s = \u0026#39;\u0026lt;h1\u0026gt;Python之re模块findall方法\u0026lt;/h1\u0026gt;\u0026#39; ret = re.search(r\u0026#39;\u0026lt;(?P\u0026lt;tag\u0026gt;\\w+)\u0026gt;(.*?)\u0026lt;/\\1\u0026gt;\u0026#39;,s) print(ret)  "},{"id":17,"href":"/docs/Python/%E9%9D%A2%E5%90%91%E8%BF%87%E7%A8%8B%E4%B8%8E%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","title":"面向过程与面向对象","section":"Python","content":"面向过程的编程思想\r#\r\r 面向过程的编程思想是按照步骤解决问题，即先干什么，后干什么。基于该思想编写程序，就好比编写一条流水线，是一种机械式思维方式，多用于运维。\n 优点：复杂的问题流程化，进而简单化；\n缺点：修改一个步骤，其他步骤都有可能做出修改，牵一发而动全身，扩展性极差。\n 应用场景：应用于扩展性要求低的场景\n 面向对象的编程思想\r#\r\r 面向对象程序设计方法是尽可能模拟人类的思维方式，使得软件的开发方法与过程尽可能接近人类认识世界、解决现实问题的方法和过程，也即使得描述问题的问题空间与问题的解决方案空间在结构上尽可能一致，把客观世界中的实体抽象为问题域中的对象。面向对象程序设计以对象为核心，该方法认为程序由一系列对象组成。类是对现实世界的抽象，包括表示静态属性的数据和对数据的操作，对象是类的实例化。对象间通过消息传递相互通信，来模拟现实世界中不同实体间的联系。在面向对象的程序设计中，对象是组成程序的基本模块。\n 优点：解决了程序的扩展性。对某一个对象单独修改，会立刻反映到整个体系中，如对游戏中一个人物参数的特征和技能修改都很容易。\n缺点：\n 编程的复杂度远高于面向过程，不了解面向对象而立即上手基于它设计程序，极容易出现过度设计的问题。一些扩展性要求低的场景使用面向对象会徒增编程难度，比如管理Linux系统的Shell脚本就不适合用面向对象去设计，面向过程反而更加适合。 无法向面向过程的程序设计流水线式的可以很精准的预测问题的处理流程与结果，面向对象的程序一旦开始就由对象之间的交互解决问题，最终结果就无法进行准确地预测。于是我们经常看到对战类游戏，新增一个游戏人物，在对战的过程中极容易出现阴霸的技能，一刀砍死3个人，这种情况是无法准确预知的，只有对象之间交互才能准确地知道最终的结果。   应用场景：需求经常变化的软件，一般需求的变化都集中在用户层，互联网应用，企业内部软件，游戏等都是面向对象的程序设计大显身手的好地方。面向对象的程序设计并不是全部。对于一个软件质量来说，面向对象的程序设计只是用来解决扩展性。\n Python的面向对象有三大特征：继承、封装和多态\n "},{"id":18,"href":"/docs/Python/Python%E4%B9%8B%E7%B1%BB%E4%B8%8E%E5%AF%B9%E8%B1%A1/","title":"Python之类与对象","section":"Python","content":"类\r#\r\r 类是用来描述具有相同的属性和方法的对象的集合（在Python中类与类型是一个概念）。\n 特点：\n  在程序中，必须先定义类（类名称通常首字母大写），再调用类，然后产生对象；\n  类（类体）中最常见的就是变量（类的数据属性或者叫做静态变量）与函数（函数属性或者叫做方法）的定义，但类中可以有任意Python代码，并且类体中的代码在类的定义阶段就会立即执行。在类中，如果一个变量的值需要被所有对象共享，那么这个变量应该被定义成静态变量，所有和静态变量相关的增、删、改、查都应该使用类名调用静态变量的方式来处理，而不应该使用对象名调用静态变量的方式进行处理。\n  类的属性可以进行增、删、改、查等操作\n  调用类产生对象的过程称为类的实例化，实例化的结果是一个对象，或者称为一个实例。\n# For example: class Chinese(): # 类命名规则是首字母大写的驼峰体 \u0026#39;\u0026#39;\u0026#39; 类的注释信息 \u0026#39;\u0026#39;\u0026#39; country = \u0026#39;China\u0026#39; # 类内通常定义相同的特征，country被称为Chinese类中的数据属性 def __init__(self,name,age,sex): # 在对象实例化的时候，__init__() 会自动触发执行 self.Name = name # Chinese.Name = name self.Age = age # Chinese.Age = age self.Sex = sex # Chinese.Sex = sex def run(self): # 类内通常定义相同的技能；类内的函数()中默认自带self参数；run(self)称之为Chinese类中的绑定方法 print(F\u0026#39;{self.Name}is running\u0026#39;) obj = Chinese(\u0026#39;HC\u0026#39;, 18, \u0026#39;males\u0026#39;) # 类的实例化，Chinese.__init__(obj,\u0026#39;HC\u0026#39;,18,\u0026#39;males\u0026#39;)    类的实例化做了三件事：\n 先调用object的__new__方法创建一个对象的空间，对象的空间中有一个类指针； 自动触发类内部 __init__() 函数的执行。__init__方法：  该方法内可以有任意的python代码； 一定不能有返回值。   将空对象及调用类括号内的参数，一同传给 __init__()，为对象定制独有的属性。在产生对象时，需要在类内定义一个__init__的函数，该函数会在调用类的时候自动触发执行，为类中不同于那些相同特征与技能的对象进行初始化。     类内部定义的变量是给所有对象共享的，所有对象使用类中的属性都指向的都是同一个内存地址。\n  类内部定义的函数，类可以使用，但类用的时候就是普通函数，普通函数有几个参数就要传几个参数；而类内部定义的函数，其实是给对象使用的，当对象调用类内部的函数时，类内部的函数会绑定给对象，称之为绑定方法，绑定方法的特殊之处在于：谁来调用，就会将谁当作第一个参数self自动传入。\n   对象\r#\r\r 类的实例化结果就是一个对象，对象中的变量只属于对象本身，每个对象都有属于自己的名称空间来存储对象的变量，当使用对象名去调用类中的属性时，会优先在自己的名称空间中寻找，再去类中寻找，如果类中没有引用其他类，找不到就会报错，即对象属性的查找顺序为：先找对象自己的名称空间（__dict__） -\u0026gt; 类的名称空间（__dict__）。\n 对象的操作\r#\r\r 增：\nChinese.gender = \u0026#39;males\u0026#39; print(Chinese.gender) 删：\ndel Chinese.gender 改：\nChinese.gender = \u0026#39;females\u0026#39; print(Chinese.gender) 查：\nprint(Chinese.country)  类与函数的区别\r#\r\r 函数内的代码，在函数定义阶段并不会运行，只有在调用阶段才会运行；类体内的代码，在类定义阶段就会立刻执行，并且产生类的名称空间。\n Python中一切皆对象\r#\r\r 在Python3中统一了类与类型的概念，类即类型。\n 新式类与经典类\r#\r\r 新式类\n 继承object的类，以及该类的子类，都是新式类。 在Python 3中如果一个类没有指定继承的父类，默认就继承object，因此Python 3中所有的类都是新式类。   经典类\n 没有继承object的类，以及该类的子类，都是经典类。 只有在Python2中才区分新式类与经典类，Python3中都是新式类。   新式类和经典类只有在菱形继承下才有区别：\n 经典类：深度优先查找。 新式类：广度优先查找。  "},{"id":19,"href":"/docs/Python/Python%E4%B9%8B%E7%BB%84%E5%90%88/","title":"Python之组合","section":"Python","content":"组合\r#\r\r 一个类的对象是另一个类的属性。\n 使用组合的意义\r#\r\r 减少代码冗余，让代码修改起来更灵活。\n 组合的使用方法\r#\r\r # 定义一个笔记本电脑类 class Laptop: def __init__(self, brand, model): self.brand = brand # 品牌 self.model = model # 型号 # 定义一个供应商类 class Supplier: def __init__(self, supplier_name, supplier_price): self.supplier_name = supplier_name # 供应商名称 self.supplier_price = supplier_price # 供应商价格 # 创建一个ThinkPad的笔记本对象 thinkpad = Laptop(\u0026#39;Thinkpad\u0026#39;, \u0026#39;T490s\u0026#39;) # 创建一个JD供应商的对象 jd = Supplier(\u0026#39;JD\u0026#39;, 11000) # 利用组合查看thinkpad在jd中的价格 thinkpad.supplier = jd print(thinkpad.supplier.supplier_price) "},{"id":20,"href":"/docs/Python/Python%E4%B9%8B%E7%BB%A7%E6%89%BF%E5%B0%81%E8%A3%85%E5%92%8C%E5%A4%9A%E6%80%81/","title":"Python之继承、封装和多态","section":"Python","content":"继承\r#\r\r 继承是一种新建类的方式，在Python中支持一个子类继承多个父类。继承是类与类之间的从属关系，寻找这种关系需要先抽象，再继承。新建的类称为子类或派生类，父类又称为基类或超类。子类会继承父类的属性，可以使用父类的静态变量和方法。继承其实增加了类的耦合性。\n 使用继承的意义\r#\r\r减少代码冗余。\n 继承的使用方法\r#\r\r在Python 2中类分为两种，一种叫经典类（没有继承了object类，以及该类的子类，查找顺序遵从深度优先），一种叫新式类（继承了object类，以及该类的子类，查找顺序遵从广度优先，新式类中使用类名.mro()可以查看C3算法）。但在Python 3中全都为新式类。类的继承分为两种，一种是单继承，单继承可以继承多次；一种是多继承，Python中支持多继承，但并不是所有语言都支持，使用多继承可以同时继承多个父类，查找顺序为先继承的先找。\n# For Example： class ParentClass1: pass class ParentClass2: pass class SubClass1(ParentClass1): # 单继承 pass class SubClass2(ParentClass1,ParentClass2): #多继承，先从写在前面的父类中找 pass print(SubClass1.__bases__) # 查看SubClass的父类 print(SubClass2.__bases__) # 查看SubClass的父类 # For Example： class Father(object):\t# 继承object这种写法可以兼容Python 2 def __init__(self): self.func() def func(self): print(\u0026#39;The func from Father\u0026#39;) class Son(Father):\t# 子类Son会继承父类Father的所有属性和方法 def func(self):\tprint(\u0026#39;The func from Son\u0026#39;) son = Son()\t# The func from Son # 注意：代码自上而下执行，定义Father类的时候，会开辟一个名称空间，将__init__和func放入Father类的名称空间；定义Son类的时候，也会开辟一个名称空间，程序读到class Son(Father)时会产生一个类指针，指向Father类的名称空间，同时将类指针和func存入Son的名称空间中；当程序读到son = Son()进行实例化产生对象的时候，同样也会为对象son开辟一个名称空间，产生一个类指针，指向Son类，并且实例化会自动触发__init__，首先会在对象son的名称空间找__init__，找不到，再去Son类中找，也没有，再通过类指针指向的Father中查找，找到了__init__，把son作为self传入到__init__中，此时，father中__init__的self实际上指向的时son的名称空间，当执行self.func()时，首先会在son的名称空间查找func()，没有，再去Son类中查找，发现有一个func()方法，执行，因此，son = Son()得到的结果是：The func from Son。 print(Son.mro()) # 查看广度优先的查找顺序，只在新式类中有  派生\r#\r\r 如果子类的类体中只有一个pass，意味着全部继承父类。如果子类中定义了自己新的属性，称之为派生。如果子类中的属性或方法与父类重名，子类永远优先调用自己的属性或方法。如果需要在子类的方法中调用父类的方法，需要通过 父类名.方法名(self) 的方式。\nclass Chinese(object): country = \u0026#39;China\u0026#39; # 类的属性 def __init__(self, name, birthday, sex): self.name = name self.birthday = birthday self.sex = sex def attribute(self): # 类的方法 print(\u0026#39;这是父类的方法\u0026#39;) class Northerners(Chinese): def northerners_diet(self): print(F\u0026#39;{self.name}is northerners,Eat pasta\u0026#39;) def attribute(self):\t# 子类中定义自己的attribute方法，称之为派生 Chinese.attribute(self)\t# 在子类的方法中调用父类的方法 print(\u0026#39;这是子类的方法\u0026#39;) class Southerners(Chinese): pass # Southerners类全部继承Chinese类 n1 = Northerners(\u0026#39;Northerner\u0026#39;, \u0026#39;2000-01-01\u0026#39;, \u0026#39;male\u0026#39;) n1.attribute() # 这是子类的方法  派生的使用方法\r#\r\r 在子类派生出的新方法中重用父类功能方法\n方式一：直接调用（其实与继承没有什么关系）\n# For Example: class User(object): def __init__(self, name, password, mobile): self.name = name self.password = password self.mobile = mobile class VIPUser(object): def __init__(self, name, password, mobile, effective_date, expiring_date): # self.name = name # self.password = password # self.mobile User.__init__(self, name, password, mobile) # 使用类名调用 self.effective_date = effective_date self.expiring_date = expiring_date user = VIPUser(\u0026#39;老王\u0026#39;, \u0026#39;123\u0026#39;, \u0026#39;xxx\u0026#39;, \u0026#39;2020-01-01\u0026#39;, \u0026#39;2021-01-01\u0026#39;) print(user.__dict__)  方式二： super()调用（严格依赖于继承）\nsuper()的返回值是一个特殊的对象，该对象专门用来调用父类中的属性。\nclass User(object): def __init__(self, name, password, mobile): self.name = name self.password = password self.mobile = mobile class VIPUser(User): # 使用super()必须继承父类 def __init__(self, name, password, mobile, effective_date, expiring_date): # self.name = name # self.password = password # self.mobile super().__init__(name, password, mobile) # super()专门调取父类的方法，super(VIPUser, self) self.effective_date = effective_date self.expiring_date = expiring_date user = VIPUser(\u0026#39;老王\u0026#39;, \u0026#39;123\u0026#39;, \u0026#39;xxx\u0026#39;, \u0026#39;2020-01-01\u0026#39;, \u0026#39;2021-01-01\u0026#39;) print(user.__dict__)  以上两种方式用哪种都可以，但不要混合使用\n  抽象类\r#\r\r 抽象类是一个开发规范，或者说是用来规范开发代码的，通过抽象类可以约束它所有的子类实现相同的方法。一般用于多人协同开发时进行开发代码规范。\n 抽象类的实现方式一：\n# 定义支付抽象类 class Payment(object): \u0026#39;\u0026#39;\u0026#39; Payment为抽象类，用于规范子类的pay方法。 \u0026#39;\u0026#39;\u0026#39; def __init__(self, name): self.name = name def pay(self, amount):\t# 严格限定子类方法的命名，如果不一样就主动抛出异常 raise NotImplementedError(\u0026#39;请在子类中规范pay方法的命名\u0026#39;) # 定义一个通过支付宝支付的类 class AliPay(Payment): # def pay(self, amount):\t# 由于父类抽象类的限制，此方法必须命名为：pay print(F\u0026#39;{self.name}通过支付宝成功支付：{amount}元\u0026#39;) # 定义一个通过微信支付的类 class WeChatPay(Payment): def pay(self, amount):\t# 由于父类抽象类的限制，此方法必须命名为：pay print(F\u0026#39;{self.name}通过微信成功支付：{amount}元\u0026#39;) # 定义一个通过苹果支付的类 class ApplePay(Payment): def pay(self, amount):\t# 由于父类抽象类的限制，此方法必须命名为：pay print(F\u0026#39;{self.name}通过苹果成功支付：{amount}元\u0026#39;) # 归一化设计：让调用者不用实例化对象 def pay(name, payment_method, amount): if payment_method == \u0026#39;AliPay\u0026#39;: obj = AliPay(name) obj.pay(amount) elif payment_method == \u0026#39;WeChatPay\u0026#39;: obj = WeChatPay(name) obj.pay(amount) elif payment_method == \u0026#39;ApplePay\u0026#39;: obj = ApplePay(name) obj.pay(amount) # 其他程序员调用归一化设计的支付接口 pay(\u0026#39;马云\u0026#39;, \u0026#39;AliPay\u0026#39;, 10000)\t# 马云通过支付宝成功支付：10000元 pay(\u0026#39;马化腾\u0026#39;, \u0026#39;WeChatPay\u0026#39;, 10000)\t# 马化腾通过微信成功支付：10000元 pay(\u0026#39;乔布斯\u0026#39;, \u0026#39;ApplePay\u0026#39;, 10000)\t# 乔布斯通过苹果成功支付：10000元 # 原理：以ApplePay为例，当ApplePay实例化产生对象obj后，obj调用ApplePay类中的pay方法，如果ApplePay中的pay方法不是以‘pay’命名，则在ApplePay类中找不到pay方法，通过类指针去父类Payment中进行查找，找到了pay方法，但pay方法中的功能为主动抛出异常，借此来实现开发代码的规范。  抽象类的实现方式二：\n# 导入相关模块 from abc import ABCMeta, abstractclassmethod # 定义支付抽象类 class Payment(metaclass=ABCMeta): \u0026#39;\u0026#39;\u0026#39; Payment为抽象类，用于规范子类的pay方法。 \u0026#39;\u0026#39;\u0026#39; def __init__(self, name): self.name = name @abstractclassmethod # 为pay加装饰器 def pay(self): pass # 定义一个通过支付宝支付的类 class AliPay(Payment): def pay(self, amount):\t# 由于父类抽象类的限制，此方法必须命名为：pay print(F\u0026#39;{self.name}通过支付宝成功支付：{amount}元\u0026#39;) # 定义一个通过微信支付的类 class WeChatPay(Payment): def pay(self, amount):\t# 由于父类抽象类的限制，此方法必须命名为：pay print(F\u0026#39;{self.name}通过微信成功支付：{amount}元\u0026#39;) # 定义一个通过苹果支付的类 class ApplePay(Payment): def pay(self, amount):\t# 由于父类抽象类的限制，此方法必须命名为：pay print(F\u0026#39;{self.name}通过苹果成功支付：{amount}元\u0026#39;) # 归一化设计：让调用者不用实例化对象 def pay(name, payment_method, amount): if payment_method == \u0026#39;AliPay\u0026#39;: obj = AliPay(name) obj.pay(amount) elif payment_method == \u0026#39;WeChatPay\u0026#39;: obj = WeChatPay(name) obj.pay(amount) elif payment_method == \u0026#39;ApplePay\u0026#39;: obj = ApplePay(name) obj.pay(amount) # 其他程序员调用归一化设计的支付接口 pay(\u0026#39;马云\u0026#39;, \u0026#39;AliPay\u0026#39;, 10000)\t# 马云通过支付宝成功支付：10000元 pay(\u0026#39;马化腾\u0026#39;, \u0026#39;WeChatPay\u0026#39;, 10000)\t# 马化腾通过微信成功支付：10000元 pay(\u0026#39;乔布斯\u0026#39;, \u0026#39;ApplePay\u0026#39;, 10000)\t# 乔布斯通过苹果成功支付：10000元  封装\r#\r\r 装就是把属性存起来，封就是把这些存起来的属性隐藏，封装的终极奥义：明确的区分内外，对外是隐藏的，对内是开放的；隐藏对象的属性和实现细节，让类外部的使用者无法直接使用，仅对外提供公共访问方式。\n广义的封装：把属性和方法装起来，在外部不能直接调用。装在类中的属性和方法都是广义上的封装。\n狭义的封装：把类的属性和方法藏起来，在类的外部不能调用，只能在内部使用。\n 使用封装的意义\r#\r\r 封装数据属性的目的：把数据属性封装起来，然后需要开辟接口给类外部的使用者使用，好处是我们可以在接口处添加逻辑控制，从而严格控制访问者对属性的操作。\n 使用封装的三个场景：\n 不想让别人看，也不想让别人改。 可以让别人看，但不想让别人改。 可以看也可以改，但必须按照指定的规则改。    封装的使用方法\r#\r\r import hashlib class User(object): def __init__(self, username, password): self.username = username self.__password = password # 在实例变量前面加上 __ ，就可以把实例变量隐藏起来，实例变量__password名变为：_User_password def __generate_hash(self): # 在方法前面加上 __ ，也可以把方法隐藏起来，在类外部无法调取 \u0026#39;\u0026#39;\u0026#39; 这是一个将用户密码加密生成MD5值的私有方法 :return: 用户密码加密后的MD5值 \u0026#39;\u0026#39;\u0026#39; md5 = hashlib.md5(self.username.encode(\u0026#39;utf-8\u0026#39;)) # 使用username加盐 md5.update(self.__password.encode(\u0026#39;utf-8\u0026#39;)) return md5.hexdigest() def get_password(self): return self.__generate_hash() user = User(\u0026#39;Python\u0026#39;, \u0026#39;123\u0026#39;) # user.__password = \u0026#39;456\u0026#39; # 无法更改，会报错 # user. __generate_hash() # 无法调取，会报错 res = user.get_password() print(res) # 输出结果：ae35eacb1cb6f6d38c29a04ecb2d7471 # 隐藏属性：其实这种隐藏只是语法上的一种变形，这种语法上的变形，只在类定义阶段发生一次，类定义之后，新增的`__`开头的属性都没有变形效果。 # 如果父类不想让子类覆盖自己的方法，可以在方法名前加`__`开头。 # 在类的外部不能定义私有方法。 # 私有方法子类不能继承使用。  私有方法的调用\r#\r\r class Father(object): def __init__(self): self.__func()\t# self.__func 实际上是： self._Father__func() def __func(self):\t# __func 实际上是： _Father__func print(\u0026#39;The func from Father\u0026#39;) class Son(Father): def __func(self):\t# __func 实际上是： _Son__func print(\u0026#39;The func from Son\u0026#39;) son = Son() # The func from Father  数据类型的级别\r#\r\r 在其他编程语言中数据类型有三种级别：\n Public（公有的）：类内类外都能用，父类子类都能用。 Protect（保护的）：类内能用，父类子类都能用，类外不能用。 Private（私有的）：只有自己的类中能用，其他地方都不能用。  在Python中只支持：Public（公有的）和 Private（私有的）。\n 封装之property\r#\r\r property 是一装饰器，访问它时会执行一段功能（函数）然后返回值，用来将类内的方法伪装成一个数据属性。\n# For Example： class People(object): def __init__(self, name, weight, height): self.name = name self.weight = weight self.height = height @property # 装饰器，将类中的方法伪装成一个数据属性 def bmi(self):\t# 被装饰的方法一定不能有参数 return self.weight / (self.height ** 2) p1 = People(\u0026#39;Python\u0026#39;, 80, 1.68) p1.name\t# 调用类的属性 p1.bmi\t# bmi被@property伪装成了一个数据属性，因此调用时不用加() # p1.bmi对应的是一个函数，所以不能被赋值 # For Example： class User(object): def __init__(self, username, password): self.username = username self.__password = password # 私有实例变量 @property\t# 将password方法伪装成一个属性，达到只能看，不能改的效果 def password(self): \u0026#39;\u0026#39;\u0026#39; 定义一个password方法，只能看，不能改 :return: \u0026#39;\u0026#39;\u0026#39; return self.__password user = User(\u0026#39;Python\u0026#39;, \u0026#39;123\u0026#39;) pwd = user.password\t# 调用者以为password是个属性，但其实只能看，不能改 print(pwd) # 123  封装之property的进阶用法\r#\r\rclass Goods(object): \u0026#39;\u0026#39;\u0026#39; 这是一个商品类： 有商品名称，商品价格以及折扣 可以进行商品价格的调整，如打折和涨价 \u0026#39;\u0026#39;\u0026#39; discount = 0.8 # 折扣 def __init__(self, name, original_price): self.name = name self.__orig_price = float(original_price) @property # 将price伪装成属性 def price(self): \u0026#39;\u0026#39;\u0026#39; 这是一个实现商品价格折扣的方法 :return: 商品折扣的价格 \u0026#39;\u0026#39;\u0026#39; return self.__orig_price * self.discount @price.setter # @后面的名字必须与上面的方法名称price一样，被装饰的方法可以传入一个值 def price(self, new_value): # 定义的新方法名字必须与上面的方法名price一样 \u0026#39;\u0026#39;\u0026#39; 这是一个实现商品改变原价的方法 :param new_value: :return: 原价变动后的价格 \u0026#39;\u0026#39;\u0026#39; self.__orig_price = float(new_value) @price.deleter # @后面的名字必须与上面的方法名称price一样 def price(self): del self.__orig_price iphone12 = Goods(\u0026#39;iPhone12\u0026#39;, 12000) print(iphone12.price) # 调用的是被@property装饰的price 输出结果：9600.0 iphone12.price = 13000.0 # 调用的是被@price.setter装饰的price print(iphone12.price) # 输出结果：10400.0 del iphone12.price # 调用的是被@price.deleter装饰的price  封装之classmethod\r#\r\r classmethod是一个装饰器，用于装饰类中的方法，被装饰的方法会成为一个类方法。\n 应用场景：定义一个方法，默认传self，但这个self没被使用，并且在这个方法里用到了类名调用属性的时候，需要使用classmethod。\nclass Goods(object): \u0026#39;\u0026#39;\u0026#39; 这是一个商品类 \u0026#39;\u0026#39;\u0026#39; __discount = 0.8 def __init__(self, name, original_price): self.name = name self.__orig_price = float(original_price) self.price = self.__orig_price * Goods.__discount @classmethod # 把一个对象的绑定方法，修改成类方法 def change_discount(cls, new_discount): # cls会把类本身传进来，cls = Goods \u0026#39;\u0026#39;\u0026#39; 这是一个修改折扣的方法 此方法中self实际上没有被使用 :param new_discount: :return: \u0026#39;\u0026#39;\u0026#39; # Goods.__discount = new_discount cls.__discount = new_discount\t# 调用类中的静态变量 Goods.change_discount(0.6)\t# 不用实例化，直接用类名调用方法 iPhone = Goods(\u0026#39;iPhone\u0026#39;, 13000) print(iPhone.price) import time class Date(object): def __init__(self, year, month, day): self.year = year self.month = month self.day = day @classmethod def today(cls): struct_time = time.localtime() date = cls(struct_time.tm_year, struct_time.tm_mon, struct_time.tm_mday) return date today_obj = Date.today() print(today_obj.year) # 调的是self.year = 2020 print(today_obj.month) # 调的是self.month = 3 print(today_obj.day) # 调的是self.day = 13  封装之staticmethod\r#\r\r staticmethod是一个装饰器，用于装饰类中的方法，被装饰的方法会成为一个静态方法。\n 应用场景：类外部的一个普通函数，需要放到类中，仍然保持普通函数的状态，需要使用staticmethod。一般纯面向对象编程中才会用到，不常用。\n 能定义在类中的内容\n 静态变量：所有对象共享的变量，由对象或类调用，不能重新赋值。 绑定方法：自带self的函数，由对象调用。 property属性：伪装成属性的方法，由对象调用，但不加()。 类方法：自带cls的函数，由对象或类调用。 静态方法：就是一个普通函数，由对象或类调用。  class People(object): country = \u0026#39;中国\u0026#39; # 静态变量 def func(self): # 绑定方法 print(self.__dict__) @property def property_func(self): # property属性 return \u0026#39;property属性\u0026#39; @classmethod def class_func(cls): # 类方法 print(cls) @ staticmethod def static_func(): # 静态方法 print(\u0026#39;不用穿self，就是一个普通函数\u0026#39;)  多态（是一种概念）\r#\r\r  在Python中一切皆对象，处处是多态。 多态指的是同一种事物的多种形态，在程序中用继承可以表现出多态。 多态性：可以在不考虑对象具体类的形况下直接参考基类的标准使用对象。   鸭子类型\r#\r\r  Duck typing 这个概念来源于美国印第安纳州的诗人詹姆斯·惠特科姆·莱利（James Whitcomb Riley,1849-1916）的诗句：\u0026quot; When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.\u0026quot; 翻译：“当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。” 在鸭子类型中，关注的不是对象的类型本身，而是它是如何使用的。\u0026ldquo;鸭子类型\u0026quot;像多态一样工作，但是没有继承。 在Python中崇尚“鸭子类型”。所谓的“鸭子类型”可以这么理解，现在我规定，只要你会用Python写程序，你就是Python程序员，而不必去考Python认证证明你是Python程序员。比如：一个对象中只要有__iter__方法，那么这个对象就是可迭代对象；一个对象只要含有__iter__方法和__next__方法，那么这个对象就是迭代器；而不用去继承什么，证明什么，只要你符合我的标准，你就是我想要的！   "},{"id":21,"href":"/docs/Python/Python%E4%B9%8B%E5%8F%8D%E5%B0%84/","title":"Python之反射","section":"Python","content":"反射的定义\r#\r\r 通过字符串来操作类与对象的属性(attribute)、实例变量、绑定方法等操作，称之为反射。\n 反射的作用\r#\r\r 想通过变量的字符串类型的名字，直接调用变量的时候，就需要用到反射。\n 反射语法\r#\r\r 以下四个内置函数是专门通过字符串来操作类与对象属性的：\n hasattr(object, 'name') 函数用于判断name在不在类object中，等同于print('name' in object.__dict__)。 getattr(object, 'name', None) 函数用于返回一个对象属性值，等于调用 object.name ,如果没有属性或属性没有值，就返回None，一般getattr()会与hasattr()成对出现。 setattr(object, 'name_1', 'name_2') 函数用于修改属性的值。 delattr(object, 'name') 函数用于删除属性的值。   object：对象\n\u0026lsquo;name\u0026rsquo;：对象属性的字符串\n  反射的使用方法（场景）\r#\r\r 反射对象的实例变量和绑定方法\nclass User(object): \u0026#39;\u0026#39;\u0026#39; 定义一个用户类 \u0026#39;\u0026#39;\u0026#39; def __init__(self): self.username = \u0026#39;徐凤年\u0026#39; self.password = \u0026#39;123\u0026#39; # 实例化 user = User() # 通过内置函数getatter()进行反射 徐凤年 = getattr(user, \u0026#39;username\u0026#39;) print(徐凤年)\t# 得到的是self.username的值  反射类的属性和方法\nclass User(object): a = \u0026#39;Python\u0026#39; def __init__(self): pass user = User() res = getattr(user, \u0026#39;a\u0026#39;) print(res)\t# Python  反射模块中的所有变量\nfrom abc import ABCMeta, abstractclassmethod import sys class Payment(metaclass=ABCMeta): def __init__(self, name): self.name = name @abstractclassmethod def pay(self): pass class AliPay(Payment): def pay(self, amount): print(F\u0026#39;{self.name}通过支付宝支付：{amount}元\u0026#39;) class WeChatPay(Payment): def pay(self, amount): print(F\u0026#39;{self.name}通过微信支付：{amount}元\u0026#39;) class ApplePay(Payment): def pay(self, amount): print(F\u0026#39;{self.name}通过苹果支付：{amount}元\u0026#39;) # 归一化设计：让调用者不用实例化对象 def pay(name, payment_method, amount): # if payment_method == \u0026#39;AliPay\u0026#39;: # obj = AliPay(name) # obj.pay(amount) # # elif payment_method == \u0026#39;WeChatPay\u0026#39;: # obj = WeChatPay(name) # obj.pay(amount) # # elif payment_method == \u0026#39;ApplePay\u0026#39;: # obj = ApplePay(name) # obj.pay(amount) # 通过反射完成上面的代码： if hasattr(sys.modules[\u0026#39;__main__\u0026#39;], payment_method): # 判断是否有payment，避免报错 pay_name = getattr(sys.modules[\u0026#39;__main__\u0026#39;], payment_method) # 将字符串类型的payment_method转化成类名称 if callable(pay_name): # 判断pay_name是否可调用，避免报错 obj = pay_name(name) # obj = payment_method(name) obj.pay(amount) # 其他程序员调用归一化设计的支付接口 pay(\u0026#39;马云\u0026#39;, \u0026#39;AliPay\u0026#39;, 10000) # 马云通过支付宝成功支付：10000元 pay(\u0026#39;马化腾\u0026#39;, \u0026#39;WeChatPay\u0026#39;, 10000) # 马化腾通过微信成功支付：10000元 pay(\u0026#39;乔布斯\u0026#39;, \u0026#39;ApplePay\u0026#39;, 10000) # 乔布斯通过苹果成功支付：10000元  练习：\n# 循环列表l # 显示序号，用户要做的操作 # 用户输入序号 # 通过用户输入的序号找到对应的login或者register # 先实例化，再调用相应的绑定方法，完成登录或注册 class Authentication(object): l = [(\u0026#39;登录\u0026#39;, \u0026#39;login\u0026#39;), (\u0026#39;注册\u0026#39;, \u0026#39;register\u0026#39;), (\u0026#39;退出\u0026#39;, \u0026#39;quit\u0026#39;)] def __init__(self): pass def login(self): print(\u0026#39;loggin\u0026#39;) def register(self): print(\u0026#39;register\u0026#39;) while 1: for i, element in enumerate(Authentication.l,1): print(i, element[0]) user_input = int(input(\u0026#39;请输入执行功能的序号：\u0026#39;).strip()) if user_input \u0026lt;= len(Authentication.l): if user_input == 3: break else: func = Authentication.l[int(user_input)-1][1] authen = Authentication() if hasattr(authen, func): getattr(authen, func)()  "},{"id":22,"href":"/docs/Python/Python%E4%B9%8B%E5%85%83%E7%B1%BB/","title":"Python之元类","section":"Python","content":"什么是元类\r#\r\r 类的类就是元类，元类创建对象。使用class定义的类，用来产生程序员自己的对象；而class定义的类，是由内置的元类type产生的。\nclass Chinese: # 默认的元类是type country = \u0026#39;China\u0026#39; def __init__(self, name, age, sex): self.name = name self.age = age self.sex = sex  使用class定义类等同于使用以下方式定义类：\nclass_name = \u0026#39;Chinese\u0026#39; class_base = (object,) # 基类为元组 class_body = \u0026#39;\u0026#39;\u0026#39; country = \u0026#39;China\u0026#39; def __init__(self, name, age, sex): self.name = name self.age = age elf.sex = sex \u0026#39;\u0026#39;\u0026#39; class_dic = {} exec(class_body, {}, class_dic) # 产生类的名称空间 # 类的三大要素，类名，基类，类的名称空间 Chinese = type(class_name, class_base, class_dic)  为什么要有元类\r#\r\r 控制类的创建和行为。\n怎么样自定义元类\r#\r\r class MyMetaclass(type): # 继承type并且可以派生 def __init__(self, class_name, class_base, class_dic): # self=Foo if not class_name.istitle(): # 可以控制创建类时名字的命名规范 raise TypeError(\u0026#39;类的名字必须首字母大写\u0026#39;) if not class_dic.get(\u0026#39;__doc__\u0026#39;): raise TabError(\u0026#39;创建类必须写好描述信息\u0026#39;) super(MyMetaclass, self).__init__(class_name, class_base, class_dic) def __call__(self, *args, **kwargs): # 当执行 Foo(1) 时会做以下事情： # 1.创造一个空对象obj obj = object.__new__(self) # 2.调用 Foo.__init__,并将obj连同Foo括号内的参数一同传给Foo.__init__(self.y) self.__init__(obj, *args, **kwargs) return obj pass class Foo(object,metaclass = MyMetaclass): # 由于Python中一切皆对象，因此Foo是元类type实例化而来，默认实例化通过Foo=type(\u0026#39;Foo\u0026#39;,(object,),class_dic)完成，现在是Foo=MyMetaclass(\u0026#39;Foo\u0026#39;,(object,),class_dic)完成实例化 \u0026#39;\u0026#39;\u0026#39; 描述信息 \u0026#39;\u0026#39;\u0026#39; x = 1 def __init__(self, y): self.y = y def f(self): print(\u0026#39;from f\u0026#39;) print(Foo.__doc__) # 查看类的描述信息 Foo(1)  单例模式\r#\r\r 单个实例，节省内存，单例模式用在对象内存的数据属性是一样的情况下，就没必要开辟新的内存空间了，因此要使用单例模式节省内存。\n "},{"id":23,"href":"/docs/Python/Python%E4%B9%8B%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","title":"Python之异常处理","section":"Python","content":"什么是异常处理\r#\r\r 异常就是程序运行时发生错误的信号（在程序出现错误时，则会产生一个异常，若程序没有处理它，则会抛出该异常，程序的运行也随之终止）。一个异常分为三部分：异常的追踪信息，异常的类型，异常的值。\n 异常的分类：\n 语法异常：Python在执行代码前会检查语法，如果有语法异常，应该在程序执行前就改正。 逻辑异常：  AttributeError：试图访问一个对象没有的树形，比如foo.x，但是foo没有属性x。 IOError：输入/输出异常；基本上是无法打开文件。 ImportError：无法引入模块或包；基本上是路径问题或名称错误。 IndentationError： 语法错误（的子类） ；代码没有正确对齐。 IndexError：下标索引超出序列边界，比如当x只有三个元素，却试图访问x[5]。 KeyError ：试图访问字典里不存在的键。 KeyboardInterrupt：Ctrl+C被按下。 NameError：使用一个还未被赋予对象的变量。 SyntaxError：Python代码非法，代码不能编译(个人认为这是语法错误，写错了）。 TypeError：传入对象类型与要求的不符合。 UnboundLocalError # 试图访问一个还未被设置的局部变量，基本上是由于另有一个同名的全局变量，导致你以为正在访问它。 ValueError：传入一个调用者不期望的值，即使值的类型是正确的。     为什么会有异常处理\r#\r\r 为了保证程序的健壮性与容错性，即在遇到错误时程序不会崩溃，因此我们需要对异常进行处理。\n 异常处理怎么用\r#\r\r 如果明确知道错误发生的条件是什么，我们需要用if进行处理（在错误发生之前进行预防）。\nAGE = 10\t# 字母大写，定义一个常量 while True: age = input(\u0026#39;\u0026gt;\u0026gt;: \u0026#39;).strip() if age.isdigit(): # 只有在age为字符串形式的整数时,下列代码才不会出错,该条件是可预知的 age = int(age) if age == AGE: print(\u0026#39;You Got It！\u0026#39;) break  如果不确定错误发生的条件是什么，则需要用到try...except...（在错误发生之后进行处理）。\n基本语法：\ntry: pass # 被检测的代码块 except \u0026#39;异常类型\u0026#39;： # except Exception as e: 为万能异常 pass # try中一旦检测到异常，就执行这个位置的逻辑 else: # 可以不加，不能单独使用，必须与except连用，在被监测的代码块没有出现任何异常的情况下执行 pass finally: # 可以不加，无论有没有异常发生都会执行里面的内容，通常用于回收资源 pass  主动触发异常\n基本语法：\nraise TypeError(\u0026#39;错误类型\u0026#39;) # 定制语法规则，不符合的就不让程序继续运行  断言\nlist = [] assert len(list) \u0026gt; 0 \u0026#39;\u0026#39;\u0026#39; assert等同于: if len(list) \u0026gt; 0: raise TypeError(\u0026#39;list中必须有值才能执行后面的代码\u0026#39;) \u0026#39;\u0026#39;\u0026#39; print(\u0026#39;...\u0026#39;)  自定义异常\nclass RegisterError(BaseException): # BaseException 是所有异常的基类 pass raise RecursionError(\u0026#39;注册失败\u0026#39;)  什么时候用异常处理\r#\r\r 异常处理要尽量少用，能不用就不用，当错误发生的条件不可预知再使用。\n "},{"id":24,"href":"/docs/Python/Python%E5%86%85%E7%BD%AE%E7%9A%84%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95/","title":"Python内置的魔术方法","section":"Python","content":"__call__方法\r#\r\r 在调用对象时（实例化的对象加括号），会自动触发类中的__call__方法。一个对象能不能在后面加括号调用，就看这个对象所在的这个类中有没有__call__方法。\nclass Foo(object): def __call__(self, *args, **kwargs): print(\u0026#39;自动触发__call__方法\u0026#39;) foo = Foo() foo() # 自动触发__call__方法  __len__方法\r#\r\r 使用len(obj)时，会自动触发类中的__len__方法。需要实现len(obj)这种用法时，类中就一定要有__len__方法。\nclass Foo(object): def __init__(self): self.list = [] def __len__(self): return len(self.list) foo = Foo() foo.list.append(1) foo.list.append(2) foo.list.append(3) print(len(foo.list)) # 3  __new__方法\r#\r\r __new__是一个构造方法，在实例化对象时为对象开辟的空间，创建的类指针，用的就是__new__方法。__new__方法常见于单例模式，即无论实例化多少次，都只开辟一次空间。\nclass Foo(object): __identification = None def __new__(cls, *args, **kwargs): if cls.__identification is None: cls.__identification = object.__new__(cls) return cls.__identification def __init__(self, name, age): self.name = name self.age = age foo_1 = Foo(\u0026#39;A\u0026#39;, 1) print(foo_1) # \u0026lt;__main__.Foo object at 0x000001D0B98D6C10\u0026gt; foo_2 = Foo(\u0026#39;B\u0026#39;, 2) print(foo_2) # \u0026lt;__main__.Foo object at 0x000001D0B98D6C10\u0026gt; # 注意：在Python中通过模块导入是实现单例模式最简单的方法。  __str__方法\r#\r\r 在print对象时，自动触发__str__方法，并且必须返回一个字符串类型。__repr__与__str__功能相似，用str(obj)时，总是优先调用__str__方法，当，__str__不存在，则会调用__repr__方法；用repr(obj)时，调用__repr__方法，__repr__方法不存在，则返回对象的内存地址。\nclass User(): def __init__(self, name, age, sex): self.name = name self.age = age self.sex = sex def __str__(self): # 当执行print(obj)时会自动执行 __str__() 方法 return F\u0026#39;\u0026lt;姓名:{self.name}年龄：{self.age}性别：{self.sex}\u0026gt;\u0026#39; obj = User(\u0026#39;Python\u0026#39;,18,\u0026#39;male\u0026#39;) print(obj) # 此时相当于调用print(obj.__str__())  __del__方法\r#\r\r 在对象被删除时，自动触发执行，可用于回收系统资源，也称为\u0026quot;析构函数\u0026quot;。\nclass MySQL(object): def __init__(self, ip, port): self.ip = ip self.port = port self.conn = connect(ip, port) # 模拟连接，需要申请系统资源 def __del__(self): self.conn.close() # 当Python程序执行完毕后，会清空所有Python占用的内存，但不会回收系统占用的内存，此时self.conn被删除后，触发 __del__() 的执行，回收系统资源 obj = MySQL(\u0026#39;127.0.0.1\u0026#39;, 3306)  "},{"id":25,"href":"/docs/Python/Python%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","title":"Python网络编程","section":"Python","content":"什么是socket\r#\r\r Socket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个“门面模式”，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。\n 基于文件类型的套接字家族：\n套接字家族的名字：AF_UNIX Unix中一切皆文件，基于文件的套接字调用的就是底层的文件系统来取数据，两个套接字进程运行在同一机器，可以通过访问同一个文件系统间接完成通信。\n 基于网络类型的套接字家族：\n套接字家族的名字：AF_INET 还有AF_INET6被用于IPv6，还有一些其他的地址家族，不过，他们要么是只用于某个平台，要么就是已经被废弃，或者是很少被使用，或者是根本没有实现，所有地址家族中，AF_INET是使用最广泛的一个，Python支持很多种地址家族，但是由于我们只关心网络编程，所以大部分时候我么只使用AF_INET。\n 为什么要用socket\r#\r\r 使用socket，我们无需深入理解TCP或UDP协议，socket已经为我们封装好了，我们只需要遵循socket的规则去编程，写出的程序自然就是遵循TCP或UDP标准的。\n 基于TCP协议的socket（无并发）\r#\r\r 服务端\n# tcp是基于可靠链接的，必须先启动服务端，然后再启动客户端去链接服务端 import socket # 由于 socket 模块中有太多的属性。因此可以使用\u0026#39;from module import *\u0026#39;语句。也就是 \u0026#39;from socket import *\u0026#39;,这样我们就把 socket 模块里的所有属性都带到我们的命名空间里了,这样能大幅减短代码。 # from socket import * # socket_server = socket(AF_INET, SOCK_STREAM) socket_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 创建服务器套接字，SOCK_STREAM流式协议，指的是TCP协议；SCOK_DGRAM数据报协议,指的是UDP协议。 # socket_server = socket.socket(family=socket.AF_INET, type=socket.SOCK_STREAM) socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8080)) # 把地址绑定到套接字，只有服务端需要绑定，IP地址填写服务器IP，端口是数字类型，1025-65530任选，端口0-1024系统占用 socket_server.listen(5) # 监听链接，backlog = 5 表示同一时间能接受5个请求，并不是最大连接数 # 等待连接 conn, client_address = socket_server.accept() # 程序阻塞，等待连接，有两个参数,一个连接对象conn，一个客户端地址client_address（包含IP和端口），对象conn是tcp三次握手的产物，用来收发消息，而socket_server对象是专门用来建立连接的 # 收发消息 msg = conn.recv(1024) # 收消息，有个返回值给msg，1024是一个最大的限制，表示最多能收 1024 bytes conn.send(\u0026#39;Hello!!!\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) # 发消息，网络中只能传输bytes类型 conn.close() # 断开（关闭）客户端套接字，回收系统资源。完成TCP四次挥手。 socket_server.close() # 断开（关闭）服务器套接字，回收系统资源  客户端\nimport socket socket_client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 创建客户端套接字，SOCK_STREAM流式协议，指的是TCP协议；SCOK_DGRAM数据报协议,指的是UDP协议。 socket_client.connect((\u0026#39;127.0.0.1\u0026#39;, 8080)) # 与服务器建立连接，地址为服务器的IP地址和端口号 socket_client.send(\u0026#39;Hello!\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) # 发消息，注意字符串不能直接直接发，需要转换成二进制 msg = socket_client.recv(1024) # 收消息 socket_client.close()  加上通信循环和连接循环的socket（无并发）\r#\r\r  解决服务端不可以循环接收客户端信息的问题\n  服务端\nimport socket socket_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 如果什么参数都不传，默认就是这个 socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8080)) socket_server.listen(5) while True: # 加连接循环 conn, client_address = socket_server.accept() while True: # 加通信循环 try: msg = conn.recv(1024) if not msg: break # 针对Linux操作系统 print(\u0026#39;客户端：\u0026#39;, client_address) conn.send(msg + b\u0026#39;_SB\u0026#39;) except ConnectionResetError: break conn.close() socket_server.close() 客户端\nimport socket socke_client = socket.socket(socket.AF_INET, socket.SOCK_STREAM) socke_client.connect((\u0026#39;127.0.0.1\u0026#39;, 8080)) while True: msg = input(\u0026#39;\u0026gt;\u0026gt;\u0026gt;:\u0026#39;) socke_client.send(msg.encode(\u0026#39;utf-8\u0026#39;)) msg = socke_client.recv(1024) print(msg) socke_client.close()  远程执行命令的小程序（无并发）\r#\r\r 服务端\nfrom socket import * import subprocess import struct # Python提供了一个struct模块来解决str和其他二进制数据类型的转换。struct的pack函数把任意数据类型变成字符串 socket_server = socket(AF_INET, SOCK_STREAM) socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8080)) socket_server.listen(5) while True: conn, client_address = socket_server.accept() print(\u0026#39;正在监听……\u0026#39;) while True: try: cmd = conn.recv(1024) if not cmd: break print(\u0026#39;开始接收文件……\u0026#39;) obj = subprocess.Popen(cmd.decode(\u0026#39;utf-8\u0026#39;), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE ) res_stdout = obj.stdout.read() res_stderr = obj.stderr.read() except ConnectionResetError: break # -*- 解决TCP粘包问题 -*-# # 制作固定长度的报头 total_size = len(res_stdout) + len(res_stderr) header = struct.pack(\u0026#39;i\u0026#39;, total_size) # 制作固定长度的报头 # 发送报头 conn.send(header) # conn.send(res_stdout + res_stderr) # 由于TCP的优化，使用了Nagle算法，将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包，实际上以下两条命令会合并到一起发送。 conn.send(res_stdout) conn.send(res_stderr) conn.close() socket_server.close()  客户端\nfrom socket import * import struct socket_client = socket(AF_INET, SOCK_STREAM) socket_client.connect((\u0026#39;127.0.0.1\u0026#39;, 8080)) while True: cmd = input(\u0026#39;\u0026gt;\u0026gt;\u0026gt;:\u0026#39;) if not cmd: continue # 判断cmd不为空，if x is not None:continue 是最好的写法 socket_client.send(cmd.encode(\u0026#39;utf-8\u0026#39;)) # -*- 解决TCP粘包问题 -*-# # 先收固定长度的报头 header = socket_client.recv(4) # 解析报头 total_size = struct.unpack(\u0026#39;i\u0026#39;, header)[0] # 根据报头，收取数据，为防止数据过大，撑爆内存，以小单位循环收取 recv_size = 0 res = b\u0026#39;\u0026#39; while recv_size \u0026lt; total_size: recv_date = socket_client.recv(1024) res += recv_date recv_size += len(recv_date) # info = socket_client.recv(1024) print(res.decode(\u0026#39;gbk\u0026#39;)) socket_client.close()  远程执行命令的小程序（自定义报头，无并发）\r#\r\r 服务端\nfrom socket import * import subprocess import struct # Python提供了一个struct模块来解决str和其他二进制数据类型的转换。struct的pack函数把任意数据类型变成字符串 import json socket_server = socket(AF_INET, SOCK_STREAM) socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8081)) socket_server.listen(5) while True: conn, client_address = socket_server.accept() print(\u0026#39;正在监听……\u0026#39;) while True: try: cmd = conn.recv(1024) if not cmd: break print(\u0026#39;开始接收文件……\u0026#39;) obj = subprocess.Popen(cmd.decode(\u0026#39;utf-8\u0026#39;), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE ) res_stdout = obj.stdout.read() res_stderr = obj.stderr.read() except ConnectionResetError: break # 制作报头 header_dic = {\u0026#39;total_size\u0026#39;: len(res_stdout) + len(res_stderr), \u0026#39;md5\u0026#39;: \u0026#39;xxxxxxxxxxxx\u0026#39;, \u0026#39;filename\u0026#39;: \u0026#39;xxx.py\u0026#39;} header_json = json.dumps(header_dic) # 将字典转换成字符串 header_bytes = header_json.encode(\u0026#39;utf-8\u0026#39;) # 将字符串转换成 # 获取报头长度 header_size = len(header_bytes) # 发送报头 conn.send(struct.pack(\u0026#39;i\u0026#39;, header_size)) # conn.send(res_stdout+res_stderr) # 由于TCP的优化，使用了Nagle算法，将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包，实际上以下两条命令会合并到一起发送。 # 发送数据 conn.send(res_stdout) conn.send(res_stderr) conn.close() socket_server.close()  客户端\nfrom socket import * import struct import json socket_client = socket(AF_INET, SOCK_STREAM) socket_client.connect((\u0026#39;127.0.0.1\u0026#39;, 8081)) while True: cmd = input(\u0026#39;\u0026gt;\u0026gt;\u0026gt;:\u0026#39;) if not cmd: continue # 判断cmd不为空，if x is not None:continue 是最好的写法 socket_client.send(cmd.encode(\u0026#39;utf-8\u0026#39;)) # 先收报头的长度 header_size = struct.unpack(\u0026#39;i\u0026#39;, socket_client.recv(4))[0] # 接收报头 header_bytes = socke_client.recv(header_size) # 解析报头 header_json = header_bytes.decode(\u0026#39;utf-8\u0026#39;) header_dic = json.loads(header_json) total_size = header_dic[\u0026#39;total_size\u0026#39;] # 根据报头，收取数据，为防止数据过大，撑爆内存，以小单位循环收取 recv_size = 0 res = b\u0026#39;\u0026#39; while recv_size \u0026lt; total_size: recv_date = socke_client.recv(1024) res += recv_date recv_size += len(recv_date) # info=socket_client.recv(1024) print(res.decode(\u0026#39;gbk\u0026#39;)) socket_client.close()  基于TCP协议的文件上传程序\r#\r\r 服务端\n#!/usr/bin/env python # -*- coding:utf-8 -*- # 上传文件的服务端 import socket import json import struct socket_server = socket.socket() socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) socket_server.listen(5) conn, _ = socket_server.accept() # 先收file_dic_json_size，格式为一个元组 msg_len = conn.recv(4) # 得到file_dic_json的长度 file_dic_json_len = struct.unpack(\u0026#39;i\u0026#39;, msg_len)[0] # 按照file_dic_json的长度接收file_dic_json msg_recv = conn.recv(file_dic_json_len) # 解析file_dic_json，得到file_dic msg = json.loads(msg_recv) with open(msg[\u0026#39;file_name\u0026#39;], mode=\u0026#39;wb\u0026#39;) as f: while msg[\u0026#39;file_size\u0026#39;] \u0026gt; 0: content = conn.recv(1024) msg[\u0026#39;file_size\u0026#39;] -= len(content) f.write(content) conn.close() socket_server.close()  客户端\n#!/usr/bin/env python # -*- coding:utf-8 -*- import socket import os import json import struct socket_client = socket.socket() socket_client.connect((\u0026#39;127.0.0.1\u0026#39;, 8000)) # 获取文件路径 file_path = input(\u0026#39;请输入文件的绝对路径：\u0026#39;).strip() # 获取文件名 file_name = os.path.basename(file_path) # 获取文件大小 file_size = os.path.getsize(file_path) # 将文件名和文件大小制作成字典 file_dic = {\u0026#39;file_name\u0026#39;:file_name, \u0026#39;file_size\u0026#39;:file_size} # 将文件名和文件大小的字典生成json，用于网络传输 file_dic_json = json.dumps(file_dic).encode(\u0026#39;utf-8\u0026#39;) # ------ 避免粘包问题 ------ # # 通过struct.pack()将file_dic_json的二进制文件长度制作成4个字节 file_dic_json_size = struct.pack(\u0026#39;i\u0026#39;, len(file_dic_json)) # 先发送file_dic_json_size，长度为4个字节 socket_client.send(file_dic_json_size) # 再发送 socket_client.send(file_dic_json) with open(file_path, mode=\u0026#39;rb\u0026#39;) as f: while file_size \u0026gt; 0: content = f.read(1024) file_size -= len(content) socket_client.send(content) socket_client.close()  基于UDP的socket\r#\r\r 数据报协议（UDP）没有粘包问题，UDP协议面向无连接，发送数据，无需对方确认，发送效率高，但UDP协议有效传输数据大小为 512 bytes，超过这个大小就非常容易丢包，DNS服务使用UDP协议，由于这个限制，导致全球根服务器数量限制在13台。\n 服务端\nimport socket # socket_server = socket.socket(family=socket.AF_INET, type=socket.SOCK_DGRAM) socket_server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8080)) while True: client_msg, client_address = socket_server.recvfrom(1024) # recvfrom()会接收信息和发送端的地址 print(client_msg.decode(\u0026#39;utf-8\u0026#39;)) socket_server.sendto(client_msg.upper(), client_address) # sendto(\u0026#39;字符串\u0026#39;, (\u0026#39;IP地址\u0026#39;, 端口号))  客户端\nimport socket socket_client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) udp_server = (\u0026#39;127.0.0.1\u0026#39;, 8080) while True: msg = input(\u0026#39;\u0026gt;\u0026gt;\u0026gt;:\u0026#39;).strip() socket_client.sendto(msg.encode(\u0026#39;utf-8\u0026#39;), udp_server)\t# sendto(\u0026#39;字符串\u0026#39;, (\u0026#39;IP地址\u0026#39;, 端口号)) server_msg = socket_client.recv(1024) print(server_msg.decode(\u0026#39;utf-8\u0026#39;))  "},{"id":26,"href":"/docs/Python/Python%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%B9%8Bsocketserver%E6%A8%A1%E5%9D%97/","title":"Python网络编程之socketserver模块","section":"Python","content":"socketserver模块与socket模块的关系\r#\r\r socketserver模块是基于socket模块开发的，socket模块是socketserver的底层模块。\n socketserver模块的用途\r#\r\r socketserver模块主要用来处理并发的TCP客户端请求。（如果自己能写出来比socketserver更好的模块，可以用自己的，但在此之前，所有的TCP服务端都应该使用socketserver模块）\n socketserver模块的使用方法（服务端）\r#\r\r import socketserver # 必须先自定义一个类,并且必须继承socketserver.BaseRequestHandler类 class MySocketServer(socketserver.BaseRequestHandler): # 必须定义个handle方法，所有客户端发起连接请求都会先调用handle()方法 def handle(self): conn = self.request # 与客户端建立连接 pass # 客户端连接成功后执行的代码，例如：登录、上传、下载等 # 多线程实例化对象 server = socketserver.ThreadingTCPServer((\u0026#39;127.0.0.1\u0026#39;,9000), MySocketServer) # 使程序一直运行 server.serve_forever()  "},{"id":27,"href":"/docs/Python/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E8%BF%9B%E7%A8%8B/","title":"Python并发编程之进程","section":"Python","content":"什么是进程\r#\r\r 进程是一个抽象的概念，进程的概念起源于操作系统，是正在进行的一个过程或者一个过程的总和，而负责执行过程的则是CPU。\n 进程与程序的区别\n程序仅仅只是一堆文件、一堆代码而已，而进程指的是程序的运行过程或过程的总和。即程序放在硬盘里没有运行叫做程序，程序运行起来就叫做进程。进程是计算机中最小的资源分配单位。\n 并发与并行\r#\r\r 无论是并行还是并发，在用户看来都是“同时”运行的，不管是进程还是线程，都只是一个任务而已，真是干活的是CPU，CPU来做这些任务，而一个CPU同一时刻只能执行一个任务。\n**并发：**是伪并行，即看起来是同时运行。单个CPU + 多道技术就可以实现并发，也就是说多个程序轮流再一个CPU上执行，其本质仍是串行，只不过多个程序的切换的非常快，因此看起来就像是同时运行一样（并行也属于并发）。\n**并行：**多个程序同时执行，并且是在多个CPU上同时执行的。因此只有具备多个CPU才能实现并行。\n 多道技术\r#\r\r 多道技术中的多道指的是多个程序，多道技术的实现是为了解决多个程序竞争同一资源（例如：CPU）的有序调度问题，解决方式为多路复用，多路复用分为时间上的复用和空间上的复用。多道的产生背景是想要在单核CPU的情况下实现多个进程并发执行，具有两大核心特点：\n 空间上的复用（多道程序复用内存的空间）：多道程序同时读入内存，等待被CPU执行，即产生了多个进程；进程之间的内存地址空间是相互隔离的，而且这种隔离是物理级别实现的。 时间上的复用（多道程序复用CPU的时间）：正在执行的进程遇到了I/O操作 或 正在执行的进程占用CPU时间过长 或 来了一个优先级更高的进程，操作系统都会强制收回当前进程的CPU使用权限，并将其分配给其他进程。  因此，若要提升程序的执行效率，需要减少或降低I/O操作。\n 进程的三种状态（三状态图）\r#\r\r  就绪 运行 阻塞   阻塞和非阻塞\r#\r\r 阻塞和非阻塞指的是程序的两种运行状态。\n**阻塞：**遇到I/O就会发生阻塞，程序一旦遇到阻塞就会停在原地，并立刻释放CPU的资源。input、accept、recv、recvfrom、sleep、connect都会引起阻塞，CPU的状态是不工作的。\n**非阻塞：**没有遇到I/O操作，或遇到了I/O操作通过某种手段让程序继续执行其他操作，尽可能多的占用CPU。\n 同步和异步\r#\r\r 同步和异步指的是提交任务的两种方式。\n**同步：**提交完任务后，就在原地等待，直到任务运行完毕后，拿到任务的返回值，才继续执行下一行代码。简单来说，同步就是必须一件一件事做，等前一件做完了才能做下一件事。\n**异步：**提交完任务后，不在原地等待，直接执行下一行代码。对于异步调用，调用的返回并不受调用者控制。\n 进程的调度算法\r#\r\r 给所有进程分配资源或CPU使用权的方法称之为进程的调度算法。\n调度算法有：\n 短作业优先 先来先服务（FCFS：First Come First Servie） 多级反馈算法：多个任务队列，优先级从高到低，新来的任务总是优先级最高的，每一个新任务几乎会立即获得一个时间片的执行时间，执行完一个时间片之后就会降级到下一个队列中，并且优先级越高，时间片越短。   进程的开启\r#\r\r  系统初始化的时候开启 一个进程再运行过程中开启子进程 用户交互式请求，而创建的新进程 一个批处理作业的初始化   进程的结束\r#\r\r  正常退出 报错退出 严重错误（非自愿，执行非法指令，如引用不存在的内存） 被其他进程杀死   开启子进程的两种方式\r#\r\r 第一种（函数）\nfrom multiprocessing import Process import time def task(name): print(F\u0026#39;{name}is running\u0026#39;) time.sleep(3) print(F\u0026#39;{name}is done\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: # 在Windows系统之上，开启子进程的操作一定要放到这下面 # if __name__ == \u0026#39;__main__\u0026#39;的意思是：当.py文件被直接运行时，if __name__ == \u0026#39;__main__\u0026#39;之下的代码块将被运行； # 当.py文件以模块形式被导入时，if __name__ == \u0026#39;__main__\u0026#39;之下的代码块不被运行。 P = Process(target=task, args=(\u0026#39;Python\u0026#39;,)) # 可以通过args为子进程的函数传参，但args=后面必须是一个元组，因此一个参数的时候必须加逗号； # Process(target=task, kwargs={\u0026#39;name\u0026#39;:\u0026#39;Python\u0026#39;}) # kwargs= 后面是一个字典，这两种传参方式任选一种 P.start() # 向操作系统发送申请内存空间请求，注意，是发请求给操作系统，至于操作系统怎么申请内存空间不管，然后把父进程的数据拷贝给子进程，作为子进程的初始状态。异步非阻塞操作，并不会等待子进程执行完毕再继续，而是直接执行下一行代码。 print(\u0026#39;父进程\u0026#39;)  第二种（类，面向对象）\nfrom multiprocessing import Process import time class MyProcess(Process): # 自己定义一个类，并继承Process def __init__(self, name): super(Process, self).__init__() self.name = name def run(self): # 规定必须要定义run方法 print(F\u0026#39;{self.name}is running\u0026#39;) time.sleep(3) print(F\u0026#39;{self.name}is done\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: p = MyProcess(\u0026#39;Python\u0026#39;) p.start() # 规定，start()调用的是MyProcess()中的run(self)方法 print(\u0026#39;父进程\u0026#39;)  基于TCP协议的Socket（并发）\r#\r\r 服务端\nimport socket from multiprocessing import Process def connect(conn): while True: try: msg = conn.recv(1024) msg = msg.decode(\u0026#39;utf-8\u0026#39;) msg = msg.upper().encode(\u0026#39;utf-8\u0026#39;) conn.send(msg) except ConnectionResetError: break conn.close() if __name__ == \u0026#39;__main__\u0026#39;: socket_server = socket.socket() socket_server.bind((\u0026#39;127.0.0.1\u0026#39;, 8000)) socket_server.listen(5) while True: conn, _ = socket_server.accept() p = Process(target=connect, args=(conn,)) p.start() socket_server.close()  客户端\nimport socket socket_client = socket.socket() socket_client.connect((\u0026#39;127.0.0.1\u0026#39;, 8000)) while True: socket_client.send(\u0026#39;hello\u0026#39;.encode(\u0026#39;utf-8\u0026#39;)) msg = socket_client.recv(1024).decode(\u0026#39;utf-8\u0026#39;) print(msg) socket_client.close()  父进程等待子进程结束\r#\r\r 验证进程的内存空间相互隔离\nfrom multiprocessing import Process import time x = 1 # 子进程要执行的代码 def task(): time.sleep(3) global x x = 0 print(\u0026#39;子进程结束\u0026#39;,x) # 打印结果：子进程结束 0 # 开启子进程 if __name__ == \u0026#39;__main__\u0026#39;: p = Process(target=task) p.start() p.join() # 同步阻塞，让父进程等待子进程结束，子进程结束后才会执行下一行代码，也有回收僵尸进程的效果 print(x) # 打印结果：1 # 注意：由于内存空间隔离，因此父进程无法获取子进程的返回值  验证父进程等待子进程结束后才会结束\nfrom multiprocessing import Process import time import random # 子进程要执行的代码 def task(n): print(F\u0026#39;{n}is running\u0026#39;) time.sleep(random.randint(1,10)) # 开启子进程 start_time = time.time() p_l= [] if __name__ == \u0026#39;__main__\u0026#39;: # 申请开启5次子进程 for i in range(5): p = Process(target=task, args=(i,)) p_l.append(p) p.start() # 由于p.start()只是向操作系统申请开辟内存空间，每次的操作系统开辟内存空间的时间程序无法掌控 # 等待所有子进程结束 for p in p_l: p.join() end_time = time.time() print(\u0026#39;父进程\u0026#39;,(end_time - start_time)) \u0026#39;\u0026#39;\u0026#39; 打印机结果： 主进程 2 is running 1 is running 0 is running 4 is running 3 is running 父进程 9.107510566711426 Process finished with exit code 0 \u0026#39;\u0026#39;\u0026#39;  父进程操作子进程的其他属性（方法）\r#\r\r from multiprocessing import Process import time import os # 子进程要执行的代码 def task(): print(\u0026#39;子进程开始，子进程：%s，父进程：%s\u0026#39; %(os.getpid，os.ppid)) time.sleep(3) print(\u0026#39;子进程结束\u0026#39;,x) # 开启子进程 if __name__ == \u0026#39;__main__\u0026#39;: print(os.getpid) #查看父进程的进程号 p = Process(target=task) p.start() print(p.pid) # 查看子进程的进程号 p.terminate() # 向操作系统发送结束子进程请求 time.sleep(1) print(p.is_alive()) # 判断子进程是否存活，返回的是布尔值  僵尸进程与孤儿进程\r#\r\r **僵尸进程：**僵尸进程是当子进程比父进程先结束，而父进程又没有回收子进程，释放子进程占用的资源，此时子进程将成为一个僵尸进程。\n **僵尸进程的危害：**僵尸进程占用进程号，如果存在过多的僵尸进程，很容易导致没有新的进程号提供给要产生的进程。一般来说父进程结束后会调用wait/waitpid来回收僵尸进程，如果父进程没有回收僵尸进程，则僵尸进程变成孤儿进程，然后由init进程进行回收。\n **孤儿进程：**在操作系统领域中，孤儿进程指的是在其父进程执行完成或被终止后仍继续运行的一类进程。这些孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。\n 守护进程\r#\r\r 守护进程(daemon)是一类在后台运行的特殊进程，用于执行特定的系统任务。如果父进程将子进程设置为守护进程，那么在父进程代码运行完毕后（注意：是父进程代码运行完毕，而不是父进程结束），这时，无论守护进程的任务有没有完成，守护进程都会立即结束并被回收。\nFor example: from multiprocessing import Process import time # 子进程代码 def task(name): print(F\u0026#39;{name}is running\u0026#39;) # 父进程代码 if __name__ == \u0026#39;__main__\u0026#39;: obj = Process(target=task,args=(\u0026#39;process\u0026#39;,)) obj.daemon = True # 将obj设置为守护进程，守护进程的特点是当父进程代码运行完毕后，无论自己的任务有没有完成，都随之结束。 obj.start() print(\u0026#39;父进程\u0026#39;)  互斥锁\r#\r\r 在Python编程中，引入了对象互斥锁的概念，来保证共享数据操作的完整性。每个对象都对应于一个可称为\u0026rsquo;互斥锁' 的标记，这个标记用来保证在任一时刻，只能有一个线程访问该对象。\n互斥锁和join的区别：\n 二者原理一样，都是将并发变成串行，从而保证有序；\n  区别一：join是按照人为指定的顺序执行，互斥锁是所有进程平等的竞争，谁先抢到谁执行。 区别二：互斥锁可以让一部分代码（修改共享数据的代码）串行，控制的粒度非常细，细到可以只控制一行代码；而join只能将代码整体串行。  使用互斥锁的注意事项：\n不能在同一个进程中连续使用lock.acquire()多次，必须lock.release()后才可以再次使用lock.acquire()。\n 互斥锁用法一：\nfrom multiprocessing import Process,Lock lock = Lock() # 所有进程共享一把互斥锁 def task_1(lock): lock.acquire() # lock.acquire()获取互斥锁，只有1个互斥锁，谁抢着就是谁的 print(\u0026#39;task-1 is running\u0026#39;) # 获得互斥锁后执行的任意代码 lock.release() # lock.release()释放互斥锁，一定要在操作完毕后释放锁！ def task_2(lock): lock.acquire() # lock.acquire()获取互斥锁，只有1个互斥锁，谁抢着就是谁的 print(\u0026#39;task-2 is running\u0026#39;) # 获得互斥锁后执行的任意代码 lock.release() # lock.release()释放互斥锁，一定要在操作完毕后释放锁！ def task_3(lock): lock.acquire() # lock.acquire()获取互斥锁，只有1个互斥锁，谁抢着就是谁的 print(\u0026#39;task-3 is running\u0026#39;) # 获得互斥锁后执行的任意代码 lock.release() # lock.release()释放互斥锁，一定要在操作完毕后释放锁！ if __name__ == \u0026#39;__main__\u0026#39;: p1 = Process(target=task_1, args=(lock,)) p2 = Process(target=task_2, args=(lock,)) p3 = Process(target=task_3, args=(lock,)) p1.start() p2.start() p3.start()  互斥锁用法二（推荐使用）：\nfrom multiprocessing import Process,Lock def task_1(lock): with lock: # 使用with代替lock.acquire()和lock.release() print(\u0026#39;task-1 is running\u0026#39;) # 获得互斥锁后执行的任意代码 def task_2(lock): with lock: # 使用with代替lock.acquire()和lock.release() print(\u0026#39;task-2 is running\u0026#39;) # 获得互斥锁后执行的任意代码 def task_3(lock): with lock: # 使用with代替lock.acquire()和lock.release() print(\u0026#39;task-3 is running\u0026#39;) # 获得互斥锁后执行的任意代码 if __name__ == \u0026#39;__main__\u0026#39;: lock = Lock() # 所有进程共享一把互斥锁 p1 = Process(target=task_1, args=(lock,)) p2 = Process(target=task_2, args=(lock,)) p3 = Process(target=task_3, args=(lock,)) p1.start() p2.start() p3.start()  互斥锁应用场景之抢票：\nimport os import json import time import random from multiprocessing import Process,Lock mutex_lock = Lock() def search_ticket(): \u0026#39;\u0026#39;\u0026#39; 这是一个车票查询的操作 :return: \u0026#39;\u0026#39;\u0026#39; time.sleep(random.randint(1,3)) with open(\u0026#39;db.json\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: dic = json.load(f) print(F\u0026#39;用户：{os.getpid()}查询到剩余车票：{dic[\u0026#39;count\u0026#39;]}\u0026#39; return dic[\u0026#39;count\u0026#39;] def get_ticket(): \u0026#39;\u0026#39;\u0026#39; 这是一个抢票的操作 :return: \u0026#39;\u0026#39;\u0026#39; with open(\u0026#39;db.json\u0026#39;, mode=\u0026#39;r\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: time.sleep(random.randint(1, 3)) dic = json.load(f) if dic[\u0026#39;count\u0026#39;] \u0026gt; 0: dic[\u0026#39;count\u0026#39;] -= 1 with open(\u0026#39;db.json\u0026#39;, mode=\u0026#39;w\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) as f: json.dump(dic,f) print(\u0026#39;用户：%s购票成功！\u0026#39; %(os.getpid())) else: print(\u0026#39;用户：%s购票失败！\u0026#39; %(os.getpid())) def buy_ticket(): \u0026#39;\u0026#39;\u0026#39; 这是一个购买车票的函数 :return: \u0026#39;\u0026#39;\u0026#39; search_ticket() with mutex_lock: get_ticket() if __name__ == \u0026#39;__main__\u0026#39;: for i in range(10): p = Process(target = buy_ticket) p.start()  IPC机制（Inter Process Communication）\r#\r\r IPC：进程间的数据在内存中是相互隔离的，但进程之间有时需要协同完成工作，例如，一个进程要把自己处理的结果交给另外一个进程，因此，进程之间通信必须找到一种介质，该介质必须满足：\n 是所有进程共享的；（实现进程共享的机制有管道和队列，队列本质是由管道+锁实现） 必须是内存空间； 帮我们处理好锁的问题。  但凡涉及到进程之间通信，就使用队列，队列是IPC机制实现的一种方式。Queue是Socket基于文件级别的进程间通讯。\n 强调：\n 队列是用来存进程之间通信消息的，数据量不应该过大； Queue(maxsize) 中的maxsize的值超过内存限制就变得毫无意义；   from multiprocessing import Queue # 从multiprocessing导入队列，队列特点：先进先出 q = Queue(3, block=True) # maxsize=3，若不指定大小就无限大，受限于内存大小；block=True默认是阻塞。 q.put(\u0026#39;Hello\u0026#39;) q.put({\u0026#39;name\u0026#39;:\u0026#39;HC\u0026#39;}) q.put(100) # q.put(55) 由于maxsize=3，第四个put会引起阻塞 print(q.get()) print(q.get()) print(q.get())  通过Queue进程间通讯示例：\nfrom multiprocessing import Queue,Process def put_process(q): for i in range(5): q.put(i) def get_process(q): for i in range(5): print(F\u0026#39;得到put_process中的:{q.get()}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: q = Queue() p_put = Process(target=put_process, args=(q,)) p_put.start() p_get = Process(target=get_process, args=(q,)) p_get.start()  基于网络的进程间通讯的组件称之为消息中间件，第三方的消息中间件有：\n Memcache Redis RabbitMQ Kafka   "},{"id":28,"href":"/docs/Python/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E7%BA%BF%E7%A8%8B/","title":"Python并发编程之线程","section":"Python","content":"什么是线程\r#\r\r 线程是进程中的执行单位，是能够被计算机操作系统调度CPU执行的最小单位。\n 进程和线程的区别\r#\r\r  进程和线程都可以利用多核。 进程根本就不是一个执行单位，而是一个资源单位，并且是操作系统中的最小资源分配单位，开进程就是在内存中开辟一个空间，将父进程的内容复制过去。一个进程内自带一个线程，而且必须至少有一个线程，线程才是执行单位。 进程在内存中相互隔离；同一进程内的线程共享该进程内资源，不同进程内的线程资源才相互隔离； 进程和线程都存在数据不安全的问题。 创建线程的开销比创建进程小很多，创建线程的速度大约是创建进程速度的100倍；一般情况下我们写的程序，开启的进程数不会超过CPU个数的两倍；而线程的开启没有限制。 进程之间由父子关系，线程之间没有父子关系。 进程可以通过terminate关闭，而线程不能关闭，只能线程执行完毕后才关闭。 在Python中大部分的并发需求都是通过多线程来完成的。   CPython解释器中的GC垃圾回收机制\r#\r\r 在CPython中通过gc线程进行垃圾回收，但由于多核CPU的出现，导致gc线程无法兼顾多个CPU同时调度不同线程线程改变同一个值的引用计数，因此在后来的CPython中加入了GIL（Global Interpreter Lock）全局解释器锁。\n Python GIL（Global Interpreter Lock）全局解释器锁\r#\r\r CPython线程管理机制不是安全的，为了规避多个线程同时操作一个数据导致的安全问题，因此CPython解释器引入了GIL（全局解释器锁），GIL本质就是一把加在解释器上的互斥锁，每一个Python进程内都有一把GIL。同一进程内的所有线程都需要先抢到GIL，才能执行解释器代码，对所有待执行的线程来说，GIL就相当于执行权限，优点是保证了CPython解释器内存管理的线程安全（垃圾回收线程的安全），但会导致同一进程内所有线程同一时刻只能有一个线程执行，而同一时刻只有一个线程争抢成功，即单进程下的多个线程同时只能有一个在运行，也就是说CPython解释器的多线程无法实现并行，也就无法利用多核优势。多个CPU可以提高计算性能，但无法提高I/O性能，因此多个CPU在I/O操作上毫无优势和作用。不同进程的线程不会争抢同意把GIL，只有同一进程的多个线程才会争抢同一把GIL。即，线程本身是可以利用多核的，但由于CPython解释器的垃圾回收机制，导致线程无法利用多核。\n在CPython解释器中如果想用到多核优势的话（例如计算密集型程序），就需要开多进程，如果是I/O密集型程序使用多线程。由于PyPy与CPython使用的同一中GC垃圾回收机制，因此，PyPy也无法通过多线程使用多核CPU，但JPython由于GC垃圾回收机制与Java相同，因此JPython可以通过多线程使用多核CPU。\n 线程互斥锁与GIL的区别\r#\r\r 二者都是互斥锁，但GIL是加到解释器上的，作用于全局，自定义互斥锁作用域局部。\n单进程内的所有线程都会抢GIL，单进程内只有一部分线程会抢自定义互斥锁。\n 开启线程的两种方式\r#\r\r 方式一：（常规用法）\nfrom threading import Thread def task(name): print(F\u0026#39;{name}is running...\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: t = Thread(target=task, args=(\u0026#39;子线程\u0026#39;,)) t.start() print(\u0026#39;***主线程***\u0026#39;)  方式二：（自定义类，继承Thread类）\nfrom threading import Thread class MyThread(Thread): def run(self): print(\u0026#39;%sis running...\u0026#39; %(self.name)) if __name__ == \u0026#39;__main__\u0026#39;: t = MyThread() t.start() print(\u0026#39;***主线程***\u0026#39;)  主线程等待子线程结束\r#\r\r 通过.join()方法，可以让主线程等待子线程结束后再结束\nimport time from threading import Thread def task(i): print(F\u0026#39;第{i}个线程已开启！\u0026#39;) time.sleep(1) print(F\u0026#39;第{i}个线程已结束！\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: t_l = [] for i in range(1,11): t = Thread(target=task, args=(i,)) t.start() t_l.append(t) # t.join() for t in t_l: t.join() print(\u0026#39;***主线程***\u0026#39;)  查看线程ID\r#\r\r 通过.ident可以查看线程ID\nfrom threading import Thread def task(name): print(\u0026#39;%sis running...\u0026#39; %(name)) if __name__ == \u0026#39;__main__\u0026#39;: t = Thread(target=task, args=(\u0026#39;子线程\u0026#39;,)) t.start() print(F\u0026#39;子线程id为：{t.ident}\u0026#39;) # 通过t.ident可以查看到子线程id  通过current_thread可以在函数里查看线程对象、线程名称、线程ID，current_thread在哪个线程中，获取的就是哪个线程的对象、线程名称和线程ID\nfrom threading import Thread from threading import current_thread def task(name): print(F\u0026#39;{name}is running...\u0026#39;) print(F\u0026#39;{name}的线程对象为：{current_thread()}\u0026#39;) print(F\u0026#39;{name}的线程名称为：{current_thread().getName()}\u0026#39;) print(F\u0026#39;{name}的线程id为：{current_thread().ident}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: t = Thread(target=task, args=(\u0026#39;子线程\u0026#39;,)) t.start()  通过enumerate可以获取一个所有活着线程对象的列表\nimport time from threading import Thread from threading import enumerate # 导入之后会与内置函数enumerate()重名 def task(i): print(F\u0026#39;第{i}个线程已开启！\u0026#39;) time.sleep(1) print(F\u0026#39;第{i}个线程已结束！\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: t_l = [] for i in range(1,11): t = Thread(target=task, args=(i,)) t.start() t_l.append(t) print(enumerate())\t# 当前应该有11个活着的线程对象，其中一个为主线程 for t in t_l: t.join() print(\u0026#39;***主线程***\u0026#39;)  通过active_count可以获取所有活着线程的个数\nimport time from threading import Thread from threading import active_count def task(i): print(F\u0026#39;第{i}个线程已开启！\u0026#39;) time.sleep(1) print(F\u0026#39;第{i}个线程已结束！\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: t_l = [] for i in range(1,11): t = Thread(target=task, args=(i,)) t.start() t_l.append(t) print(active_count()) # 11 for t in t_l: t.join() print(\u0026#39;***主线程***\u0026#39;)  守护线程\r#\r\r  守护线程是一个任务守护另一个任务代码的执行过程。在一个进程内可以开启多个线程，守护线程会在该进程内所有非守护线程都执行完毕后才结束。主线程会等待子线程结束后才结束。并且，主线程结束，主进程就会结束。 守护进程和守护线程的结束原理不同，守护进程需要主进程来回收资源，而守护线程是随着进程的结束而结束的，其他子线程结束-\u0026gt;主线程结束-\u0026gt;主进程结束-\u0026gt;整个进程中所有的资源都会被回收-\u0026gt;守护线程也会被回收   线程互斥锁\r#\r\r 如果多个线程需要操作全局变量和类中的静态变量，有可能产生数据不安全现象，因此，需要对线程加互斥锁，以保证数据安全。如果不想加互斥锁，就要避免操作全局变量和类中的静态变量。\nfrom threading import Thread from threading import Lock import time x = 100 mutex_lock = Lock() def task(): # global x # mutex_lock.acquire() # temp = x # time.sleep(0.1) # x = temp - 1 # print(x) # mutex_lock.release() # 以上代码可以简写成： global x with mutex_lock: temp = x time.sleep(0.1) x = temp - 1 print(x) if __name__ == \u0026#39;__main__\u0026#39;: t_l = [] for i in range(100): t = Thread(target=task,) t_l.append(t) t.start() for t in t_l: t.join() print(\u0026#39;主线程\u0026#39;, x)  线程递归锁\r#\r\r 递归锁和互斥锁唯一的区别在于递归锁可以连续多次acquire()（用了几次acquire()就要有几次release()），但互斥锁不能连续多次使用acquire()，必须release()之后才可以再次使用acquire()，其他的使用方法一样。\n 互斥锁的效率高于递归锁。并且日常大部分使用的都是互斥锁。\n 递归锁用法示例：\nfrom threading import Thread from threading import RLock # 导入threading模块中的RLock类 import time def func(i,mutex_local): mutex_local.acquire() mutex_local.acquire() print(F\u0026#39;{i}is start!\u0026#39;) mutex_local.release() mutex_local.release() print(F\u0026#39;{i}is end!\u0026#39;) time.sleep(0.1) if __name__ == \u0026#39;__main__\u0026#39;: mutex_local = RLock() for i in range(10): t = Thread(target=func, args=(i, mutex_local)) t.start()  死锁现象\r#\r\r 在多线程中使用了多把锁，并且多把锁在多线程中交叉使用，这时候就有可能产生死锁现象。\n互斥锁和递归锁都会产生死锁现象，但如果是互斥锁出现了死锁现象，最快速的解决方法是把所有的互斥锁都改成一把递归锁，但这样做会降低程序的执行效率。\n 线程队列\r#\r\r 线程之间安全的容器称之为线程队列\n 队列（应用场景：购票）\nimport queue q = queue.Queue(4) # 队列：先进先出 q.put(1) q.put(2) q.put(3) q.put(4) print(q.get()) # 1 print(q.get()) # 2 print(q.get()) # 3 print(q.get()) # 4  堆栈（应用场景：三级菜单）\nimport queue q = queue.LifoQueue(4) # 堆栈：Last in first out 后进先出 q.put(1) q.put(2) q.put(3) q.put(4) print(q.get()) # 4 print(q.get()) # 3 print(q.get()) # 2 print(q.get()) # 1  优先级队列（应用场景：会员）\nimport queue q = queue.PriorityQueue() # 优先级队列：以元组的形式网队列里传值，第一个元素代表优先级，数字越小优先级越高；第二个元素是数据 q.put((0,\u0026#39;date1\u0026#39;)) q.put((10,\u0026#39;date2\u0026#39;)) q.put((-1,\u0026#39;date3\u0026#39;)) q.put((1,\u0026#39;date4\u0026#39;)) print(q.get()) # (-1, \u0026#39;date3\u0026#39;) print(q.get()) # (0, \u0026#39;date1\u0026#39;) print(q.get()) # (1, \u0026#39;date4\u0026#39;) print(q.get()) # (10, \u0026#39;date2\u0026#39;)  线程Event\r#\r\r 同进程的一样，线程的一个关键特性是每个线程都是独立运行且状态不可预测。如果程序中的其他线程需要通过判断某个线程的状态来确定自己下一步的操作，这时线程同步问题就会变得非常棘手。为了解决这些问题,我们需要使用threading库中的Event对象。Event对象包含一个可由线程设置的信号标志，它允许线程等待某些事件的发生。在初始情况下，Event对象中的信号标志被设置为假。如果有线程等待一个Event对象，而这个Event对象的标志为假，那么这个线程将会被一直阻塞直至该标志为真。一个线程如果将一个Event对象的信号标志设置为真，它将唤醒所有等待这个Event对象的线程。如果一个线程等待一个已经被设置为真的Event对象，那么它将忽略这个事件，继续执行：\nevent.isSet() # 返回event的状态值； event.wait() # 如果 event.isSet()==False将阻塞线程；  event.set() # 设置event的状态值为True，所有阻塞池的线程激活进入就绪状态， 等待操作系统调度； event.clear() # 恢复event的状态值为False。 例如，有多个工作线程尝试链接MySQL，我们想要在链接前确保MySQL服务正常才让那些工作线程去连接MySQL服务器，如果连接不成功，都会去尝试重新连接。那么我们就可以采用threading.Event机制来协调各个工作线程的连接操作：\nfrom threading import Thread,Event import threading import time,random def conn_mysql(): count = 1 while not event.is_set(): if count \u0026gt; 3: raise TimeoutError(\u0026#39;链接超时\u0026#39;) print(\u0026#39;\u0026lt;%s\u0026gt;第%s次尝试链接\u0026#39; % (threading.current_thread().getName(), count)) event.wait(0.5) count += 1 print(\u0026#39;\u0026lt;%s\u0026gt;链接成功\u0026#39; %threading.current_thread().getName()) def check_mysql(): print(\u0026#39;\\033[45m[%s]正在检查mysql\\033[0m\u0026#39; % threading.current_thread().getName()) time.sleep(random.randint(2,4)) event.set() if __name__ == \u0026#39;__main__\u0026#39;: event = Event() conn1 = Thread(target=conn_mysql) conn2 = Thread(target=conn_mysql) check = Thread(target=check_mysql) conn1.start() conn2.start() check.start()  进程池和线程池\r#\r\r 进程池和线程池是在计算机可承受范围内，用来限制并发的任务数目的。同时，使用进程池或线程池提前开好进程或线程，可以节省使用进程或线程时开启的时间，并且可以提高进程或线程的复用率。\nconcurrent.futures模块：提供了高度封装的异步调用接口。\nThreadPoolExecutor模块：提供了线程池，提供异步调用。\nProcessPoolExecutor模块：提供了进程池，提供异步调用。\n 进程池的使用方法：\nimport time import os import random from concurrent.futures import ProcessPoolExecutor # 导入进程池（类） def task(name): print(F\u0026#39;({name}){os.getpid()}is running...\u0026#39;) time.sleep(random.randint(1, 3)) if __name__ == \u0026#34;__main__\u0026#34;: p = ProcessPoolExecutor() # 实例化创建进程池，不写参数，默认开启的进程数是CPU的核数，一般开启进程的数量不超过CPU核数x2 for i in range(20): p.submit(task, i) # 异步提交任务到池，可以传参数到任务中 p.shutdown(wait=True) # \u0026#39;shutdown\u0026#39;指的是不能再往进程池内提交任务，\u0026#39;wait=True\u0026#39;指的是等待进程池或者线程池内的所有任务都运行完毕  线程池的使用方法\nimport time import random from threading import current_thread from concurrent.futures import ThreadPoolExecutor # 导入线程池（类） def task(name): print(F\u0026#39;({name}){current_thread().ident}is run...\u0026#39;) time.sleep(random.randint(1, 3)) if __name__ == \u0026#34;__main__\u0026#34;: p = ThreadPoolExecutor() # 实例化创建线程池，不写参数，默认开启的线程数是CPU的核数*5 for i in range(20): p.submit(task, i) # 异步提交任务到池，可以传参数到任务中 p.shutdown(wait=True) # \u0026#39;shutdown\u0026#39;指的是不能再往进程池内提交任务，\u0026#39;wait=True\u0026#39;指的是等待进程池或者线程池内的所有任务都运行完毕  小知识：\nPython中先有的threading模块，但threading模块中并没有提供池，而后，有人仿照threading模块写了multiprocessing模块，并加入了池，但只有进程池，从Python 3.4开始引入concurrent.futures模块，提供进程池和线程池，目前开始进程池和线程池都使用concurrent.futures模块。\n  回调函数\r#\r\r 池中任何一个任务一旦处理完了，就立即告知主进程或主线程：我好了，你可以处理我的结果了。主进程或主线程则调用一个函数去处理该结果，该函数即回调函数。我们可以把耗时（阻塞）的任务放到进程池或线程池中，然后指定回调函数（主进程或主线程负责执行），这样主进程或主线程在执行回调函数时就省去了I/O的过程，直接拿到的是任务的结果。只要是利用多进程或多线程获取返回值后去做某件事，回调函数的效率是最高的。\nimport time import random from threading import current_thread from concurrent.futures import ThreadPoolExecutor def func(a, b): print(F\u0026#39;线程名称：{current_thread().getName()},线程ID：{current_thread().ident}，传入的参数a：{a}，传入的参数b：{b}\u0026#39;) time.sleep(random.randint(1,3)) return a * b def print_func(ret): # 异步阻塞 print(F\u0026#39;线程{current_thread().getName()}中a*b的返回值为：{ret.result()}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: thread_pool = ThreadPoolExecutor() for i in range(20): # 异步非阻塞 ret = thread_pool.submit(func, i, b=i+1) ret.add_done_callback(print_func) # 给ret对象绑定一个回调函数，等ret对应的任务有了结果之后立即调用函数print_func，并将ret的结果作为参数传入print_func，而不用按照顺序接收和处理结果。  线程对象的其他方法\r#\r\r Thread实例化对象的方法\nisAlive() # 返回线程是否活动的。 getName() # 返回线程名。 setName() # 设置线程名。  threading模块提供的一些方法\nthreading.currentThread() # 返回当前的线程变量。 threading.enumerate() # 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount() # 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。  "},{"id":29,"href":"/docs/Python/Python%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8B%E5%8D%8F%E7%A8%8B/","title":"Python并发编程之协程","section":"Python","content":"协程\r#\r\r 协程是程序级别的概念，操作系统根本就没有协程的概念\n协程的本质就是一条线程，可以实现多个任务在一条线程上来回切换。协程可以规避I/O操作对程序执行效率的影响，也就是说当CPU调用线程执行任务，遇到I/O或阻塞时，保存这个任务的执行状态，然后让这条线程切换到其他任务上执行，使线程的利用率最大化。\n协程对任务的切换是基于用户级的，因此能够感知到的I/O操作（例如socket、网页请求等）是用户级别的，而线程的任务是系统级的，因此线程能够感知的I/O操作（例如文件操作等）更为细腻。\n使用协程可以减轻操作系统的负担。\n使用协程可以为程序多争取一些CPU的时间片进行任务处理，提高程序执行效率。\n 单线程下实现并发\r#\r\r 并发指的是多个任务看起来是同时运行的。\n并发实现的本质是：切换 + 保存状态\n协程遇到I/O效率才高，纯计算时因为有任务的切换，所以效率反而相比串行效率低。\n协程主要用来提升单线程下的线程效率。\n 能够让线程在任务间切换并规避I/O的两个模块\r#\r\r gevent模块：利用C语言写的greenlet底层模块完成的切换，并实现了自动规避I/O的功能。\nasyncio模块：利用Python中yield底层语法完成的切换，并实现了自动规避I/O的功能，asyncio模块是基于python原生的协程概念，asyncio模块出现在Python 3.4中，在Python 3.5中，专门为协程提供了两个内置关键字：aysnc和await。yield from和send的出现，其实就是为了更好的实现协程。\n 协程的gevent模块用法示例\r#\r\r gevent模块是第三方模块，需要单独安装才可使用，可以写协程版的并发Socket Server端\nimport gevent from gevent import monkey # 需要在导入time之前导入，并执行monkey.patch_all() monkey.patch_all() # 通过monkey.patch_all()，让gevent识别支持的阻塞 import time def func(): # 带有I/O操作的任务写在函数中 print(\u0026#39;Start func!\u0026#39;) time.sleep(1) # 又遇到阻塞，会切换任务，阻塞完毕，继续执行 print(\u0026#39;Stop func!\u0026#39;) g_1 = gevent.spawn(func) # 提交func给gevent g_2 = gevent.spawn(func) # 提交func给gevent g_3 = gevent.spawn(func) # 提交func给gevent gevent.joinall([g_1, g_2, g_3]) # 主线程阻塞，会切换到协程任务，执行func，直到所有协程任务都完成后才取消阻塞 # 检测gevent对指定模块是否生效的方法： # 在monkey.patch_all()之前和之后分别打印一下模块，看结果是否一致，如果结果不一致，说明gevent生效，如果不一致，说明不生效。  协程的asyncio模块用法示例\r#\r\r asyncio模块是Python原生的协程模块，不需要单独安装即可使用。\nimport asyncio async def func(name): # 随便定义一个函数，前面加上async关键字，这个函数就会变成async函数 print(F\u0026#39;{name}is Start!\u0026#39;) # await 后面总是跟着会阻塞或有可能阻塞的方法,且await必须写在async函数中 await asyncio.sleep(1) print(F\u0026#39;{name}is Stop!\u0026#39;) loop = asyncio.get_event_loop() # loop.run_until_complete(func(\u0026#39;asyncio\u0026#39;)) # 开启一个任务 loop.run_until_complete(asyncio.wait([func(\u0026#39;asyncio_1\u0026#39;), func(\u0026#39;asyncio_2\u0026#39;)])) # 开启多个任务（异步）  "},{"id":30,"href":"/docs/Python/%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%AF%B9%E6%AF%94/","title":"进程、线程和协程的对比","section":"Python","content":"Python之进程、线程和协程的对比\r#\r\r     数据共享性 数据安全性 级别 开销 能否利用多核     进程 数据隔离 数据不安全 系统级 开销大（1） 能   线程 数据共享 数据不安全 系统级 开销小（1/100） 不能   协程 数据共享 数据安全 用户级 开销非常小（与调用函数一样快） 不能     "},{"id":31,"href":"/docs/Python/%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%9E%8B%E8%BF%9B%E7%A8%8B/","title":"生产者消费者模型（进程）","section":"Python","content":"生产者消费者模型（非常重要）\r#\r\r 模型指的是一种解决问题的套路，目的是为了使生产数据与处理数据达到平衡，使得效率最大化。\n生产者消费者模型中包含两类重要角色一类叫生产者，另一类叫消费者：\n 生产者：将负责制造数据的称为生产者（生产数据）。通常在生产数据之前需要通过一些代码濑获取数据。 消费者：接收生产者制造出的数据，来做进一步处理，该类任务被比喻成消费者（处理数据）。通常在获取代码之后需要通过一些代码进行数据处理。   实现生产者消费者模型的三要素\r#\r\r  生产者 消费者 队列（队列中存放的是一些消息）   生产者消费者模型的运作方式\r#\r\r 生产者生产数据，放到一个共享的空间，然后消费者取走进行处理。\n 生产者消费者模型的实现方式\r#\r\r 由于生产者消费者模型并不局限于某一类技术，因此，有多种实现方式，包括但不限于以下方式：\n生产者进程 + 队列 + 消费者进程\n 该模型的应用场景\r#\r\r程序中出现明显的两类任务，一类任务负责生产数据，另一类任务是负责处理生产数据的，此时就应该考虑生产者消费者模型。（例如：爬虫）\n 使用生产者消费者模型的优势：\r#\r\r 实现了生产者与消费者解耦合 平衡了生产力和消费力，彼此不影响，生产者可以一致不停的生产，消费者可以一致不停的消费，因为二者不再是直接沟通了，而是跟队列沟通  import time import random from multiprocessing import Process,Queue def consumer(name, q): while True: res = q.get() if res == None:break time.sleep(random.randint(1,3)) print(F\u0026#39;[{name}]获取到{res}\u0026#39;) def producer(name,q,tools): for i in range(3): time.sleep(random.randint(1,2)) res = F\u0026#39;{tools}:{i}\u0026#39; q.put(res) print(F\u0026#39;[{name}]制造了{res}\u0026#39;) q.put(None) if __name__ == \u0026#39;__main__\u0026#39;: # 队列 q = Queue() # 生产者 p1 = Process(target=producer, args=((\u0026#39;生产者-1\u0026#39;, q, \u0026#39;食物\u0026#39;))) p2 = Process(target=producer, args=((\u0026#39;生产者-2\u0026#39;, q, \u0026#39;武器\u0026#39;))) # 消费者 c1 = Process(target=consumer, args=((\u0026#39;消费者-1\u0026#39;,q))) c2 = Process(target=consumer, args=((\u0026#39;消费者-2\u0026#39;,q))) c3 = Process(target=consumer, args=((\u0026#39;消费者-3\u0026#39;,q))) p1.start() p2.start() c1.start() c2.start() c3.start() # 在生产者生产完毕之后，往队列的末尾添加一个结束信号None p1.join() p2.join() # 有几个消费者就应该放几个结束信号 q.put(None) q.put(None) q.put(None)  改进：（加入守护进程）\nimport time import random from multiprocessing import Process,JoinableQueue def consumer(name, q): while True: res = q.get() if res == None:break time.sleep(random.randint(1,3)) print(F\u0026#39;[{name}]获取到{res}\u0026#39;) q.task_done() def producer(name, q, tools): for i in range(3): time.sleep(random.randint(1,2)) res = F\u0026#39;{tools}:{i}\u0026#39; q.put(res) print(F\u0026#39;[{name}]制造了{res}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: # 队列 q = JoinableQueue() # 生产者 p1 = Process(target=producer, args=((\u0026#39;生产者-1\u0026#39;, q, \u0026#39;食物\u0026#39;))) p2 = Process(target=producer, args=((\u0026#39;生产者-2\u0026#39;, q, \u0026#39;武器\u0026#39;))) # 消费者 c1 = Process(target=consumer, args=((\u0026#39;消费者-1\u0026#39;, q))) c2 = Process(target=consumer, args=((\u0026#39;消费者-2\u0026#39;, q))) c3 = Process(target=consumer, args=((\u0026#39;消费者-3\u0026#39;, q))) c1.daemon = True c2.daemon = True c3.daemon = True p1.start() p2.start() c1.start() c2.start() c3.start() # 确定生产者生产完毕 p1.join() p2.join() # 在生产者生产完毕后，拿到队列中元素的总个数，然后知道元素总数变为0，q.join()这一行代码才算运行完毕 q.join() print(\u0026#39;父进程结束\u0026#39;)  "},{"id":32,"href":"/docs/Python/Python%E4%B9%8B%E6%93%8D%E4%BD%9CMySQL%E6%95%B0%E6%8D%AE%E5%BA%93/","title":"Python之操作MySQL数据库","section":"Python","content":"安装PyMySQL模块\r#\r\r pip install pymysql  PyMySQL查询数据\r#\r\r import pymysql # 连接数据库 connection = pymysql.connect(host=\u0026#39;127.0.0.1\u0026#39;, user=\u0026#39;root\u0026#39;, password=\u0026#39;123456\u0026#39;, database=\u0026#39;DB\u0026#39;) # 获取游标对象，cursor=pymysql.cursors.DictCursor 表示返回字典类型的数据 cursor = connection.cursor(cursor=pymysql.cursors.DictCursor) # 需要执行的sql语句，一般情况下Python只操作数据表中的数据，查询用户信息表中的user和password sql = \u0026#39;select * from user_info where user=%sand password=%s;\u0026#39; # 执行MySQL命令，sql后面传入user和password参数，可以防止sql注入 cursor.execute(sql,(user,password)) # 获取执行MySQL命令的一个值 result = cursor.fetchone() # 获取执行MySQL命令的多个值 result = cursor.fetchmany(10) # 获取执行MySQL命令的所有值 result = cursor.fetchall() # 关闭游标对象 cursor.close() # 断开数据库连接 connection.close()  PyMySQL增、删、改数据\r#\r\r import pymysql # 连接数据库 connection = pymysql.connect(host=\u0026#39;127.0.0.1\u0026#39;, user=\u0026#39;root\u0026#39;, password=\u0026#39;123456\u0026#39;, database=\u0026#39;DB\u0026#39;) # 获取游标对象 cursor = connection.cursor(cursor=pymysql.cursors.DictCursor) # 需要执行的sql语句 sql = \u0026#39;insert into tb(username,password) values (\u0026#34;python\u0026#34;,\u0026#34;123456\u0026#34;);\u0026#39; try: # 执行MySQL命令 cursor.execute(sql) # 提交到数据库执行，查询不用写这句，但增、删、改需要 connection.commit() except Exception as e: # 如果出现异常，打印异常 print(e) # 如果出现异常则回滚try中的语句 connection.rollback() # 关闭游标对象 cursor.close() # 断开数据库连接 connection.close()  "},{"id":33,"href":"/docs/Linux/Basic-Operation/Firewalld%E9%98%B2%E7%81%AB%E5%A2%99%E5%9F%BA%E7%A1%80/","title":"Firewalld防火墙基础","section":"Linux运维基础","content":"启动：systemctl start firewalld.service\n 关闭：systemctl stop firewalld.service\n 开机启用：systemctl enable firewalld.service\n 开启禁用：systemctl disable firewalld.service\n 查询状态：systemctl status firewalld.service\n 查看版本：firewall-cmd --version\n 查看所有打开的端口：firewall-cmd --zone=public --list-ports\n 添加指定的端口（80端口）：firewall-cmd --zone=public --add-port=80/tcp --permanent\n --permanent 表示永久生效，没有此参数重启后失效\n  删除指定的端口（80端口）：firewall-cmd --zone= public --remove-port=80/tcp --permanent\n 重新加载：firewall-cmd --reload\n "},{"id":34,"href":"/docs/Linux/Basic-Operation/Linux%E7%A3%81%E7%9B%98%E7%9A%84%E6%93%8D%E4%BD%9C/","title":"Linux磁盘的操作","section":"Linux运维基础","content":"文件系统\r#\r\r Windwos平台\r#\r\r FAT FAT16 FAT32 NTFS   Linux平台\r#\r\r EXT2 EXT3 EXT4 XFS   网络共享文件系统\r#\r\r NFS：Network File System SMB：Server Message Block   集群文件系统\r#\r\r GFS：Google File System（谷歌公司为了存储海量数据而开发的文件系统） OCFS：Oracle Cluster File System（甲骨文公司为了数据库研发平台而定制的文件系统）   分布式文件系统\r#\r\r ceph：为了存储的可靠性和扩展性而研发的分布式文件系统   交换文件系统\r#\r\r swap   Linux磁盘分区\r#\r\r 查看识别的所有硬盘\r#\r\rfdisk -l  新建分区\r#\r\r硬盘小于2T时，可以使用fidsk命令\nfdisk /dev/sdb # 按 m 获取帮助 # 按 n 新建分区 # 按 p 创建主分区 # 一路回车 # 按 w 保存并写入分区表 硬盘大于2T时，需要使用parted命令\nparted /dev/sdb # 对sdb硬盘进行分区 # 输入 help 获取帮助 mklabel gpt # 设置分区表类型为GPT print # 检查分区表类型设置情况 mkpart primary 0 100% # 将整个硬盘划分成一个主分区 quit # 退出  Linux格式化分区\r#\r\r 查看分区上的文件系统\r#\r\rparted -l  格式化分区\r#\r\r Debian需要安装xfs格式化工具：\napt install -y xfsprogs  将sdb1分区格式化为xfs的文件系统\nmkfs.xfs /dev/sdb1  对格式化的结果进行检查\r#\r\rblkid lsblk -f\r Linux挂载分区\r#\r\r 挂载分区\r#\r\r 使用 blkid 来查看一个特定块设备的 UUID\n mkdir /mnt/sdb1 mount -t xfs /dev/sdb1 /mnt/sdb1  将挂载硬盘写入配置文件\r#\r\rvim /etc/fstab # 添加如下内容 UUID=[分区的UUID值] /mnt/sdb1 xfs defaults 0 0  Linux文件系统检测修复\r#\r\r 对Linux文件系统进行检测和修复时，经常会用到fsck命令\n语法格式：\nfsck [参数] [磁盘分区/目录信息] 示例：\nfsck -t xfs -r /dev/sdb1 "},{"id":35,"href":"/docs/Linux/Basic-Operation/NetworkManager/","title":"NetworkManager","section":"Linux运维基础","content":"RHEL 8与RHEL 7的区别\r#\r\r  在RHEL 7上，同时支持Network.service和NetworkManager.service（简称NM），默认情况下，这两个服务都开启。 在RHEL 8上，已经弃用Network.service，因此只能通过NetworkManager.service进行网络配置，包括动态IP和静态IP。   NetworkManager介绍\r#\r\r NetworkManager是2004年Red Hat启动的项目，旨在能够让Linux用户更轻松地处理现代网络需求，尤其是无线网络，能自动发现网卡并配置ip地址。\n 为什么要用NetworkManager？\r#\r\r  工具齐全：命令行、文本界面、图形界面、web 广泛管理：管理各种网络，有线、无线、物理、虚拟 参数丰富：多达200多项配置参数（包括ethtool参数） 通用性强：RedHat系、Suse系、Debian/Ubuntu系等，均支持 大势所趋：下一个大版本的RHEL只能通过NM管理网络   NetworkManager能管理什么？\r#\r\r 有线网卡、无线网卡 动态ip、静态ip 以太网、非以太网 物理网卡、虚拟网卡   NetworkManager的命令介绍\r#\r\r nmcli：命令行。这是最常用的工具，本文将详细讲解该工具使用。 nmtui：在shell终端开启文本图形界面。示意图见本文最后的Tips Freedesktop applet：如GNOME上自带的网络管理工具 cockpit：redhat自带的基于web图形界面的\u0026quot;驾驶舱\u0026quot;工具，具有dashborad和基础管理功能。示意图见本文   nmcli使用方法\r#\r\r nmcli使用方法非常类似linux ip命令、cisco交换机命令，并且支持tab补全，通过-h、–help、help查看帮助。在nmcli中有两个命令最为常用：\nnmcli connection：译作连接，可理解为配置文件，可以简写为nmcli c 。\nnmcli device：译作设备，可理解为实际存在的网卡（包括物理网卡和虚拟网卡），可以简写为nmcli d 。\n 在NM里，有两个维度：连接（connection）和设备（device），这是多对一的关系。想给某个网卡配ip，首先NM要能纳管这个网卡。设备里存在的网卡（即nmcli d可以看到的），就是NM纳管的。接着，可以为一个设备配置多个连接（即nmcli c可以看到的），每个连接可以理解为一个ifcfg配置文件。同一时刻，一个设备只能有一个连接活跃。可以通过nmcli c up切换连接。\n connection有2种状态：  **活跃（带颜色字体）：**表示当前该connection生效 **非活跃（正常字体）：**表示当前该connection不生效   device有4种常见状态：  **connected：**已被NM纳管，并且当前有活跃的connection **disconnected：**已被NM纳管，但是当前没有活跃的connection **unmanaged：**未被NM纳管 **unavailable：**不可用，NM无法纳管，通常出现于网卡link为down的时候（比如：ip link set ethX down）     nmcli的常用命令示例\r#\r\r 查看IP\nnmcli  创建connection，配置静态IP（等同于配置ifcfg，其中BOOTPROTO=none，并ifup启动）\nnmcli c add type ethernet con-name ethX ifname ethX ipv4.addr 192.168.1.100/24 ipv4.gateway 192.168.1.1 ipv4.method manual  创建connection，配置动态IP（等同于配置ifcfg，其中BOOTPROTO=dhcp，并ifup启动）\nnmcli c add type ethernet con-name ethX ifname ethX ipv4.method auto  修改ip（非交互式）\nnmcli c modify ethX ipv4.addr \u0026#39;192.168.1.100/24\u0026#39; nmcli c up ethX  修改ip（交互式）\nnmcli c edit ethX nmcli\u0026gt; goto ipv4.addresses nmcli ipv4.addresses\u0026gt; change Edit \u0026#39;addresses\u0026#39; value: 192.168.1.100/24 Do you also want to set \u0026#39;ipv4.method\u0026#39; to \u0026#39;manual\u0026#39;? [yes]: yes nmcli ipv4.addresses\u0026gt; back nmcli ipv4\u0026gt; save nmcli ipv4\u0026gt; quit  启用connection（相当于ifup）\nnmcli c up ethX  停止connection（相当于ifdown）\nnmcli c down  删除connection（类似于ifdown并删除ifcfg）\nnmcli c delete ethX  查看connection列表\nnmcli c show  查看connection详细信息\nnmcli c show ethX  重载所有ifcfg或route到connection（不会立即生效）\nnmcli c reload  重载指定ifcfg或route到connection（不会立即生效）\nnmcli c load /etc/sysconfig/network-scripts/ifcfg-ethX nmcli c load /etc/sysconfig/network-scripts/route-ethX  立即生效connection，有3种方法\nnmcli c up ethX nmcli d reapply ethX nmcli d connect ethX  查看device列表\nnmcli d  查看所有device详细信息\nnmcli d show  查看指定device的详细信息\nnmcli d show ethX  激活网卡\nnmcli d connect ethX  关闭无线网络（NM默认启用无线网络）\nnmcli r all off  查看NM纳管状态\nnmcli n  开启NM纳管\nnmcli n on  关闭NM纳管（谨慎执行）\nnmcli n off  监听事件\nnmcli m  查看NM本身状态\nnmcli  检测NM是否在线可用\nnm-online   参考链接：https://blog.csdn.net/Loveychent/article/details/89811722\n "},{"id":36,"href":"/docs/Linux/Basic-Operation/%E5%80%9F%E5%8A%A9%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E5%99%A8%E7%AE%A1%E7%90%86LVM/","title":"借助系统存储管理器管理LVM","section":"Linux运维基础","content":"安装系统存储管理器\nsudo yum install system-storage-manager  查看关于现有磁盘存储设备、存储池、LVM卷和存储快照的信息\nsudo ssm list  将一个新的物理磁盘（比如 /dev/sdb）添加到现有的存储池（比如 centos）中\nsudo ssm add -p \u0026lt;pool-name\u0026gt; \u0026lt;device\u0026gt;  如果你在存储池中有额外空间，可以扩大存储池中现有的磁盘卷\nsudo ssm resize -s [size] [volume] 例如：需要给home挂载点增加 100G 的空间\nsudo ssm resize -s +100G /dev/centos_centos7/home  使用 xfs_growfs 来扩展现有的 XFS 文件系统\nsudo xfs_growfs /dev/centos_centos7/home  "},{"id":37,"href":"/docs/Linux/Basic-Operation/Linux%E5%AE%9E%E7%8E%B0SSH%E5%85%8D%E5%AF%86%E7%99%BB%E9%99%86/","title":"Linux实现SSH免密登录","section":"Linux运维基础","content":"生成密钥\nssh-keygen -t rsa  查看生成的密钥\nls -lh /root/.ssh/  id_rsa：私钥\nid_rsa.pub：公钥\n  将公钥发送到需要免密登陆的服务器（192.168.1.100）\nssh-copy-id -i /root/.ssh/id_rsa.pub root@10.124.84.20  在此过程中需要输入192.168.1.100的密码\nssh-copy-id命令会将公钥内容写入到192.168.1.100服务器中的～/.ssh/authorized_keys文件中\n  "},{"id":38,"href":"/docs/Linux/Basic-Operation/%E8%A7%A3%E5%86%B3OpenMediaVault%E4%B8%ADFTP%E4%B9%B1%E7%A0%81%E9%97%AE%E9%A2%98/","title":"解决OpenMediaVault中FTP乱码问题","section":"Linux运维基础","content":"问题分析\r#\r\r OpenMediaVault使用的FTP为proftpd，由于Linux中的默认字符编码为UTF-8，而Windows中的默认字符编码为GBK，因此使用Windows系统上传至FTP服务器后，文件会有乱码问题，为解决此问题，需要修改proftpd的配置文件。\n 解决方法\r#\r\r 在/etc/proftpd路径下，创建lang.conf文件，加入以下内容：\n\u0026lt;IfModule mod_lang.c\u0026gt; LangEngine on LangDefault en_US LangOptions PreferServerEncoding UseEncoding utf-8 GBK \u0026lt;/IfModule\u0026gt; 在/etc/proftpd/proftpd.conf文件的最后一行添加以下内容：\nInclude /etc/proftpd/lang.conf 重启proftpd\nsystemctl restart proftpd.service  "},{"id":39,"href":"/docs/Git/git%E5%9F%BA%E7%A1%80/","title":"Git基础","section":"Git","content":"Git的安装\r#\r\r  官方网站：\rGit (git-scm.com)\n  Fedora\ndnf install git  Debian/Ubuntu\nadd-apt-repository ppa:git-core/ppa apt update -y apt install -y git  Windows\n 下载地址：\rGit - Downloading Package (git-scm.com)\n  Git的配置文件\r#\r\r  当前项目配置文件路径：/.git/config，使用git config --local命令进行配置，配置文件仅对当前项目（目录生效） 全局配置文件路径：~/.gitconfig，使用git config --global命令进行配置，配置文件对当前用户生效 系统配置文件路径：/etc/.gitconfig，使用git config --system命令进行配置，配置文件对系统下的所有用户生效   配置文件的优先级：当前项目配置文件-\u0026gt;全局配置文件-\u0026gt;系统配置文件\n应用场景：\n 配置用户信息     Git的基本操作\r#\r\r 要让Git对一个目录进行版本控制，首先需要在Git Bash（或其他命令行工具）中进入目录\n执行初始化命令\ngit init  查看工作区中文件的管理状态\ngit status  在工作区（目录或文件夹）中，新增或修改过的文件都会是红色\n  让Git忽略项目中的一些文件\n在项目中新建文件.gitigonre，在.gitigonre文件中添加想要被Git忽略的文件名称或文件夹名称（文件名支持通配符）\nvim .gitigonre # 添加想要被Git忽略的文件名称或文件夹名称 .gitigonre files/ *.sql !a.sh  将文件提交到暂存区\n# 管理指定文件 git add \u0026lt;文件名称\u0026gt; # 管理全部文件 git add .  提交到暂存区文件会由红色变成绿色\n  配置个人信息\n 在首次提交版本前，需要配置用户名称和电子邮箱，首次配置完成后，再次提交就无需再次配置了\n git config --global user.email \u0026#34;you@examole.com\u0026#34; git config --global user.name \u0026#34;Your Name\u0026#34;  提交到版本库\ngit commit -m \u0026#39;描述信息\u0026#39;  给版本打标签\ngit tag -a 标签名称 -m \u0026#39;描述信息\u0026#39;  查看版本记录\ngit log  以图形化的方式显示版本记录\ngit log --graph   查看引用日志\n 查看所有分支的所有操作记录，包括已经被删除的 commit 记录和 reset 的操作，配合回滚版本命令，相当于有了“后悔药”\n git relog  回滚版本\n# 从版本库回滚到暂存区（绿色） git reset --soft \u0026lt;版本号\u0026gt; # 将文件从暂存区（绿色）回滚到工作区（红色） git reset HEAD \u0026lt;文件名称\u0026gt; # 将工作区中已修改的文件（红色）回滚到未修改的状态（白色） git checkout \u0026lt;文件名称\u0026gt; # 从版本库直接回滚到工作区（红色） git reset --mix \u0026lt;版本号\u0026gt; # 从版本库直接回滚到工作区（白色） git reset --hard \u0026lt;版本号\u0026gt;  Git的分支\r#\r\r 分支可以给开发者提供多个开发环境，这样就可以将开发工作从主线分离出来，以避免影响主线的功能。\n查看目前所处的分支\ngit branch  创建分支\ngit branch \u0026lt;分支名称\u0026gt;  切换分支\ngit checkout \u0026lt;分支名称\u0026gt;  通过如下命令可以创建并切换到dev分支：\ngit checkout -b dev   合并分支\n 要想将其他分支合并到master上，需要切换到master上进行操作\n git merge \u0026lt;分支名称\u0026gt; 将已经合并到master的分支删除\ngit branch -d \u0026lt;分支名称\u0026gt;  Git的工作流\r#\r\r 使用Git进行开发，应至少拥有2个分支，一个master分支，一个dev分支。master分支用于发布正式版本，其余的开发工作都应在dev分支进行。\n 将项目推送到Github\r#\r\r 添加远程仓库地址\ngit remote add origin https://github.com/xxx/xxx.git  origin为 https://github.com/xxx/xxx.git 地址的别名，将 用户名和密码拼接到连接\rhttps://用户名:密码@github.com/xxx/xxx.git中，可以实现免密码登录\n  将项目推送到Github\n# 将master分支推送到github git push -u origin master # 将dev分支推送到github git push -u origin dev  -u表示指定默认仓库地址，首次使用git push -u指定默认仓库地址后，下次推送可不加任何参数，而直接使用git push，就可以将项目推送到origin master或origin dev\n  将项目从Github中拉取到本地\r#\r\r 将Github中的项目克隆到本地\n 适用于首次获取项目\n git clone https://github.com/xxx/xxx.git  注意，本地开发时要使用dev分支，同时根据情况选择要不要将master分支合并到dev分支\n切换到dev分支\ngit checkout dev 将master分支合并到dev分支\ngit merge master   从Github仓库拉取代码\n 适用于本地已有项目，需要从Github获取dev分支更新的代码\n git pull origin dev  合并提交记录\r#\r\r 当提交记录过多或部分提交记录不被关心时，可以将这些提交记录进行合并，使提交记录变得更加简洁\n 注意：尽量不要合并已经提交到版本库的记录\n git rebase -i \u0026lt;commit hash值\u0026gt;  快速解决冲突\r#\r\r  安装Beyond Compare软件\n 在Git中进行如下配置\ngit config --local merge.tool BeyondCompare git config --local mergetool.path \u0026#39;BeyondCompare安装路径\u0026#39; git config --local mergetool.keepbackup false 在Git中使用Beyond Compare解决冲突\ngit mergetool  "},{"id":40,"href":"/docs/Kubernetes/Kubernetes/","title":"Kubernetes","section":"Kubernetes","content":"Kubernetes（K8S）\r#\r\r Kubernetes的基本概念\r#\r\r Pod\r#\r\r Pod是Kubernetes中能够被运行的最小逻辑单元（原子单元），一个Pod里面可以运行多个容器，他们共享UTS+NET+IPC名称空间，可以把Pod理解成豌豆荚，而同一个Pod中的每一个容器都是一颗颗的豌豆，一个Pod中运行多个容器，又叫边车（SideCar）模式。（边车就是侉子摩托）\n Pod控制器\r#\r\r Pod控制器是Pod启动的一种模式，用来保证在Kubernetes中启动的Pod应始终按照预期运行（副本数、生命周期和健康状态检查等）。\n虽然Pod可以不通过Pod控制器，单独启动并运行在Kubernetes中，但在生产环境中强烈建议使用Pod控制器控制Pod。\nKubernetes中提供了众多的Pod控制器，常用的有以下几种：\n Deployment DeamonSet ReplicaSet StatefulSet Job Cronjob   Name\r#\r\r 由于Kubernetes内部使用“资源”来定义每一种逻辑概念（功能），故每种“资源”都应该有自己的名称。\n“资源”有API版本（API Version）、类别（kind）、元数据（metadata）、定义清单（spec）、状态（status）等配置信息。\n“名称”通常定义在“资源”的“元数据（metadata）”信息里。\n Namespace\r#\r\r 随着项目的增多、人员的增加、集群规模的扩大，需要一种能够隔离Kubernetes内各种“资源”的方法，这就是Namcespace（名称空间）。\nNamespace可以理解为把Kubernetes的内部资源进行了分组，类似于一个公司的各个部门（行政、人力、财务、研发、销售等）。\n不同Namespace内的“资源”，名称可以相同，相同Namespace内的同种“资源”，“名称”不能相同（可以理解为A机房中的服务器不能有相同的编号，但是B机房中的服务器可以跟A机房中的服务器的编号相同）。\n合理的使用Kubernetes的Namespace，使得集群管理源能够更好的对交付到Kubernetes中的服务进行分类管理和浏览。\nKubernetes中默认存在的Namespace有：default、kube-system、kube-public。\n查询Kubernetes中特定的“资源”要带上相应的Namespace。\n Label\r#\r\r 标签是Kubernetes特色的管理方式，便于分类管理资源对象。\n一个标签可以对应多个资源，一个资源也可以有多个标签，他们是多对多的关心。\n一个资源拥有多个标签，可以实现不同维度的管理。\n标签的组成：key = value\n与标签类似的，还有一种“注解（annotaions）”\n Lable选择器\r#\r\r 给资源打上标签后，可以使用标签选择器过滤指定标签。\n标签选择器目前有两个：基于等值关系（等于、不等于）和基于合关系（属于、不属于、存在）。\n许多资源支持内嵌标签选择字段：\n matchLable matchExpressions   Service\r#\r\r 在Kubernetes的世界里，虽然每一个Pod都会被分配一个单独的IP地址，但这个IP地址会随着Pod的销毁而消失，Pod是有生命周期的，每一次Pod的变更，其IP地址都会随之而变，随之而来的问题就是其流量如何调度，而Service（服务）就是用来解决这个问题的。\n一个Service可以看作一组提供相同服务Pod的对外访问接口，而Service作用于哪些Pod是通过标签选择器来定义的。\nService工作在OSI网路参考模型的第四层，只能进行第四层的网络调度，表现形式是：IP+端口。\n Ingress\r#\r\r Ingress是Kubernetes集群里工作在OSI网路参考模型的第七层，对外暴露的接口是应用层接口，而Service只能进行第四层的网络调度，Ingress可以调度不同业务域、不同URL访问路径的业务流量。\nIngress是kubernetes的标准资源类型之一，也是一种核心资源，它其实就是一组基于域名和URL路径，把用户的请求转发至指定Service资源的一种规则。\nIngress可以将集群外部的请求流量转发至集群内部，从而实现服务暴露。\nIngress控制器能够监听Ingress资源，然后根据Ingress规则匹配路由、调度流量的一个组件。\n常用的Ingress控制器的实现软件：\n Ingress-nginx HAProxy Traefik ……   RBAC\r#\r\r Kubernetes自1.6版本起默认使用基于角色的访问控制（RBAC），相较于ABAC（基于属性的访问控制）和WebHook等鉴权机制。RBAC对集群中的资源权限实现了完整覆盖，同时支持权限的动态调整，无需重启apiserver\n 权限\n get：读 write：写 update：更新 list：列出 watch：监视 ……   账户\n 注意：账户不能直接被分配权限，需要先绑定一个角色，然后给角色分配权限\n  UserAccount：用户账户 ServiceAccount：服务账户。所有交付到Kubernetes中的pod，都必须有拥有一个服务账户。   角色\n Role：普通角色。只能应用于特定的名称空间下。 ClusterRole：集群角色。应用于整个集群。   绑定角色的操作\n RoleBinding ClusterRoleBinding   RBAC的YAML文件一般包含如下内容：\n 创建账户 定义角色并赋予角色相应的权限 将账户绑定到相应的角色上   Kubernetes的核心组件\r#\r\r 配置存储中心\r#\r\r Kubernetes的配置存储中心是etcd服务\n etcd服务也是一种数据库，拥有自己的高可用机制和通信方式，并且拥有自己组织数据的结构和方法（etcd使用键值对，MySQL使用二维表）。\netcd服务主要用于存储集群的元数据信息。\netcd服务应该有奇数个（3、5、7、9……），因为etcd的高可用是投票机制（选举机制），当leader死后，会留遗言，将leader给指定的etcd（平日里与leader通信延迟低、响应快的）。而参与投票etcd都会选择自己，因此只有基数个etcd才会选出新的leader。\n  主控节点（master）\r#\r\r kube-apiserver 服务\n apiserver是整个Kubernetes集群的大脑，主要提供了以下功能：\n  集群管理的REST API接口（包括鉴权、数据校验以及集群状态的变更）\n  负责其他模块之间的数据交互，承担通信枢纽的功能\n  是资源配额控制的入口\n  为集群提供完备的安全机制\n    kube-controller-manager 服务\n controller-manager被称为控制器管理器，用于管理一系列的控制器，通过apiserver监控整个集群的状态，并确保集群处于预期的工作状态。\ncontroller-manager所管理的控制器主要有：\n Node Controller（节点控制器） Deployment Controller（Pod控制器） Service Controller（服务控制器） Volume Controller（存储卷控制器） Endpoint Controller（接入点控制器） Garbage Controller（垃圾回收控制器） Namespace Controller（名称空间控制器） Job Controller（任务控制器） Resoure Quta Controller（资源配额控制器） \u0026hellip;\u0026hellip;    kube-scheduler 服务\n scheduler主要功能是接收并调度Pod到适合的运算节点上，scheduler在为Pod选择节点时主要有两种策略：\n  预算策略（predict）\n  优选策略（priorities）\n    运算节点（node）\r#\r\r kube-kubelet服务\n kublet（苦逼老父亲）是真正干活儿的服务，简单的说，kubelet的主要功能有：\n 定制从某个地方获取节点上Pod的期望状态（运行什么容器、运行的副本数量、网络或者存储如何配置等），并调用对应容器平台的接口（Docker接口）达到这个状态 定时汇报当前节点的状态给apiserver，由apiserver将状态写道etcd中，以供调度的时候使用 完成镜像和容器的清理工作，保证节点上镜像不会占满磁盘空间，推出的容器不会占用太多资源    kube-proxy服务\n kube-proxy是Kubernetes在每个节点上运行的网络代理，是service资源的载体，kube-proxy在集群网络和Pod网络间建立关系（clusterip -\u0026gt; podip），注意，是建立关系，并不是提供网络，网络是由netns提供。\n kube-proxy常用的三种流量调用模式：  Userspace（已经废弃） Iptables（目前在用，但濒临废弃） Ipvs（推荐使用的流量调用模式）   负责建立和删除更新调度规则、通知apiserver自己的更新，或者从apiserver那里获取其他kube-proxy的调度规则，同时更新自己现有的规则 Kubernetes中有三种网络：宿主机节点网路（10.0.0.0/24）、Service网络（172.16.0.0/16）和Pod网络（192.168.0.0/16）    CLI客户端\r#\r\r kubectl\nKubernetes管理核心资源依托于kubectl和dashboard，主要有以下三种方式：\n 陈述式管理：主要依赖命令行工具（CLI）进行管理 声明式管理：主要依赖统一资源配置清单（manifest）进行管理 GUI图形用户界面式管理：主要依赖图形化操作界面（WEB界面）进行管理   这三种对核心资源管理的方式各有特点，属于互相依托、协同工作的关系\n  Kubernetes的附加组件\r#\r\r  Kubernetes addons\n  CNI网络插件\r#\r\r Kubernetes设计了网络模型，但却将它的实现交给了网络插件，CNI网络插件最主要的功能就是实现pod资源能够跨宿主机进行通信。\n常见的CNI网络插件：\n Flannel Calico Cannal Contiv OpenContrail NSX-T Kube-router   Flannel/Calico\n flannel利用Kubernetes API或者etcd，用于存储整个集群的网络配置，其中最主要的功能是设置集群的网络地址空间。例如，设定整个集群内所有容器的IP都取自网段“10.1.0.0/16”。 flannel在每个主机中运行flanneld作为agent，它会为所在主机集群的网络地址空间中，获取一个小的网段subnet，本主机中所有容器的IP地址都将从subnet中分配。 flanneld将本主机获取的subnet以及用于主机间通信的Public IP，通过kubernetes API或者etcd存储起来。 flannel利用各种backend mechanism，例如udp，vxlan等等，跨主机转发容器间的网络流量，完成容器间的跨主机通信。   服务发现用插件\r#\r\r    服务发现就是服务（应用之间互相定位的过程）\n  服务发现并非云计算时代独有的，传统架构时代也会用到，一般来说，在服务（应用）的动态性强、更新发布频繁、需要支持自动伸缩的场景下需要服务发现\n  在Kubernetes集群里，pod的IP地址是在不断变化的，如何“以不变应万变”呢？\n 抽象出了Service资源，通过标签选择器，关联一组pod 抽象出了集群网络，通过相对固定的“集群IP”，使服务接入点固定    在Kuberntes v1.2至v1.10是使用Kube-dns进行自动关联Service资源的“名称”和“集群网络IP”，从而达到服务被集群自动发现的目的。在Kubernetes v1.11以后，就改用Coredns了。\n  注意：在Kubernetes中的DNS不是万能的，它只负责自动维护“服务名称”和“集群网络IP地址”的关系\n CoreDNS\n 集群网络：Cluster IP Service资源：Service Name Coredns：实现了Service Name和Cluster IP的自动关联   服务暴露用插件\r#\r\r Ingress资源：专用于暴露7层应用到K8S集群外的一种核心资源（http/https）\nIngress控制器：通过Traefik软件实现的Ingress控制器，简单来说，Ingress控制器就是一个简化版的Nginx（调度流量）+ Go语言脚本（动态识别YAML）\n Traefik\n GUI管理插件\r#\r\r Dashboard\n Kubernetes核心资源管理方法（CRUD）\r#\r\r   陈述式资源管理：基于kubectl命令 声明式资源管理：基于K8S资源配置清单 GUI式资源管理：基于K8S仪表盘（Dashboard）    陈述式资源管理\r#\r\r    Kubenetes集群管理其集群资源的唯一入口是通过相应的方法调用apiserver的接口\n  kubectl是官方的CLI命令行工具，用于与apiserver进行通信，将用户在命令行输入的命令组织并转化为apiserver可以识别的命令，是实现管理Kubenetes各种资源的一种有效的方式\n  kubectl的命令大全\n kubectl \u0026ndash;help \rhttp://docs.kubernetes.org.cn    陈述式资源管理方法可以满足90%以上的资源管理需求，但它的缺点也很明显\n 命令冗长、负载、难以记忆 特定场景下、无法实现管理需求 对资源的增、删、查操作比较容易，而对改操作比较麻烦      管理名称空间资源\r#\r\r 查看名称空间\nkubectl get namespaces  查看指定名称空间内的资源\nkubectl get all -n \u0026lt;名称空间的名称\u0026gt; kubectl get pods -n \u0026lt;名称空间的名称\u0026gt; kubectl get nodes -n \u0026lt;名称空间的名称\u0026gt;  查询命名空间中的资源，使用-n指定名称空间，如果不使用-n指定名称空间，则默认查询的是default的名称空间\n  创建名称空间\nkubectl create namespace \u0026lt;名称空间\u0026gt;  删除名称空间\nkubectl create namespace \u0026lt;名称空间\u0026gt;  管理Deployment资源\r#\r\r 创建deployment类型的pod控制器\nkubectl create deployment \u0026lt;pod控制器资源名称\u0026gt; --image=\u0026lt;镜像地址\u0026gt; -n \u0026lt;名称空间\u0026gt; 示例：\nkubectl create deployment nginx-dp --image=harbor.k8s.com/public/nginx:v1.7.0 -n kube-public  查看deployment类型的pod控制器或者pod概览信息\nkubectl get deploy -n kube-public # 加上 -o wide 可查看扩展信息 kubectl get deploy -o wide -n kube-public kubectl get pod -o wide -n kube-public  查看pod控制器、pod、service等资源的详细信息\nkubectl describe \u0026lt;资源类型\u0026gt; \u0026lt;pod控制器名称\u0026gt; -n \u0026lt;名称空间\u0026gt; 示例：\nkubectl describe deploy nginx-dp -n kube-public kubectl describe pod nginx-dp-5dfc689474-4bhfh -n kube-public kubectl describe svc nginx-dp -n kube-public　 进入pod容器（也可以使用docker exec命令进入容器）\nkubectl exec -ti \u0026lt;pod容器名称\u0026gt; /bin/bash -n \u0026lt;名称空间\u0026gt; 示例：\nkubectl exec -ti nginx-dp-7975769c4c-pz8bh /bin/bash -n kube-public  扩容pod容器\nkubectl scale deployment \u0026lt;pod容器名称\u0026gt; --replicas=\u0026lt;数量\u0026gt; -n 名称空间\u0026gt; 示例：\nkubectl scale deployment nginx-dp --replicas=2 -n kube-public  删除pod容器\nkubectl delete pods \u0026lt;pod容器名称\u0026gt; -n \u0026lt;名称空间\u0026gt; [--force --grace-period=0] # 示例 kubectl delete pods nginx-dp-5dfc689474-4bhfh -n kube-public  注意：此删除，只是删除了pod容器，并没有删除pod控制器，此操作删除pod后，pod控制器会再拉起一个新的pod，所以删除pod是重启pod的一个重要方法，想要完全删除pod，需要删除pod控制器。当无法删除pod的时候，还可以使用强制删除参数：--force --grace-period=0\n  删除deployment（pod控制器）\nkubectl delete deploy \u0026lt;pod控制器名称\u0026gt; -n \u0026lt;名称空间\u0026gt; 示例：\nkubectl delete deploy nginx-dp -n kube-public  当我们删除了pod控制器以后，pod容器也会被随之删除。\n  管理Service资源\r#\r\r  Service资源为Pod资源提供稳定的接入点\n资源包括(不区分大小写)：\nPod（po），Service（svc），Replication Controller（rc），Deployment（deploy），Replica Set（rs）\n  将资源暴露为新的Service\nkubectl expose \u0026lt;资源类型\u0026gt; \u0026lt;资源名称\u0026gt; --port=\u0026lt;Service端口号\u0026gt; --target-port=\u0026lt;容器的端口号\u0026gt; -n \u0026lt;名称空间\u0026gt; 示例：\nkubectl expose deploy nginx-dp --port=80 -n kube-public  查看Service\nkubectl discribe svc nginx-dp -n kube-public # 查看资源配置清单详细信息：-o yaml kubectl discribe svc nginx-dp -o yaml -n kube-public  声明式资源管理\r#\r\r   声明式资源管理方法依赖于资源配置清单（yaml/json） 更改配置清单使用声明式资源管理比较好    查看资源配置清单\nkubectl get \u0026lt;资源类型\u0026gt; \u0026lt;资源名称\u0026gt; -o yaml -n \u0026lt;名称空间\u0026gt;  解释资源配置清单或资源配置清单中关键字的作用\nkubectl explain \u0026lt;资源类型\u0026gt;.\u0026lt;关键字\u0026gt; 示例：\nkubectl explain service.metadata  创建资源配置清单\nvim /root/nginx-ds-svc.yaml apiVersion: v1 kind: Service metadata: labels: app: nginx-ds name: nginx-ds namespace: default spec: ports: - port: 80 protocol: TCP targetPort: 80 selector: app: nginx-ds sessionAffinity: None type: ClusterIP  应用资源配置清单\nkubectl apply -f nginx-ds-svc.yaml  修改资源配置清单并应用\n 修改资源配置清单分为在线修改和离线修改，推荐离线修改\n   在线修改\n直接使用kubectl edit service nginx-ds在线编辑资源配置清单并保存生效\n  离线修改\n修改nginx-ds-svc.yaml文件，并使用kubectl apply -f nginx-ds-svc.yaml命令使配置文件生效\n   删除资源配置清单\n  陈述式删除\nkubectl delete svc nginx-ds   声明式删除\nkubectl delete -f nginx-dp-svc.yaml    Kubernetes实验架构\r#\r\r 主机配置（基础优化）\r#\r\r  Linux系统内核3.8以上\n  更改主机名称\nhostnamectl set-hostname xxx.host.com  关闭selinux服务\nsetenforce 0  关闭firewalld服务\nsystemctl stop firewalld \u0026amp;\u0026amp; systemctl disable firewalld  调整Base源\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup wget http://mirrors.aliyun.com/repo/Centos-7.repo -O /etc/yum.repos.d/CentOS-Base.repo  安装epel源\nyum update -y \u0026amp;\u0026amp; yum install epel-release -y  安装常用工具\nyum install -y bash-completion vim wget net-tools telnet htop tree nmap sysstat lrzsz dos2unix bind-utils  时间同步\nyum install -y chronyd echo \u0026#39;server ntp1.aliyun.com iburst\u0026#39; \u0026gt;\u0026gt; /etc/chrony.conf systemctl start chronyd \u0026amp;\u0026amp; systemctl enable chronyd  搭建DNS服务\r#\r\r  在10.0.0.11上通过bind搭建DNS服务\n  安装bind软件\nyum install -y bind  配置bind\nvim /etc/named.conf options { listen-on port 53 { 10.0.0.11; }; directory \u0026#34;/var/named\u0026#34;; dump-file \u0026#34;/var/named/data/cache_dump.db\u0026#34;; statistics-file \u0026#34;/var/named/data/named_stats.txt\u0026#34;; memstatistics-file \u0026#34;/var/named/data/named_mem_stats.txt\u0026#34;; recursing-file \u0026#34;/var/named/data/named.recursing\u0026#34;; secroots-file \u0026#34;/var/named/data/named.secroots\u0026#34;; allow-query { any; }; forwarders { 10.0.0.254; }; recursion yes; dnssec-enable no; dnssec-validation no; include \u0026#34;/etc/named/named.rfc1912.zones\u0026#34;;  配置区域文件\nvim /etc/named/named.rfc1912.zones zone \u0026#34;host.com\u0026#34; IN { type master; file \u0026#34;host.com.zone\u0026#34;; allow-update { 10.0.0.11; }; }; zone \u0026#34;k8s.com\u0026#34; IN { type master; file \u0026#34;k8s.com.zone\u0026#34;; allow-update { 10.0.0.11; }; };  配置区域数据文件\nvim /var/named/host.com.zone $ORIGIN host.com. $TTL 60 ; 1 minutes @ IN SOA dns.host.com. dnsadmin.host.com. ( 2020010101 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.host.com. dns A 10.0.0.11 host-0-11 A 10.0.0.11 host-0-12 A 10.0.0.12 host-0-21 A 10.0.0.21 host-0-22 A 10.0.0.22 host-0-200 A 10.0.0.200  配置业务域数据文件\nvim /var/named/k8s.com.zone $ORIGIN k8s.com. $TTL 60 ; 1 minutes @ IN SOA dns.k8s.com. dnsadmin.k8s.com. ( 2020010101 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.k8s.com. dns A 10.0.0.11  检查配置文件\nnamed-checkconf  启动服务\nsystemctl start named  设置开机自动启动\nsystemctl enable named  验证DNS解析\ndig -t A host-0-12.host.com @10.0.0.11 +short  搭建证书签发环境\r#\r\r  cfssl：证书签发的主要工具\ncfssl-json：将cfssl生成的证书（json格式）变为文件承载式证书（只是转换了一下格式）\ncfssl-certinfo：验证证书的信息\ncfssl-certinfo -cert \u0026lt;证书名称\u0026gt; 在运维主机10.0.0.200上安装证书签发服务\n  安装CFSSL\nwget http://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -O /usr/bin/cfssl wget http://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -O /usr/bin/cfssl-json wget http://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -O /usr/bin/cfssl-certinfo chmod +x /usr/bin/cfssl*  创建生成CA证书签名请求（CSR）的JSON配置文件\nmkdir /opt/certs vim /opt/certs/ca-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;k8s\u0026#34;, \u0026#34;hosts\u0026#34;: [], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;k8s\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;ops\u0026#34; } ], \u0026#34;ca\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;175200h\u0026#34; } }  CN: Common Name , 浏览器使用该字段验证网站是否合法，一般写的是域名。非常重要。\nC： Country，国家\nST：State，州，省\nL：Locality，地区，城市\nO：Organization Name，组织名称，公司名称\nOU：Organization Unit Name，组织单位名称，公司部门\nexpiry：证书过期时间\n  生成CA证书和私钥\ncd /opt/certs \u0026amp;\u0026amp; cfssl gencert -initca ca-csr.json | cfssl-json -bare ca  注意：私钥ca-key.pem的权限是600\n  搭建Docker环境\r#\r\r  在10.0.0.200、10.0.0.21、10.0.0.22上搭建Docker环境\n  安装Docker\ncurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun  配置Docker\nmkdir -p /etc/docker /data/docker vi /etc/docker/daemon.json { \u0026#34;graph\u0026#34;: \u0026#34;/data/docker\u0026#34;, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;insecure-registries\u0026#34;: [\u0026#34;registry.access.redhat.com\u0026#34;,\u0026#34;quary.io\u0026#34;,\u0026#34;harbor.k8s.com\u0026#34;], \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://q2gr04ke.mirror.aliyuncs.com\u0026#34;], \u0026#34;bip\u0026#34;: \u0026#34;172.16.200.1/24\u0026#34;, # 根据主机IP进行配置21.1 22.1 200.1 \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;live-restore\u0026#34;: true }  启动Docker\nsystemctl start docker \u0026amp;\u0026amp; systemctl enable docker  安装Docker-Compose（harbor依赖Docker-Compose做单机编排）\nyum install -y docker-compose  验证Docker-Compose\nrpm -qa docker-compose  搭建私有镜像仓库Harbor\r#\r\r  harbor下载地址：https://github.com/goharbor/harbor/releases\n在10.0.0.200上搭建Docker私有仓库harbor\n  下载harbor\nmkdir /opt/installed \u0026amp;\u0026amp; cd /opt/installed wget https://github.com/goharbor/harbor/releases/download/v1.10.4/harbor-offline-installer-v1.10.4.tgz  解压harbor\ntar -xvf /opt/installed/harbor-offline-installer-v1.10.4.tgz -C /opt/ mv /opt/harbor/ /opt/harbor-v1.10.4 ln -s /opt/harbor-v1.10.4/ /opt/harbor  配置harbor\nvim /opt/harbor/harbor.yml # 修改以下内容 hostname: harbor.k8s.com http: port: 8000 # 注释掉https，不然会报错[ERROR:root:Error: The protocol is https but attribute ssl_cert is not set] # https: # port: 443 # certificate: /your/certificate/path # private_key: /your/private/key/path data_volume: /data/harbor log: level: info local: rotate_count: 50 rotate_size: 200M location: /data/harbor/logs mkdir -p /data/harbor/logs  安装harbor\n/opt/harbor/install.sh  验证harbor\ndocker-compose ps  安装Nginx（反向代理harbor）\nyum install -y nginx  验证Nginx\nrpm -qa nginx  配置Nginx\nvim /etc/nginx/conf.d/harbor.k8s.conf server { listen\t80; server_name\tharbor.k8s.com; client_max_body_size\t1000m; location / { proxy_pass http://127.0.0.1:8000; } } nginx -t  启动Nginx\nsystemctl start nginx systemctl enable nginx  在10.0.0.11中添加harbor的DNS解析\nvim /var/named/k8s.com.zone $ORIGIN k8s.com. $TTL 60 ; 1 minutes @ IN SOA dns.k8s.com. dnsadmin.k8s.com. ( 2020010102 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.k8s.com. dns A 10.0.0.11 harbor A 10.0.0.200 systemctl restart named dig -t A harbor.k8s.com +short # 返回：10.0.0.200  更改宿主机的本地网卡和VMnet8的网卡DNS为10.0.0.11\n 浏览器打开harbor.k8s.com，默认用户名：admin，默认密码：Harbor12345\n 在项目中，点击新建项目，项目名称设置为public，访问级别设置为：公开\n 在10.0.0.200上，下载镜像\ndocker pull nginx:1.7.9  在10.0.0.200上，给镜像打标签\ndocker tag 84581e99d807 harbor.k8s.com/public/nginx:v1.7.9  在10.0.0.200上，将Nginx镜像推送到harbor私有镜像仓库\ndocker login harbor.k8s.com # 输入harbor的用户名和密码 docker push harbor.k8s.com/public/nginx:v1.7.9  部署主控（Master）节点服务\r#\r\r 部署etcd集群\r#\r\r  在10.0.0.12、10.0.0.21和10.0.0.22上安装etcd服务\n   主机名 角色 IP地址     host-0-12.host.com etcd lead 10.0.0.12   host-0-21.host.com etcd follow 10.0.0.21   host-0-22.host.com etcd follow 10.0.0.22      由于etcd之间的通讯基于SSL，因此部署etcd之前，首先在10.0.0.200上创建基于根证书的配置文件\nvim /opt/certs/ca-config.json { \u0026#34;signing\u0026#34;: { \u0026#34;default\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;175200h\u0026#34; }, \u0026#34;profiles\u0026#34;: { \u0026#34;server\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;175200h\u0026#34;, \u0026#34;usages\u0026#34;: [ \u0026#34;signing\u0026#34;, \u0026#34;key encipherment\u0026#34;, \u0026#34;server auth\u0026#34; ] }, \u0026#34;client\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;175200h\u0026#34;, \u0026#34;usages\u0026#34;: [ \u0026#34;signing\u0026#34;, \u0026#34;key encipherment\u0026#34;, \u0026#34;client auth\u0026#34; ] }, \u0026#34;peer\u0026#34;: { \u0026#34;expiry\u0026#34;: \u0026#34;175200h\u0026#34;, \u0026#34;usages\u0026#34;: [ \u0026#34;signing\u0026#34;, \u0026#34;key encipherment\u0026#34;, \u0026#34;server auth\u0026#34;, \u0026#34;client auth\u0026#34; ] } } } }  证书类型:\nclient certificate：客户端使用，用于服务端认证客户端，例如：etcdctl、etcd proxy、fleetctl、docker客户端\nserver certificate：服务端使用，客户端以此验证服务端身份，例如：docker服务端、kube-apiserver\npeer certificate：双向证书，用于etcd集群成员间通信\n  在10.0.0.200上创建生成自签证书签名请求（csr）的JSON配置文件\nvim /opt/certs/etcd-peer-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;k8s-etcd\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;10.0.0.11\u0026#34;, \u0026#34;10.0.0.12\u0026#34;, \u0026#34;10.0.0.21\u0026#34;, \u0026#34;10.0.0.22\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;k8s\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;k8s\u0026#34; } ] }  在10.0.0.200上签发etcd证书和私钥\ncd /opt/certs cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer /opt/certs/etcd-peer-csr.json | cfssl-json -bare etcd-peer  在10.0.0.200上检查签发的证书和私钥\nls -l | grep etcd  注意：私钥etcd-peer-key.pem的权限是600\n  在10.0.0.12、10.0.0.21和10.0.0.22上创建etcd用户\nuseradd -s /sbin/nologin -M etcd  在10.0.0.12、10.0.0.21和10.0.0.22上创建安装文件存储目录\nmkdir /opt/installed \u0026amp;\u0026amp; cd /opt/installed/  在10.0.0.12、10.0.0.21和10.0.0.22上,下载etcd\nwget https://github.com/etcd-io/etcd/releases/download/v3.1.20/etcd-v3.1.20-linux-amd64.tar.gz  在10.0.0.12、10.0.0.21和10.0.0.22上解压etcd\ntar -zxvf etcd-v3.1.20-linux-amd64.tar.gz -C /opt/ mv /opt/etcd-v3.1.20-linux-amd64/ /opt/etcd-v3.1.20 ln -s /opt/etcd-v3.1.20 /opt/etcd  在10.0.0.12、10.0.0.21和10.0.0.22上创建证书目录\nmkdir -p /opt/etcd/certs /data/etcd /data/logs/etcd-server  将运维主机10.0.0.200生成的ca.pem、etcd-peer-key.pem、etcd-peer.pem拷贝到10.0.0.12、10.0.0.21和10.0.0.22上的/opt/etcd/certs目录中\nscp root@10.0.0.200:/opt/certs/ca.pem /opt/etcd/certs/ scp root@10.0.0.200:/opt/certs/etcd-peer-key.pem /opt/etcd/certs/ scp root@10.0.0.200:/opt/certs/etcd-peer.pem /opt/etcd/certs/  在10.0.0.12、10.0.0.21和10.0.0.22创建etcd服务启动脚本\nvim /opt/etcd/etcd-server-startup.sh #!/bin/bash ./etcd --name etcd-server-0-12 \\  --data-dir /data/etcd/etcd-server \\  --listen-peer-urls https://10.0.0.12:2380 \\  --listen-client-urls https://10.0.0.12:2379,http://127.0.0.1:2379 \\  --quota-backend-bytes 8000000000 \\  --initial-advertise-peer-urls https://10.0.0.12:2380 \\  --advertise-client-urls https://10.0.0.12:2379,http://127.0.0.1:2379 \\  --initial-cluster etcd-server-0-12=https://10.0.0.12:2380,etcd-server-0-21=https://10.0.0.21:2380,etcd-server-0-22=https://10.0.0.22:2380 \\  --ca-file ./certs/ca.pem \\  --cert-file ./certs/etcd-peer.pem \\  --key-file ./certs/etcd-peer-key.pem \\  --client-cert-auth \\  --trusted-ca-file ./certs/ca.pem \\  --peer-ca-file ./certs/ca.pem \\  --peer-cert-file ./certs/etcd-peer.pem \\  --peer-key-file ./certs/etcd-peer-key.pem \\  --peer-client-cert-auth \\  --peer-trusted-ca-file ./certs/ca.pem \\  --log-output stdout  注意：etcd集群中各主机的启动脚本略有不同，部署其他节点时注意修改\n  在10.0.0.12、10.0.0.21和10.0.0.22上修改etcd-server-startup.sh权限\nchmod +x /opt/etcd/etcd-server-startup.sh  在10.0.0.12、10.0.0.21和10.0.0.22上修改/opt/etcd-v3.1.20、/data/etcd、/data/logs/etcd-server目录的属主和属组\nchown -R etcd:etcd /opt/etcd-v3.1.20 /data/etcd /data/logs/etcd-server  在10.0.0.12、10.0.0.21和10.0.0.22安装并启动supervisor，将etcd通过supervisor变成后台进程\nyum install -y supervisor systemctl start supervisord \u0026amp;\u0026amp; systemctl enable supervisord  Supervisor是用Python开发的一套通用的进程管理程序，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。它是通过fork/exec的方式把这些被管理的进程当作supervisor的子进程来启动，这样只要在supervisor的配置文件中，把要管理的进程的可执行文件的路径写进去即可。也实现当子进程挂掉的时候，父进程可以准确获取子进程挂掉的信息的，可以选择是否自己启动和报警。supervisor还提供了一个功能，可以为supervisord或者每个子进程，设置一个非root的user，这个user就可以管理它对应的进程。\n  在10.0.0.12、10.0.0.21和10.0.0.22上创建etcd-server的启动配置文件\nvim /etc/supervisord.d/etcd-server.ini [program:etcd-server-0-12] command=/opt/etcd/etcd-server-startup.sh numprocs=1 directory=/opt/etcd autostart=true autorestart=true startsecs=30 startretries=3 exitcodes=0,2 stopsignal=QUIT stopwaitsecs=10 user=etcd redirect_stderr=true stdout_logfile=/data/logs/etcd-server/etcd.stdout.log stdout_logfile_maxbytes=64MB stdout_logfile_backups=4 stdout_capture_maxbytes=1MB stdout_events_enabled=false  注意：etcd集群中各主机的启动脚本略有不同，部署其他节点时注意修改\n  在10.0.0.12、10.0.0.21和10.0.0.22上通过supervisor启动etcd-server，并检查启动状态\nsupervisorctl update supervisorctl status netstat -lntup | grep etcd  在任意一台部署的etcd服务器上，使用etcdctl检测集群的健康状态\n/opt/etcd/etcdctl cluster-health # 或者使用以下命令： /opt/etcd/etcdctl member list # 出现以下信息说明集群状态正确 member 6cbdd801d2c800d9 is healthy: got healthy result from http://127.0.0.1:2379 member 74538ef5dc383e39 is healthy: got healthy result from http://127.0.0.1:2379 member f7a9c20602b8532e is healthy: got healthy result from http://127.0.0.1:2379 cluster is healthy  部署kube-apiserver集群\r#\r\r  集群规划\n   主机名 角色 IP地址     host-0-21.host.com kube-apiserver 10.0.0.21   host-0-22.host.com kube-apiserver 10.0.0.22   host-0-11.host.com Nginx 4层负载均衡 10.0.0.11   host-0-12.host.com Nginx 4层负载均衡 10.0.0.12    在10.0.0.11和10.0.0.12上使用Nginx做4层负载均衡器，用Keepalived跑一个VIP：10.0.0.10，代理两个kube-apiserver实现高可用\n  在10.0.0.21、10.0.0.22上，下载Kubernetes的Server Binaries\ncd /opt/installed/ \u0026amp;\u0026amp; wget https://dl.k8s.io/v1.18.6/kubernetes-server-linux-amd64.tar.gz  在10.0.0.21、10.0.0.22上，解压Kubernetes的Server Binaries\ntar -zxvf kubernetes-server-linux-amd64.tar.gz -C /opt/ mv /opt/kubernetes/ /opt/kubernetes-v1.18.6 ln -s /opt/kubernetes-v1.18.6/ /opt/kubernetes  在10.0.0.200上签发client证书（apiserver与etcd集群通信时使用的证书，apiserver是客户端，etcd集群是服务端）\nvim /opt/certs/apiserver-to-etcd-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;k8s-node\u0026#34;, \u0026#34;hosts\u0026#34;: [], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;k8s\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;ops\u0026#34; } ] } cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client apiserver-to-etcd-csr.json | cfssl-json -bare apiserver-to-etcd  在10.0.0.200上签发kube-apiserver的证书（其他组件与apiserver通信时所需要的证书）\nvim /opt/certs/apiserver-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;k8s-apiserver\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;192.168.0.1\u0026#34;, \u0026#34;kubernetes.default\u0026#34;, \u0026#34;kubernetes.default.svc\u0026#34;, \u0026#34;kubernetes.default.svc.cluster\u0026#34;, \u0026#34;kubernetes.default.svc.cluster.local\u0026#34;, \u0026#34;10.0.0.10\u0026#34;, \u0026#34;10.0.0.21\u0026#34;, \u0026#34;10.0.0.22\u0026#34;, \u0026#34;10.0.0.23\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;k8s\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;ops\u0026#34; } ] } cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server apiserver-csr.json | cfssl-json -bare apiserver  在10.0.0.21、10.0.0.22上创建证书目录\nmkdir -p /opt/kubernetes/server/bin/certs  在10.0.0.21、10.0.0.22上从10.0.0.200上将证书和私钥下载到证书目录中\ncd /opt/kubernetes/server/bin/certs scp root@10.0.0.200:/opt/certs/ca.pem /opt/kubernetes/server/bin/certs scp root@10.0.0.200:/opt/certs/ca-key.pem /opt/kubernetes/server/bin/certs scp root@10.0.0.200:/opt/certs/apiserver.pem /opt/kubernetes/server/bin/certs scp root@10.0.0.200:/opt/certs/apiserver-key.pem /opt/kubernetes/server/bin/certs scp root@10.0.0.200:/opt/certs/apiserver-to-etcd.pem /opt/kubernetes/server/bin/certs scp root@10.0.0.200:/opt/certs/apiserver-to-etcd-key.pem /opt/kubernetes/server/bin/certs  在10.0.0.21、10.0.0.22上创建kube-apiserver的审计策略配置文件\n Kubernetes 审计功能提供了与安全相关的按时间顺序排列的记录集，记录单个用户、管理员或系统其他组件影响系统的活动顺序。 它能帮助集群管理员处理以下问题：\n 发生了什么？ 什么时候发生的？ 谁触发的？ 为什么发生？ 在哪观察到的？ 它从哪触发的？ 它将产生什么后果？  审计政策定义了关于应记录哪些事件以及应包含哪些数据的规则。处理事件时，将按顺序与规则列表进行比较。第一个匹配规则设置事件的 审计级别。 审计策略对象结构在 audit.k8s.io API 组 中定义。\n您可以使用 \u0026ndash;audit-policy-file 标志将包含策略的文件传递给 kube-apiserver。如果不设置该标志，则不记录事件。 注意： kind 和 apiVersion 字段以及 rules 必须 在审计策略文件中提供。没有（0）规则的策略或者不提供有效的 apiVersion 和 kind 值的策略将被视为非法配置。\n mkdir /opt/kubernetes/server/bin/conf vim /opt/kubernetes/server/bin/conf/audit-policy.yaml apiVersion: audit.k8s.io/v1beta1 # This is required. kind: Policy # Don\u0026#39;t generate audit events for all requests in RequestReceived stage. omitStages: - \u0026#34;RequestReceived\u0026#34; rules: # Log pod changes at RequestResponse level - level: RequestResponse resources: - group: \u0026#34;\u0026#34; # Resource \u0026#34;pods\u0026#34; doesn\u0026#39;t match requests to any subresource of pods, # which is consistent with the RBAC policy. resources: [\u0026#34;pods\u0026#34;] # Log \u0026#34;pods/log\u0026#34;, \u0026#34;pods/status\u0026#34; at Metadata level - level: Metadata resources: - group: \u0026#34;\u0026#34; resources: [\u0026#34;pods/log\u0026#34;, \u0026#34;pods/status\u0026#34;] # Don\u0026#39;t log requests to a configmap called \u0026#34;controller-leader\u0026#34; - level: None resources: - group: \u0026#34;\u0026#34; resources: [\u0026#34;configmaps\u0026#34;] resourceNames: [\u0026#34;controller-leader\u0026#34;] # Don\u0026#39;t log watch requests by the \u0026#34;system:kube-proxy\u0026#34; on endpoints or services - level: None users: [\u0026#34;system:kube-proxy\u0026#34;] verbs: [\u0026#34;watch\u0026#34;] resources: - group: \u0026#34;\u0026#34; # core API group resources: [\u0026#34;endpoints\u0026#34;, \u0026#34;services\u0026#34;] # Don\u0026#39;t log authenticated requests to certain non-resource URL paths. - level: None userGroups: [\u0026#34;system:authenticated\u0026#34;] nonResourceURLs: - \u0026#34;/api*\u0026#34; # Wildcard matching. - \u0026#34;/version\u0026#34; # Log the request body of configmap changes in kube-system. - level: Request resources: - group: \u0026#34;\u0026#34; # core API group resources: [\u0026#34;configmaps\u0026#34;] # This rule only applies to resources in the \u0026#34;kube-system\u0026#34; namespace. # The empty string \u0026#34;\u0026#34; can be used to select non-namespaced resources. namespaces: [\u0026#34;kube-system\u0026#34;] # Log configmap and secret changes in all other namespaces at the Metadata level. - level: Metadata resources: - group: \u0026#34;\u0026#34; # core API group resources: [\u0026#34;secrets\u0026#34;, \u0026#34;configmaps\u0026#34;] # Log all other resources in core and extensions at the Request level. - level: Request resources: - group: \u0026#34;\u0026#34; # core API group - group: \u0026#34;extensions\u0026#34; # Version of group should NOT be included. # A catch-all rule to log all other requests at the Metadata level. - level: Metadata # Long-running requests like watches that fall under this rule will not # generate an audit event in RequestReceived. omitStages: - \u0026#34;RequestReceived\u0026#34;  在10.0.0.21、10.0.0.22上创建kube-apiserver的启动脚本\nvim /opt/kubernetes/server/bin/kube-apiserver.sh #!/bin/bash ./kube-apiserver \\  --apiserver-count 2 \\  --audit-log-path /data/logs/kubernetes/kube-apiserver/audit-policy-log \\  --audit-policy-file ./conf/audit-policy.yaml \\  --authorization-mode RBAC \\  --client-ca-file ./certs/ca.pem \\  --requestheader-client-ca-file ./certs/ca.pem \\  --enable-admission-plugins NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota \\  --etcd-cafile ./certs/ca.pem \\  --etcd-certfile ./certs/apiserver-to-etcd.pem \\  --etcd-keyfile ./certs/apiserver-to-etcd-key.pem \\  --etcd-servers https://10.0.0.12:2379,https://10.0.0.21:2379,https://10.0.0.22:2379 \\  --service-account-key-file ./certs/ca-key.pem \\  --service-cluster-ip-range 192.168.0.0/16 \\  --service-node-port-range 3000-29999 \\  --target-ram-mb=1024 \\  --kubelet-client-certificate ./certs/apiserver-to-etcd.pem \\  --kubelet-client-key ./certs/apiserver-to-etcd-key.pem \\  --log-dir /data/logs/kubernetes/kube-apiserver \\  --tls-cert-file ./certs/apiserver.pem \\  --tls-private-key-file ./certs/apiserver-key.pem \\  --v 2 chmod +x /opt/kubernetes/server/bin/kube-apiserver.sh  在10.0.0.21、10.0.0.22上的supervisor中创建kube-apiserver的启动配置文件\nvim /etc/supervisord.d/kube-apiserver.ini [program:kube-apiserver-0-21] command=/opt/kubernetes/server/bin/kube-apiserver.sh numprocs=1 directory=/opt/kubernetes/server/bin autostart=true autorestart=true startsecs=30 startretries=3 exitcodes=0,2 stopsignal=QUIT stopwaitsecs=10 user=root redirect_stderr=true stdout_logfile=/data/logs/kubernetes/kube-apiserver/kube-apiserver.stdout.log stdout_logfile_maxbytes=64MB stdout_logfile_backups=4 stdout_capture_maxbytes=1MB stdout_events_enabled=false mkdir -p /data/logs/kubernetes/kube-apiserver  在10.0.0.21、10.0.0.22上通过supervisor启动kube-apiserver，并检查启动状态\nsupervisorctl update supervisorctl status netstat -lntup | grep kube-apiserv  在10.0.0.11、10.0.0.12上，安装Nginx\nyum install -y nginx rpm -qa nginx  在10.0.0.11、10.0.0.12上，配置4层反向代理（由于是四层反向代理，因此不能配置在Nginx配置文件的http{}里，需要配置在最后）\nvim /etc/nginx/nginx.conf # kube-apiserver的四层反向代理 stream{ upstream kube-apiserver { server 10.0.0.21:6443\tmax_fails=3\tfail_timeout=30s; server 10.0.0.22:6443\tmax_fails=3\tfail_timeout=30s; } server { listen 7443; proxy_connect_timeout 2s; proxy_timeout 900s; proxy_pass kube-apiserver; } }  在10.0.0.11、10.0.0.12上，启动Nginx并设置开机启动\nnginx -t systemctl start nginx \u0026amp;\u0026amp; systemctl enable nginx  在10.0.0.11、10.0.0.12上， 安装Keepalived高可用\nyum install -y keepalived rpm -qa keepalived  在10.0.0.11、10.0.0.12上，制作Keepalived的监听脚本\nvim /etc/keepalived/check_port.sh #!/bin/bash # keepalived 监控端口脚本 # 使用方法： # 在keepalived的配置文件中： # vrrp_script check_port { # script \u0026#34;/etc/keepalived/check_port.sh 6379\u0026#34; # 配置监听的端口 # interval 2 # 检查脚本的频率，单位（秒） # } CHK_PORT=$1 if [ -n \u0026#34;$CHK_PORT\u0026#34; ];then PORT_PROCESS=`ss -lnt|grep $CHK_PORT|wc -l` if [ $PORT_PROCESS -eq 0 ];then echo \u0026#34;Port $CHK_PORTis Not Used，End.\u0026#34; exit 1 fi else echo \u0026#34;Check Port Can\u0026#39;t Be Empty!\u0026#34; fi chmod +x /etc/keepalived/check_port.sh  在10.0.0.11上，配置keepalived（主）（将keepalived.conf中的内容全部删除）\nvim /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id 10.0.0.11 } vrrp_script chk_nginx { script \u0026#34;/etc/keepalived/check_port.sh 7443\u0026#34; interval 2 weight -20 } vrrp_instance VI_1 { state MASTER interface eth0 # 注意根据网卡名称进行修改 virtual_router_id 251 priority 100 advert_int 1 mcast_src_ip 10.0.0.11 nopreempt authentication { auth_type PASS auth_pass 11111111 } track_script { chk_nginx } virtual_ipaddress { 10.0.0.10 } }  在10.0.0.12上，配置keepalived（从）（将keepalived.conf中的内容全部删除）\nvim /etc/keepalived/keepalived.conf ! Configuration File for keepalived global_defs { router_id 10.0.0.12 } vrrp_script chk_nginx { script \u0026#34;/etc/keepalived/check_port.sh 7443\u0026#34; interval 2 weight -20 } vrrp_instance VI_1 { state BACKUP interface eth0 # 注意根据网卡名称进行修改 virtual_router_id 251 priority 90 advert_int 1 mcast_src_ip 10.0.0.12 authentication { auth_type PASS auth_pass 11111111 } track_script { chk_nginx } virtual_ipaddress { 10.0.0.10 } }  在10.0.0.11、10.0.0.12上，启动keepalived并设置开机启动\nsystemctl start keepalived \u0026amp;\u0026amp; systemctl enable keepalived  在10.0.0.11、10.0.0.12上，检查keepalived启动情况\nip addr netstat -lntup | grep 7443  部署kube-controller-manager集群\r#\r\r  kube-controller-manager不用签证书\n集群规划\n   主机名 角色 IP地址     host-0-21.host.com kube-controller-manager 10.0.0.21   host-0-22.host.com kube-controller-manager 10.0.0.22      在10.0.0.21、10.0.0.22上创建kube-controller-manager启动脚本\nvim /opt/kubernetes/server/bin/kube-controller-manager.sh #!/bin/bash ./kube-controller-manager \\ \t--cluster-cidr 172.168.0.0/16 \\ \t--leader-elect true \\ \t--log-dir /data/logs/kubernetes/kube-controller-manager \\ \t--master http://127.0.0.1:8080 \\ \t--service-account-private-key-file ./certs/ca-key.pem \\ \t--service-cluster-ip-range 192.168.0.0/16 \\ \t--root-ca-file ./certs/ca.pem \\ \t--v 2 chmod +x /opt/kubernetes/server/bin/kube-controller-manager.sh  在10.0.0.21、10.0.0.22上创建kube-controller-manager启动脚本的相关目录\nmkdir -p /data/logs/kubernetes/kube-controller-manager  在10.0.0.21、10.0.0.22上的supervisor中创建kube-controller-manager的启动配置文件\nvim /etc/supervisord.d/kube-conntroller-manager.ini [program:kube-controller-manager-0-21] command=/opt/kubernetes/server/bin/kube-controller-manager.sh numprocs=1 directory=/opt/kubernetes/server/bin autostart=true autorestart=true startsecs=30 startretries=3 exitcodes=0,2 stopsignal=QUIT stopwaitsecs=10 user=root redirect_stderr=true stdout_logfile=/data/logs/kubernetes/kube-controller-manager/kube-controller-manager.stdout.log stdout_logfile_maxbytes=64MB stdout_logfile_backups=4 stdout_capture_maxbytes=1MB stdout_events_enabled=false  在10.0.0.21、10.0.0.22上通过supervisor启动kube-controller-manager，并检查启动状态\nsupervisorctl update supervisorctl status  部署kube-scheduler集群\r#\r\r  kube-controller-manager不用签证书\n集群规划\n   主机名 角色 IP地址     host-0-21.host.com kube-controller-manager 10.0.0.21   host-0-22.host.com kube-controller-manager 10.0.0.22      在10.0.0.21、10.0.0.22上创建kube-scheduler启动脚本\nvim /opt/kubernetes/server/bin/kube-scheduler.sh #!/bin/bash ./kube-scheduler \\ \t--leader-elect \\ \t--log-dir /data/logs/kubernetes/kube-scheduler \\ \t--master http://127.0.0.1:8080 \\ \t--v 2 chmod +x /opt/kubernetes/server/bin/kube-scheduler.sh  创建kube-scheduler启动脚本中的相关文件目录\nmkdir -p /data/logs/kubernetes/kube-scheduler  在10.0.0.21、10.0.0.22上的supervisor中创建kube-scheduler的启动配置文件\nvim /etc/supervisord.d/kube-scheduler.ini [program:kube-scheduler-0-21] command=/opt/kubernetes/server/bin/kube-scheduler.sh numprocs=1 directory=/opt/kubernetes/server/bin autostart=true autorestart=true startsecs=30 startretries=3 exitcodes=0,2 stopsignal=QUIT stopwaitsecs=10 user=root redirect_stderr=true stdout_logfile=/data/logs/kubernetes/kube-controller-manager/kube-scheduler.stdout.log stdout_logfile_maxbytes=64MB stdout_logfile_backups=4 stdout_capture_maxbytes=1MB stdout_events_enabled=false  在10.0.0.21、10.0.0.22上通过supervisor启动kube-scheduler，并检查启动状态\nsupervisorctl update supervisorctl status  检查集群健康状态\r#\r\r 将kubectl添加到环境变量中\nln -s /opt/kubernetes/server/bin/kubectl /usr/bin/kubectl  检查集群的健康状态\nkubectl get cs  部署计算（Node）节点服务\r#\r\r 部署kubelet集群\r#\r\r  集群规划\n   主机名 角色 IP地址     host-0-21.host.com kubelet 10.0.0.21   host-0-22.host.com kubelet 10.0.0.22      在10.0.0.200上制作签发kubelet证书的JSON请求文件\nvim /opt/certs/kubelet-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;k8s-kubelet\u0026#34;, \u0026#34;hosts\u0026#34;: [ \u0026#34;127.0.0.1\u0026#34;, \u0026#34;10.0.0.10\u0026#34;, \u0026#34;10.0.0.11\u0026#34;, \u0026#34;10.0.0.12\u0026#34;, \u0026#34;10.0.0.21\u0026#34;, \u0026#34;10.0.0.22\u0026#34;, \u0026#34;10.0.0.23\u0026#34;, \u0026#34;10.0.0.24\u0026#34;, \u0026#34;10.0.0.25\u0026#34;, \u0026#34;10.0.0.26\u0026#34;, \u0026#34;10.0.0.27\u0026#34;, \u0026#34;10.0.0.28\u0026#34;, \u0026#34;10.0.0.29\u0026#34; ], \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;k8s\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;ops\u0026#34; } ] }  在10.0.0.200签发kubelet证书和私钥（其他组件与kebelet通信时的证书）\ncfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server kubelet-csr.json | cfssl-json -bare kubelet  在10.0.0.200上检查签发的证书和私钥\nls -l | grep kubelet  在10.0.0.21、10.0.0.22上拷贝10.0.0.200签发的kubelet证书和私钥（分发证书）\nscp root@10.0.0.200:/opt/certs/kubelet.pem /opt/kubernetes/server/bin/certs/ scp root@10.0.0.200:/opt/certs/kubelet-key.pem /opt/kubernetes/server/bin/certs/  在10.0.0.21上为kubelet创建配置文件\n kubeconfig文件是一个K8S用户的配置文件，它里面包含证书信息，证书过期或更换，需要同步替换该文件\n   set-cluster\ncd /opt/kubernetes/server/bin/conf # 直接执行如下命令： kubectl config set-cluster myk8s \\ --certificate-authority=/opt/kubernetes/server/bin/certs/ca.pem \\ --embed-certs=true \\ --server=https://10.0.0.10:7443 \\ --kubeconfig=kubelet.kubeconfig # 输出结果：Cluster \u0026#34;myk8s\u0026#34; set.   set-credentials\ncd /opt/kubernetes/server/bin/conf # 直接执行如下命令： kubectl config set-credentials k8s-node \\ --client-certificate=/opt/kubernetes/server/bin/certs/apiserver-to-etcd.pem \\ --client-key=/opt/kubernetes/server/bin/certs/apiserver-to-etcd-key.pem \\ --embed-certs=true \\ --kubeconfig=kubelet.kubeconfig # 输出结果：User \u0026#34;k8s-node\u0026#34; set.   set-contest\ncd /opt/kubernetes/server/bin/conf # 直接执行如下命令： kubectl config set-context myk8s-context \\ --cluster=myk8s \\ --user=k8s-node \\ --kubeconfig=kubelet.kubeconfig # 输出结果：Context \u0026#34;myk8s-context\u0026#34; created.   use-context\ncd /opt/kubernetes/server/bin/conf # 直接执行如下命令： kubectl config use-context myk8s-context --kubeconfig=kubelet.kubeconfig # 输出结果：Switched to context \u0026#34;myk8s-context\u0026#34;.    在10.0.0.21上RBAC建权，角色绑定\nvim /opt/kubernetes/server/bin/conf/k8s-node.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: k8s-node roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:node subjects: - apiGroup: rbac.authorization.k8s.io kind: User name: k8s-node # 应用资源配置文件 kubectl create -f k8s-node.yaml # 输出结果：clusterrolebinding.rbac.authorization.k8s.io/k8s-node created # 检查应用资源配置 kubectl get clusterrolebinding k8s-node  在10.0.0.22上，拷贝10.0.0.21上的kubelet.kubeconfig\nscp root@10.0.0.21:/opt/kubernetes/server/bin/conf/kubelet.kubeconfig /opt/kubernetes/server/bin/conf/  在10.0.0.21、10.0.0.22上验证kubelet.kubeconfig的MD5值\nmd5sum /opt/kubernetes/server/bin/conf/kubelet.kubeconfig  在10.0.0.200上准备pause基础镜像\n 在kubernetes的Pod启动时，pause的容器最先启动，然后才启动其他业务容器。\n在Kubernetes中，pause容器主要负责：\n pause容器创建的命名空间作为基础，与pod中的其他容器共享 pause容器在PID namespace中是PID为1的init进程，也是Pod中其他容器的父进程，负责回收pod内的僵尸子进程   docker pull kubernetes/pause  将10.0.0.200上的pause基础镜像提交至私有仓库（harbor）中\ndocker tag f9d5de079539 harbor.k8s.com/public/pause:latest docker login harbor.k8s.com docker push harbor.k8s.com/public/pause:latest  在10.0.0.21、10.0.0.22上创建kubelet启动脚本\nvim /opt/kubernetes/server/bin/kubelet.sh #!/bin/bash ./kubelet \\  --anonymous-auth=false \\  --cgroup-driver systemd \\  --cluster-dns 192.168.0.2 \\  --cluster-domain cluster.local \\  --runtime-cgroups=/systemd/system.slice \\  --kubelet-cgroups=/systemd/system.slice \\  --fail-swap-on=\u0026#34;false\u0026#34; \\  --client-ca-file ./certs/ca.pem \\  --tls-cert-file ./certs/kubelet.pem \\  --tls-private-key-file ./certs/kubelet-key.pem \\  --hostname-override host-0-21.host.com \\  # 根据不同主机进行修改 --image-gc-high-threshold 20 \\  --image-gc-low-threshold 10 \\  --kubeconfig ./conf/kubelet.kubeconfig \\  --log-dir /data/logs/kubernetes/kube-kubelet \\  --pod-infra-container-image harbor.k8s.com/public/pause:latest \\  --root-dir /data/kubelet chmod +x /opt/kubernetes/server/bin/kubelet.sh  在10.0.0.21、10.0.0.22上创建kubelet启动脚本所需要的目录\nmkdir -p /data/logs/kubernetes/kube-kubelet /data/kubelet  在10.0.0.21、10.0.0.22上的supervisor中创建kubelet的启动配置文件\nvim /etc/supervisord.d/kube-kubelet.ini [program:kube-kubelet-0-21] # 根据不同主机进行修改 command=/opt/kubernetes/server/bin/kubelet.sh numprocs=1 directory=/opt/kubernetes/server/bin autostart=true autorestart=true startsecs=30 startretries=3 exitcodes=0,2 stopsignal=QUIT stopwaitsecs=10 user=root redirect_stderr=true stdout_logfile=/data/logs/kubernetes/kube-kubelet/kube-kubelet.stdout.log stdout_logfile_maxbytes=64MB stdout_logfile_backups=4 stdout_capture_maxbytes=1MB stdout_events_enabled=false  在10.0.0.21、10.0.0.22上通过supervisor启动kubelet，并检查启动状态\nsupervisorctl update supervisorctl status  在10.0.0.21、10.0.0.22上检查Node节点是否加入到集群\nkubectl get nodes  在10.0.0.21、10.0.0.22上给Node打tag\nkubectl label node host-0-21.host.com node-role.kubernetes.io/master= kubectl label node host-0-21.host.com node-role.kubernetes.io/node=  部署kube-proxy集群\r#\r\r  集群规划\n   主机名 角色 IP地址     host-0-21.host.com kube-proxy 10.0.0.21   Host-0-22.host.com Kube-proxy 10.0.0.22      在10.0.0.200上制作签发kube-proxy证书的JSON请求文件\nvim /opt/certs/kube-proxy-client-csr.json { \u0026#34;CN\u0026#34;: \u0026#34;system:kube-proxy\u0026#34;, \u0026#34;key\u0026#34;: { \u0026#34;algo\u0026#34;: \u0026#34;rsa\u0026#34;, \u0026#34;size\u0026#34;: 2048 }, \u0026#34;names\u0026#34;: [ { \u0026#34;C\u0026#34;: \u0026#34;CN\u0026#34;, \u0026#34;ST\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;L\u0026#34;: \u0026#34;beijing\u0026#34;, \u0026#34;O\u0026#34;: \u0026#34;od\u0026#34;, \u0026#34;OU\u0026#34;: \u0026#34;ops\u0026#34; } ] }  在10.0.0.200签发kube-proxy证书和私钥（kube-proxy的client证书与其他client证书不通用）\ncfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client kube-proxy-client-csr.json |cfssl-json -bare kube-proxy-client  在10.0.0.200上检查签发的证书和私钥\nls -l | grep kube-proxy  在10.0.0.21、10.0.0.22上拷贝10.0.0.200签发的kubelet证书和私钥（分发证书）\nscp root@10.0.0.200:/opt/certs/kube-proxy-client.pem /opt/kubernetes/server/bin/certs/ scp root@10.0.0.200:/opt/certs/kube-proxy-client-key.pem /opt/kubernetes/server/bin/certs/  在10.0.0.21上为kube-proxy创建配置文件\n  set-cluster\ncd /opt/kubernetes/server/bin/conf kubectl config set-cluster myk8s \\  --certificate-authority=/opt/kubernetes/server/bin/certs/ca.pem \\  --embed-certs=true \\  --server=https://10.0.0.10:7443 \\  --kubeconfig=kube-proxy.kubeconfig   set-credentials\ncd /opt/kubernetes/server/bin/conf kubectl config set-credentials kube-proxy \\  --client-certificate=/opt/kubernetes/server/bin/certs/kube-proxy-client.pem \\  --client-key=/opt/kubernetes/server/bin/certs/kube-proxy-client-key.pem \\  --embed-certs=true \\  --kubeconfig=kube-proxy.kubeconfig   set-contest\ncd /opt/kubernetes/server/bin/conf kubectl config set-context myk8s-context \\  --cluster=myk8s \\  --user=kube-proxy \\  --kubeconfig=kube-proxy.kubeconfig   use-context（kubeconfig是k8s用户的配置文件）\nkubectl config use-context myk8s-context --kubeconfig=kube-proxy.kubeconfig    在10.0.0.22上，拷贝10.0.0.21上的kube-proxy.kubeconfig\nscp root@10.0.0.21:/opt/kubernetes/server/bin/conf/kube-proxy.kubeconfig /opt/kubernetes/server/bin/conf/  在10.0.0.21、10.0.0.22上制作加载ipvs模块的脚本\nvim /root/ipvs.sh #!/bin/bash ipvs_mods_dir=\u0026#34;/usr/lib/modules/$(uname -r)/kernel/net/netfilter/ipvs\u0026#34; for i in $(ls $ipvs_mods_dir|grep -o \u0026#34;^[^.]*\u0026#34;) do /sbin/modinfo -F filename $i \u0026amp;\u0026gt;/dev/null if [ $? -eq 0 ];then /sbin/modprobe $i fi done chmod +x /root/ipvs.sh  在10.0.0.21、10.0.0.22上加载ipvs模块\nbash /root/ipvs.sh  在10.0.0.21、10.0.0.22上验证模块加载是否成功\nlsmod | grep ip_vs  在10.0.0.21、10.0.0.22上创建kube-proxy启动脚本\nvim /opt/kubernetes/server/bin/kube-proxy.sh #!/bin/sh ./kube-proxy \\  --cluster-cidr 172.16.0.0/16 \\  --hostname-override host-0-21.host.com \\  # 根据不同主机进行修改 --proxy-mode=ipvs \\  --ipvs-scheduler=nq \\  --kubeconfig ./conf/kube-proxy.kubeconfig chmod +x /opt/kubernetes/server/bin/kube-proxy.sh  在10.0.0.21、10.0.0.22上的supervisor中创建kubelet的启动配置文件\nvim /etc/supervisord.d/kube-proxy.ini [program:kube-proxy-0-21] command=/opt/kubernetes/server/bin/kube-proxy.sh ; the program (relative uses PATH, can take args) numprocs=1 ; number of processes copies to start (def 1) directory=/opt/kubernetes/server/bin ; directory to cwd to before exec (def no cwd) autostart=true ; start at supervisord start (default: true) autorestart=true ; retstart at unexpected quit (default: true) startsecs=30 ; number of secs prog must stay running (def. 1) startretries=3 ; max # of serial start failures (default 3) exitcodes=0,2 ; \u0026#39;expected\u0026#39; exit codes for process (default 0,2) stopsignal=QUIT ; signal used to kill process (default TERM) stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) user=root ; setuid to this UNIX account to run the program redirect_stderr=true ; redirect proc stderr to stdout (default false) stdout_logfile=/data/logs/kubernetes/kube-proxy/proxy.stdout.log ; stderr log path, NONE for none; default AUTO stdout_logfile_maxbytes=64MB ; max # logfile bytes b4 rotation (default 50MB) stdout_logfile_backups=4 ; # of stdout logfile backups (default 10) stdout_capture_maxbytes=1MB ; number of bytes in \u0026#39;capturemode\u0026#39; (default 0) stdout_events_enabled=false ; emit events on stdout writes (default false)  在10.0.0.21、10.0.0.22上创建kube-proxy启动脚本所需要的目录\nmkdir -p /data/logs/kubernetes/kube-proxy  在10.0.0.21、10.0.0.22上通过supervisor启动kubelet，并检查启动状态\nsupervisorctl update supervisorctl status  在10.0.0.21、10.0.0.22上安装ipvsadm（此步骤可跳过）\nyum install -y ipvsadm ipvsadm -Ln kubectl get svc  验证Kubenetes集群\r#\r\r 在任意一个计算（Node）节点上，创建一个资源配置清单\nvim /root/nginx-ds.yaml apiVersion: apps/v1 kind: DaemonSet metadata: name: nginx-ds labels: app: nginx-ds spec: selector: matchLabels: app: nginx-ds template: metadata: labels: app: nginx-ds spec: containers: - name: my-nginx image: harbor.od.com/public/nginx:v1.7.9 ports: - containerPort: 80  应用资源配置并检查\nkubectl create -f /root/nginx-ds.yaml kubectl get pods kubectl get pods -o wide  部署CNI网络插件（Flannel）\r#\r\r  \rhttps://github.com/coreos/flannel/releases\n集群规划\n   主机名 角色 IP地址     host-0-21.host.com flannel 10.0.0.21   host-0-22.host.com flannel 10.0.0.22      在10.0.0.21、10.0.0.22上，下载flannel\nwget https://github.com/coreos/flannel/releases/download/v0.11.0/flannel-v0.11.0-linux-amd64.tar.gz -P /opt/installed  在10.0.0.21、10.0.0.22上，解压flannel\nmkdir /opt/flannel-v0.11.0 tar -zxvf /opt/installed/flannel-v0.11.0-linux-amd64.tar.gz -C /opt/flannel-v0.11.0/ ln -s /opt/flannel-v0.11.0/ /opt/flannel  在10.0.0.21、10.0.0.22上，创建证书目录\nmkdir /opt/flannel/certs  在10.0.0.21、10.0.0.22上，将10.0.0.200上的apiserver访问etcd的客户端证书拷贝至本地\n flannel默认使用etcd进行存储和配置，而flannel不能直接访问etcd，需要通过apiserver与etcd进行通讯，因此需要拷贝apiserver访问etcd的客户端证书。\n scp root@10.0.0.200:/opt/certs/ca.pem /opt/flannel/certs scp root@10.0.0.200:/opt/certs/apiserver-to-etcd.pem /opt/flannel/certs scp root@10.0.0.200:/opt/certs/apiserver-to-etcd-key.pem /opt/flannel/certs  在10.0.0.21、10.0.0.22上，编辑flannel环境变量env文件\nvim /opt/flannel/subnet.env FLANNEL_NETWORK=172.16.0.0/16 FLANNEL_SUBNET=172.16.21.1/24 # 注意根据不同主机修改不同IP FLANNEL_MTU=1500 FLANNEL_IPMASQ=false  在10.0.0.21、10.0.0.22上，创建启动脚本\nvim /opt/flannel/flanneld.sh #!/bin/bash ./flanneld \\  --public-ip=10.0.0.21 \\  # 注意根据不同主机修改不同IP地址 --etcd-endpoints=https://10.0.0.12:2379,https://10.0.0.21:2379,https://10.0.0.22:2379 \\  --etcd-keyfile=./certs/apiserver-to-etcd-key.pem \\  --etcd-certfile=./certs/apiserver-to-etcd.pem \\  --etcd-cafile=./certs/ca.pem \\  --iface=ens33 \\  # 注意根据实际网卡名称填写 --subnet-file=./subnet.env \\  --healthz-port=2401 chmod +x /opt/flannel/flanneld.sh  在10.0.0.21、10.0.0.22上的etcd中，增加host-gw模型的网络配置信息\n/opt/etcd/etcdctl set /coreos.com/network/config \u0026#39;{\u0026#34;Network\u0026#34;: \u0026#34;172.16.0.0/16\u0026#34;, \u0026#34;Backend\u0026#34;: {\u0026#34;Type\u0026#34;: \u0026#34;host-gw\u0026#34;}}\u0026#39;  host-gw模型（添加静态路由）适用在宿主机在同一网段的局域网中。\nflannel的其他网络模型：\n  VxLAN模型\n/opt/etcd/etcdctl set /coreos.com/network/config \u0026#39;{\u0026#34;Network\u0026#34;: \u0026#34;172.16.0.0/16\u0026#34;, \u0026#34;Backend\u0026#34;: {\u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34;}}\u0026#39;   host-gw与VxLAN混合模型（根据实际情况自动选择host-gw或VxLAN模型）\n/opt/etcd/etcdctl set /coreos.com/network/config \u0026#39;{\u0026#34;Network\u0026#34;: \u0026#34;172.7.0.0/16\u0026#34;, \u0026#34;Backend\u0026#34;: {\u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34;,\u0026#34;Directrouting\u0026#34;: true}}\u0026#39;     在10.0.0.21、10.0.0.22上的etcd中，查看网络配置信息\n/opt/etcd/etcdctl get /coreos.com/network/config  在10.0.0.21、10.0.0.22上的supervisor中，创建flannel的启动配置文件\nvim /etc/supervisord.d/flannel.ini [program:flanneld-0-21] # 注意根据不同主机IP进行更改 command=/opt/flannel/flanneld.sh ; the program (relative uses PATH, can take args) numprocs=1 ; number of processes copies to start (def 1) directory=/opt/flannel ; directory to cwd to before exec (def no cwd) autostart=true ; start at supervisord start (default: true) autorestart=true ; retstart at unexpected quit (default: true) startsecs=30 ; number of secs prog must stay running (def. 1) startretries=3 ; max # of serial start failures (default 3) exitcodes=0,2 ; \u0026#39;expected\u0026#39; exit codes for process (default 0,2) stopsignal=QUIT ; signal used to kill process (default TERM) stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10) user=root ; setuid to this UNIX account to run the program redirect_stderr=true ; redirect proc stderr to stdout (default false) stdout_logfile=/data/logs/flanneld/flanneld.stdout.log ; stderr log path, NONE for none; default AUTO stdout_logfile_maxbytes=64MB ; max # logfile bytes b4 rotation (default 50MB) stdout_logfile_backups=4 ; # of stdout logfile backups (default 10) stdout_capture_maxbytes=1MB ; number of bytes in \u0026#39;capturemode\u0026#39; (default 0) stdout_events_enabled=false ; emit events on stdout writes (default false)  在10.0.0.21、10.0.0.22上的supervisor中，创建flannel的启动配置中所需要的文件目录\nmkdir /data/logs/flanneld/  在10.0.0.21、10.0.0.22上，通过supervisor启动flannel\nsupervisorctl update  在10.0.0.21、10.0.0.22上，优化iptables的SNAT规则\n 由于在同一node访问容器时，访问记录是node节点的IP地址：10.0.0.x，而不是pod集群内部IP地址：172.16.21.x，我们不希望在相同的node节点中的容器之间相互访问经过node节点网卡，因此，需要优化iptables的SNAT规则\n # 安装iptables-services yum install -y iptables-services # 启动iptables并设置开机自动启动 systemctl start iptables \u0026amp;\u0026amp; systemctl enable iptables # 删除默认的规则（所有不是从docker0出来的流量，均被NAT转换） iptables -t nat -D POSTROUTING -s 172.16.21.0/24 ! -o docker0 -j MASQUERADE # 添加新规则（所有目标地址不是172.16.0.0/16和不是从docker0出来的流量，均被NAT转换） iptables -t nat -I POSTROUTING -s 172.16.21.0/24 ! -d 172.16.0.0/16 ! -o docker0 -j MASQUERADE # 删除入口过滤规则 iptables -t filter -D INPUT -j REJECT --reject-with icmp-host-prohibited # 删除出口过滤规则 iptables -t filter -D FORWARD -j REJECT --reject-with icmp-host-prohibited # 检查规则是否生效 iptables-save | grep -i postrouting # 保存当前规则 iptables-save \u0026gt; /etc/iptables_save  在10.0.0.21、10.0.0.22上，重启Docker\n 修改宿主机上的iptables后会影响到docker原本的iptables链的规则，所以需要重启docker服务\n systemctl restart docker  部署服务发现插件（CoreDNS）\r#\r\r 部署K8S内网资源HTTP服务\r#\r\r  在运维主机10.0.0.200上，配置一个Nginx虚拟主机，用以提供Kubernetes统一的资源配置清单访问入口\n  在10.0.0.200上，配置Nginx\nvim /etc/nginx/conf.d/k8s-yaml.k8s.com.conf server { listen 80; server_name k8s-yaml.k8s.com; location / { autoindex on; default_type text/plain; root /data/k8s-yaml; } } mkdir /data/k8s-yaml nginx -t nginx -s reload  在10.0.0.11上，添加k8s-yaml.k8s.com与10.0.0.200的地址解析\nvim /var/named/k8s.com.zone $ORIGIN k8s.com. $TTL 60 ; 1 minutes @ IN SOA dns.k8s.com. dnsadmin.k8s.com. ( 2020010103 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.k8s.com. dns A 10.0.0.11 harbor A 10.0.0.200 k8s-yaml A 10.0.0.200 systemctl restart named dig -t A k8s-yaml.k8s.com @10.0.0.11 +short  部署CoreDNS\r#\r\r  官网：https://coredns.io\nGitHub：https://github.com/coredns/coredns\nDocker Hub：https://hub.docker.com/r/coredns/coredns/tags\n接下来部署CoreDNS，就不再用之前的二进制安装的方式进行了，我们会用容器的方式向Kubernetes交付CoreDNS。\n  在10.0.0.200上，创建CoreDNS的目录\nmkdir /data/k8s-yaml/coredns cd /data/k8s-yaml/coredns  在10.0.0.200上，从Docker Hub上拉取CoreDNS镜像\ndocker pull coredns/coredns:1.7.0 docker images | grep coredns  在10.0.0.200上，给从Docker Hub上拉取CoreDNS镜像打tag\ndocker tag bfe3a36ebd25 harbor.k8s.com/public/coredns:v1.7.0  在10.0.0.200上，将coredns:v1.7.0镜像推送到harbor私有镜像仓库中\ndocker login harbor.k8s.com docker push harbor.k8s.com/public/coredns:v1.7.0  在10.0.0.200上，创建CoreDNS的资源配置清单\n CoreDNS资源配置清单模板：\n\rhttps://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/coredns/coredns.yaml.base\n官方把配置清单写在了一起，我们把配置清单做个分类，使用起来更清晰\n vim /data/k8s-yaml/coredns/rbac.yaml apiVersion: v1 kind: ServiceAccount metadata: name: coredns namespace: kube-system labels: kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: labels: kubernetes.io/bootstrapping: rbac-defaults addonmanager.kubernetes.io/mode: Reconcile name: system:coredns rules: - apiGroups: - \u0026#34;\u0026#34; resources: - endpoints - services - pods - namespaces verbs: - list - watch --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: \u0026#34;true\u0026#34; labels: kubernetes.io/bootstrapping: rbac-defaults addonmanager.kubernetes.io/mode: EnsureExists name: system:coredns roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: system:coredns subjects: - kind: ServiceAccount name: coredns namespace: kube-system vim /data/k8s-yaml/coredns/ConfigMap.yaml apiVersion: v1 kind: ConfigMap metadata: name: coredns namespace: kube-system data: Corefile: |.:53 { errors log health ready kubernetes cluster.local 192.168.0.0/16 forward . 10.0.0.11 cache 30 loop reload loadbalance }  kubernetes cluster.local 192.168.0.0/16：Cluster网段（该网段就是service ip地址范围）\nforward . 10.4.7.11：制定上级dns服务器地址\n vim /data/k8s-yaml/coredns/Deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: coredns namespace: kube-system labels: k8s-app: coredns kubernetes.io/name: \u0026#34;CoreDNS\u0026#34; spec: replicas: 1 selector: matchLabels: k8s-app: coredns template: metadata: labels: k8s-app: coredns spec: priorityClassName: system-cluster-critical serviceAccountName: coredns containers: - name: coredns image: harbor.k8s.com/public/coredns:v1.7.0 args: - -conf - /etc/coredns/Corefile volumeMounts: - name: config-volume mountPath: /etc/coredns ports: - containerPort: 53 name: dns protocol: UDP - containerPort: 53 name: dns-tcp protocol: TCP - containerPort: 9153 name: metrics protocol: TCP livenessProbe: httpGet: path: /health port: 8080 scheme: HTTP initialDelaySeconds: 60 timeoutSeconds: 5 successThreshold: 1 failureThreshold: 5 dnsPolicy: Default volumes: - name: config-volume configMap: name: coredns items: - key: Corefile path: Corefile vim /data/k8s-yaml/coredns/Service.yaml apiVersion: v1 kind: Service metadata: name: coredns namespace: kube-system labels: k8s-app: coredns kubernetes.io/cluster-service: \u0026#34;true\u0026#34; kubernetes.io/name: \u0026#34;CoreDNS\u0026#34; spec: selector: k8s-app: coredns clusterIP: 192.168.0.2 ports: - name: dns port: 53 protocol: UDP - name: dns-tcp port: 53 - name: metrics port: 9153 protocol: TCP  clusterIP: 192.168.0.2 指定了coredns的server cluster ip地址（必须要和kubelet的--cluster-dns ip一致）\n  在10.0.0.21上，应用10.0.0.200创建的CoreDNS资源配置清单\nkubectl apply -f http://k8s-yaml.k8s.com/coredns/rbac.yaml kubectl apply -f http://k8s-yaml.k8s.com/coredns/ConfigMap.yaml kubectl apply -f http://k8s-yaml.k8s.com/coredns/Deployment.yaml kubectl apply -f http://k8s-yaml.k8s.com/coredns/Service.yaml  在kube-system的名称空间下，查看根据CoreDNS资源配置清单创建的pod和service\nkubectl get pods -n kube-system ubectl get svc -n kube-system  检测CoreDNS解析是否正常\ndig -t A host-0-200.host.com @192.168.0.2 +short dig -t A www.badiu.com @192.168.0.2 +short dig -t A nginx-dp.kube-public.svc.cluster.local @192.168.0.2 +short  Kubernetes的DNS实现了服务在集群内被自动发现，那如何使得服务在kubernetes集群外被使用和访问呢？\n  使用NodePort的Service\n注意：无法使用kube-proxy的ipvs模型，只能使用iptables模型\n  使用Ingress的Service（生产上推荐用Ingress）\n注意：Ingress只能调度并暴露7层协议的应用，特指http和https\n   部署服务暴露插件（Ingress）\r#\r\r 部署Ingress\r#\r\r 在10.0.0.200上，创建Traefik的目录\nmkdir /data/k8s-yaml/traefik cd /data/k8s-yaml/traefik  在10.0.0.200上，从Docker Hub上拉取Traefik镜像\ndocker pull traefik:v1.7.2-alpine docker images | grep traefik  在10.0.0.200上，给从Docker Hub上拉取Traefik镜像打tag\ndocker tag add5fac61ae5 harbor.k8s.com/public/traefik:v1.7.2  在10.0.0.200上，将traefik:v1.7.2镜像推送到harbor私有镜像仓库中\ndocker login harbor.k8s.com docker push harbor.k8s.com/public/traefik:v1.7.2  在10.0.0.200上，创建Traefik的资源配置清单\n Traefik资源配置清单模板：\n\rhttps://github.com/containous/traefik/tree/v1.7/examples/k8s\n vim /data/k8s-yaml/traefik/rbac.yaml apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress-controller namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1beta1 kind: ClusterRole metadata: name: traefik-ingress-controller rules: - apiGroups: - \u0026#34;\u0026#34; resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress-controller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress-controller subjects: - kind: ServiceAccount name: traefik-ingress-controller namespace: kube-system vim /data/k8s-yaml/traefik/DaemonSet.yaml apiVersion: extensions/v1beta1 kind: DaemonSet metadata: name: traefik-ingress namespace: kube-system labels: k8s-app: traefik-ingress spec: template: metadata: labels: k8s-app: traefik-ingress name: traefik-ingress spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 containers: - image: harbor.k8s.com/public/traefik:v1.7.2 name: traefik-ingress ports: - name: controller containerPort: 80 hostPort: 81 - name: admin-web containerPort: 8080 securityContext: capabilities: drop: - ALL add: - NET_BIND_SERVICE args: - --api - --kubernetes - --logLevel=INFO - --insecureskipverify=true - --kubernetes.endpoint=https://10.0.0.10:7443 - --accesslog - --accesslog.filepath=/var/log/traefik_access.log - --traefiklog - --traefiklog.filepath=/var/log/traefik.log - --metrics.prometheus vi /data/k8s-yaml/traefik/Service.yaml kind: Service apiVersion: v1 metadata: name: traefik-ingress-service namespace: kube-system spec: selector: k8s-app: traefik-ingress ports: - protocol: TCP port: 80 name: controller - protocol: TCP port: 8080 name: admin-web vim /data/k8s-yaml/traefik/Ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: traefik-web-ui namespace: kube-system annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: traefik.k8s.com http: paths: - path: / backend: serviceName: traefik-ingress-service servicePort: 8080  在10.0.0.21上，应用10.0.0.200创建的Traefik资源配置清单\nkubectl create -f http://k8s-yaml.k8s.com/traefik/rbac.yaml kubectl create -f http://k8s-yaml.k8s.com/traefik/DaemonSet.yaml kubectl create -f http://k8s-yaml.k8s.com/traefik/Service.yaml kubectl create -f http://k8s-yaml.k8s.com/traefik/Ingress.yaml  在kube-system的名称空间下，查看根据Treafik资源配置清单创建的pod和service\nkubectl get pods -n kube-system kubectl get svc -n kube-system kubectl get ingress -n kube-system  在10.0.0.11上，添加treafik与10.0.0.10的地址解析\nvim /var/named/k8s.com.zone $ORIGIN k8s.com. $TTL 60 ; 1 minutes @ IN SOA dns.k8s.com. dnsadmin.k8s.com. ( 2020010104 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.k8s.com. dns A 10.0.0.11 harbor A 10.0.0.200 k8s-yaml A 10.0.0.200 traefik A 10.0.0.10 systemctl restart named dig -t A traefik.k8s.com @10.0.0.11 +short  在10.0.0.11和10.0.0.12上，配置反向代理（可以使用ansible进行统一配置管理）\nvim /etc/nginx/conf.d/k8s.com.conf upstream default_backend_traefik { server 10.0.0.21:81 max_fails=3 fail_timeout=10s; server 10.0.0.22:81 max_fails=3 fail_timeout=10s; } server { server_name *.k8s.com; location / { proxy_pass http://default_backend_traefik; proxy_set_header Host $http_host; proxy_set_header x-forwarded-for $proxy_add_x_forwarded_for; } } nginx -t nginx -s reload  在集群外访问http://traefik.k8s.com，测试是否可以正常访问\n 部署GUI资源管理插件（仪表盘）\r#\r\r 部署Kubernetes-dashboard\r#\r\r  Github：https://github.com/kubernetes/dashboard\n  在10.0.0.200上，创建Dashboard的目录\nmkdir /data/k8s-yaml/dashboard cd /data/k8s-yaml/dashboard  在10.0.0.200上，从Docker Hub上拉取Kubernetes-dashboard镜像\ndocker pull kubernetesui/dashboard:v2.0.3 docker images | grep dashboard  在10.0.0.200上，给从Docker Hub上拉取Kubernetes-dashboard镜像打tag\ndocker tag 503bc4b7440b harbor.k8s.com/public/dashboard:v2.0.3  在10.0.0.200上，将dashboard:v1.8.3镜像推送到harbor私有镜像仓库中\ndocker login harbor.k8s.com docker push harbor.k8s.com/public/dashboard:v2.0.3  在10.0.0.200上，创建Dashboard的资源配置清单\n Dashboard资源配置清单模板：\n\rhttps://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dashboard\n  vim /data/k8s-yaml/dashboard/rbac.yaml apiVersion: v1 kind: ServiceAccount metadata: labels: k8s-app: kubernetes-dashboard addonmanager.kubernetes.io/mode: Reconcile name: kubernetes-dashboard-admin namespace: kube-system --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: kubernetes-dashboard-admin namespace: kube-system labels: k8s-app: kubernetes-dashboard addonmanager.kubernetes.io/mode: Reconcile roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: cluster-admin subjects: - kind: ServiceAccount name: kubernetes-dashboard-admin namespace: kube-system vim /data/k8s-yaml/dashboard/Deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: kubernetes-dashboard namespace: kube-system labels: k8s-app: kubernetes-dashboard kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile spec: selector: matchLabels: k8s-app: kubernetes-dashboard template: metadata: labels: k8s-app: kubernetes-dashboard annotations: scheduler.alpha.kubernetes.io/critical-pod: \u0026#39;\u0026#39; spec: priorityClassName: system-cluster-critical containers: - name: kubernetes-dashboard image: harbor.k8s.com/public/dashboard:v2.0.3 resources: limits: cpu: 100m memory: 300Mi requests: cpu: 50m memory: 100Mi ports: - containerPort: 8443 protocol: TCP args: # PLATFORM-SPECIFIC ARGS HERE - --auto-generate-certificates volumeMounts: - name: tmp-volume mountPath: /tmp livenessProbe: httpGet: scheme: HTTPS path: / port: 8443 initialDelaySeconds: 30 timeoutSeconds: 30 volumes: - name: tmp-volume emptyDir: {} serviceAccountName: kubernetes-dashboard-admin tolerations: - key: \u0026#34;CriticalAddonsOnly\u0026#34; operator: \u0026#34;Exists\u0026#34; vim /data/k8s-yaml/dashboard/Service.yaml apiVersion: v1 kind: Service metadata: name: kubernetes-dashboard namespace: kube-system labels: k8s-app: kubernetes-dashboard kubernetes.io/cluster-service: \u0026#34;true\u0026#34; addonmanager.kubernetes.io/mode: Reconcile spec: selector: k8s-app: kubernetes-dashboard ports: - port: 443 targetPort: 8443 vim /data/k8s-yaml/dashboard/Ingress.yaml apiVersion: extensions/v1beta1 kind: Ingress metadata: name: kubernetes-dashboard namespace: kube-system annotations: kubernetes.io/ingress.class: traefik spec: rules: - host: dashboard.k8s.com http: paths: - backend: serviceName: kubernetes-dashboard servicePort: 443  在10.0.0.21上，应用10.0.0.200创建的Dashboard资源配置清单\nkubectl create -f http://k8s-yaml.k8s.com/dashboard/rbac.yaml kubectl create -f http://k8s-yaml.k8s.com/dashboard/Deployment.yaml kubectl create -f http://k8s-yaml.k8s.com/dashboard/Service.yaml kubectl create -f http://k8s-yaml.k8s.com/dashboard/Ingress.yaml  在kube-system的名称空间下，查看根据Dashboard资源配置清单创建的pod、service和ingress\nkubectl get pods -n kube-system kubectl get svc -n kube-system kubectl get ingress -n kube-system  在10.0.0.11上，添加dashboard与10.0.0.10的地址解析\nvim /var/named/k8s.com.zone $ORIGIN k8s.com. $TTL 60 ; 1 minutes @ IN SOA dns.k8s.com. dnsadmin.k8s.com. ( 2020010105 ; serial 10800 ; refresh (3 hours) 900 ; retry (15 minutes) 604800 ; expire (1 week) 86400 ; minimum (1 day) ) NS dns.k8s.com. dns A 10.0.0.11 harbor A 10.0.0.200 k8s-yaml A 10.0.0.200 traefik A 10.0.0.10 dashboard A 10.0.0.10 systemctl restart named dig -t A dashboard.k8s.com @10.0.0.11 +short  在集群外访问http://dashboard.k8s.com，测试是否可以正常访问\n 使用OpenSSL签发Dashbord证书\r#\r\r 在10.0.0.200上，使用OpenSSL创建Dashbord私钥\ncd /opt/certs/ (umask 077; openssl genrsa -out dashboard.k8s.com.key 2048)  在10.0.0.200上，使用OpenSSL制作证书签发的请求文件\nopenssl req -new -key dashboard.k8s.com.key -out dashboard.k8s.com.csr -subj \u0026#34;/CN=dashboard.k8s.com/C=CN/ST=BJ/L=Beijing/O=k8s/OU=ops\u0026#34;  在10.0.0.200上，使用OpenSSL签发证书\nopenssl x509 -req -in dashboard.k8s.com.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out dashboard.k8s.com.crt -days 7300  在10.0.0.11上，将10.0.0.200上制作好的Dashboard证书拷贝到Nginx中\nmkdir /etc/nginx/certs scp root@10.0.0.200:/opt/certs/dashboard.k8s.com.crt /etc/nginx/certs/  在10.0.0.11上，卸载证书\nvim /etc/nginx/conf.d/dashboard.k8s.com.conf server { listen 80; server_name dashboard.k8s.com; rewrite ^(.*)$ https://${server_name}$1 permanent; } server { listen 443 ssl; server_name dashboard.k8s.com; ssl_certificate \u0026#34;certs/dashboard.k8s.com.crt\u0026#34;; ssl_certificate_key \u0026#34;certs/dashboard.k8s.com.key\u0026#34;; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers HIGH:!aNULL:!MD5; ssl_prefer_server_ciphers on; location / { proxy_pass http://default_backend_traefik; proxy_set_header Host $http_host; proxy_set_header x-forwarded-for $proxy_add_x_forwarded_for; } } nginx -t nginx -s reload  在10.0.0.21上获取Dashboard的Token\nkubectl get secret -n kube-system kubectl describe secret kubernetes-dashboard-admin-token-wbndw -n kube-system  在集群外访问https://dashboard.k8s.com，测试是否可以正常访问\n Kubernetes集群Node节点平滑升级\r#\r\r  当我们遇到K8S有漏洞的时候，或者为了满足需求，有时候可能会需要升级或者降级版本，为了减少对业务的影响，尽量选择在业务低谷的时候来升级\n  首先准备好需要升级的Kubernetes版本文件\n然后在10.0.0.11和10.0.0.12的Nginx上摘除（注释掉需要升级的Node节点）api-server的四层均衡负载\n查看哪个Node上跑的Pod少\nkubectl get node -o wide 将需要升级的Node从节点中删除（以10.0.0.21为例）\nkubectl delete node host-0-21.k8s.com 等所有的Pod都迁移到其他节点上之后，在10.0.0.21上更换Kubernetes的软连接\nrm -rf kubernetes ln -s /opt/kubernetes-v1.19.0 /opt/kubernetes 在supervisor重启服务，生产上记得一个一个重启\nsupervisorctl restart all 启动成功后，查看版本\nkubectl get node -o wide  "},{"id":41,"href":"/docs/C++/C++%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/","title":"C++编程基础","section":"C++","content":"C++简介\r#\r\r C++ 是一种静态类型的、编译式的、通用的、大小写敏感的、不规则的编程语言，支持面向过程、面向对象编程和泛型编程。\nC++ 是 C 的一个超集，事实上，任何合法的 C 程序都是合法的 C++ 程序。\n C++的开发工具\r#\r\r C++常用的开发工具有Microsoft Visual Studio和Jetbrains CLion。\n C++的基础语法\r#\r\r HelloWorld\r#\r\r // 引入iostream库 #include \u0026lt;iostream\u0026gt; // 调用名称空间std内定义的所有标识符 using namespace std; int main() { // 输出\u0026#34;Hello,World!\u0026#34;，并换行  cout \u0026lt;\u0026lt; \u0026#34;Hello,World!\u0026#34; \u0026lt;\u0026lt; endl; // 将程序在此处暂停,等待任意输入后,再继续执行后续代码  system(\u0026#34;pause\u0026#34;); // 程序正常退出  return 0; }  注释\r#\r\r 单行注释：// 描述信息 多行注释：/* 描述信息 */\n 变量\r#\r\r 作用：给指定的一段内存空间起名，方便操作这个段内存空间。\n语法：数据类型 变量名称 = 初始值;\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义一个整型变量a，并赋值数字10  int a = 10; cout \u0026lt;\u0026lt; \u0026#34;变量a的值是：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; }  常量\r#\r\r 作用：用于记录程序中不可更改的数据\n定义常量的两种方式：\n  #define宏常量：#define 常量名 常量值\n 通常在文件上方定义，表示一个常量。\n   使用const修饰的变量：const 数据类型 常量名 = 常量值\n 通常在变量定义前加关键字const，修饰该变量为常量，不可修改。\n   示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; // 定义宏常量 #define day 7  int main() { cout \u0026lt;\u0026lt; \u0026#34;一周共有：\u0026#34; \u0026lt;\u0026lt; day \u0026lt;\u0026lt; \u0026#34;天\u0026#34; \u0026lt;\u0026lt; endl; // 使用const修饰的变量  const int month = 12; cout \u0026lt;\u0026lt; \u0026#34;一年共有：\u0026#34; \u0026lt;\u0026lt; month \u0026lt;\u0026lt; \u0026#34;个月\u0026#34; \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; }  标识符的命名规则\r#\r\r  标识符不能是关键字 标识符只能由字母、数字、下划线组成 第一个字符必须为字母或下划线 标识符中字母区分大小写   数据类型\r#\r\r 整型\r#\r\r 作用：表示整数类型的数据。\nC++中对于占用不同内存空间的整形有四种方式：\n   数据类型 占用空间 取值范围     short（短整型） 2 字节 （-2^15 ~ 2^15-1）   int（整型） 4 字节 （-2^31 ~ 2^31-1）   long（长整型） Windows为 4 字节，32位Linux为 4 字节，64位Linux为 8 字节 （-2^31 ~ 2^31-1）   long long（长长整型） 8 字节 （-2^63 ~ 2^63-1）     实型（浮点型）\r#\r\r 作用：用于表示小数。\n浮点型变量分为两种：\n 单精度：float 双精度：double   单精度和双精度的区别在于表示的有效数字范围不同\n    数据类型 占用内存空间 有效数字范围     float 4 字节 7 位有效数字   double 8 字节 15 ~ 16 位有效数字    示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 由于编译器看到浮点型的数据会默认为double类型，因此定义float类型的变量时在值后加上“f”可以避免数据类型的转换  float f1 = 3.1415926f; double d1 = 3.1415926; // 默认情况下，输出的浮点型只能显示6位有效数字，如果需要显示更多的有效数字，需要做额外的配置  cout \u0026lt;\u0026lt; \u0026#34;f1的值为：\u0026#34; \u0026lt;\u0026lt; f1 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;d1的值为：\u0026#34; \u0026lt;\u0026lt; d1 \u0026lt;\u0026lt; endl; // 科学计数法在浮点型中的应用  float f2 = 2e3; // 2 * 10^3  double d2 = 2e-3; // 2 * 0.1^3  cout \u0026lt;\u0026lt; \u0026#34;f2的值为：\u0026#34; \u0026lt;\u0026lt; f2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;d2的值为：\u0026#34; \u0026lt;\u0026lt; d2 \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; }  字符型\r#\r\r 作用：字符型变量用于表示单个字符的类型。\n语法：char ch = 'a';\n 在C和C++中字符型变量只占用1个字节。字符型变量并不是把字符本身放到内存中存储，而是将对应的ASCii编码放入到存储单元。\n注意：在显示字符型变量时，用单引号将字符括起来，不要用双引号；单引号内只能有一个字符，不可以是字符串。\n 示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 字符型变量的创建  char ch = \u0026#39;a\u0026#39;; cout \u0026lt;\u0026lt; \u0026#34;字符型变量a的值为：\u0026#34; \u0026lt;\u0026lt; ch \u0026lt;\u0026lt; endl; // 字符型变量所占的内存大小  cout \u0026lt;\u0026lt; \u0026#34;字符型变量a所占的内存大小：\u0026#34; \u0026lt;\u0026lt; sizeof(ch) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; // 字符型变量对应的ASCII编码  cout \u0026lt;\u0026lt; \u0026#34;字符型变量a所对应的ASCII编码为：\u0026#34; \u0026lt;\u0026lt; (int)ch \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; }  字符串型\r#\r\r 作用：用于表示一串字符\nC语言风格的字符串：char 变量名称[] = \u0026quot;字符串值\u0026quot;\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义一个C语言风格的字符串  char str[] = \u0026#34;Hello,World!\u0026#34;; cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return(0); } C++语言风格的字符串：string 变量名称 = \u0026quot;字符串值\u0026quot;\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义一个C++风格的字符串  string str = \u0026#34;Hello,World!\u0026#34;; cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return(0); }  布尔型\r#\r\r 作用：表示真或假的值\n布尔（bool）类型只有两个值：\n true（本质是：1） false（本质是：0）  布尔（bool）类型占用1字节。\n C/C++遵循非零即真\n 示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义一个布尔类型的变量flag \tbool flag = true; cout \u0026lt;\u0026lt; flag \u0026lt;\u0026lt; endl; // 1  flag = false; cout \u0026lt;\u0026lt; flag \u0026lt;\u0026lt; endl; // 0  system(\u0026#34;pause\u0026#34;); return(0); }  sizeof\r#\r\r 作用：利用sizeof可以统计数据类型所占内存大小。\n语法：sizeof(数据类型/标量)\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { cout \u0026lt;\u0026lt; \u0026#34;short类型所占内存空间为：\u0026#34; \u0026lt;\u0026lt; sizeof(short) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;int类型所占内存空间为：\u0026#34; \u0026lt;\u0026lt; sizeof(int) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;long类型所占内存空间为：\u0026#34; \u0026lt;\u0026lt; sizeof(long) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;long long类型所占内存空间为：\u0026#34; \u0026lt;\u0026lt; sizeof(long long) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;float类型所占内存空间为：\u0026#34; \u0026lt;\u0026lt; sizeof(float) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;double类型所占内存空间为：\u0026#34; \u0026lt;\u0026lt; sizeof(double) \u0026lt;\u0026lt; \u0026#34;字节\u0026#34; \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; }  转义字符\r#\r\r 作用：用于表示一些不能显示出来的ASCII字符\n   转义字符 含义 ASCII编码值（十进制）     \\a 报警 007   \\b 退格（BS），将当前位置移到前一列 008   \\t 水平制表（HT）（跳到下一个Tab位置） 009   \\n 换行（LF），将当前位置移到下一行开头 010   \\v 垂直制表（VT） 011   \\f 换页（FF），将当前位置移到下一页开头 012   \\r 回车（CR），将当前位置移到本行开头 013   \\\u0026quot; 双引号字符 034   \\' 单引号字符 039   ? 代表一个问号 063   \\\\ 反斜线字符“\\” 092     获取输入数据\r#\r\r 作用：从键盘获取输入的数据\n关键字：cin\n语法：cin \u0026gt;\u0026gt; 变量名称\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { int a = 0; cout \u0026lt;\u0026lt; \u0026#34;请输入整型变量的值：\u0026#34;; cin \u0026gt;\u0026gt; a; cout \u0026lt;\u0026lt; \u0026#34;您输入的整型变量的值为：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return(0); }  运算符\r#\r\r 作用：用于执行代码的运算。\n运算符的分类\n   运算符类型 作用     算术运算符 用于处理四则运算   赋值运算符 用于将表达式的值赋值给变量   比较运算符 用于表达式的比较，并返回一个布尔值（true或false）   逻辑运算符 用于根据表达式的值返回布尔值（true或false）     算数运算符\r#\r\r 算术运算符包括以下符号\n   运算符 术语 示例 结果     + 正号 +10 10   - 负号 -10 -10   + 加 10 + 5 15   - 减 10 - 5 5   * 乘 10 * 5 50   / 除 10 / 5 2   % 取模（取余） 10 % 3 1   ++ 前置递增（先自增，再运算或赋值） a = 2; b = ++a; a = 3; b = 3;   ++ 后置递增（先运算或赋值，再自增） a = 2; b = a++; a = 3; b = 2;   \u0026ndash; 前置递减（先自减，再运算或赋值） a = 2; b = \u0026ndash;a; a = 1; b = 1;   \u0026ndash; 后置递减（先运算或赋值，再自减） a = 2; b = a\u0026ndash;; a = 1; b = 2;     赋值运算符\r#\r\r    运算符 术语 示例 结果     = 赋值 a = 2; b = 3; a = 2; b = 3;   += 加等于 a = 2; a += 3; a = 5;   -= 减等于 a = 2; a -= 3; a = -1;   *= 乘等于 a = 2; a *= 3; a = 6;   /= 除等于 a = 10; a /= 5; a = 2;   %= 模等于 a = 3; a %= 2; a = 1;     比较运算符\r#\r\r    运算符 术语 示例 结果     == 等于 2 == 3 0   != 不等于 2 != 3 1   \u0026lt; 小于 2 \u0026lt; 3 1   \u0026gt; 大于 2 \u0026gt; 3 0   \u0026lt;= 小于等于 2 \u0026lt;= 3 1   \u0026gt;= 大于等于 2 \u0026gt;= 3 0     逻辑运算符\r#\r\r    运算符 术语 示例 结果     ! 非 !a 如果a为true，则!a为false   \u0026amp;\u0026amp; 与 a \u0026amp;\u0026amp; b 当a和b都为true，则结果为true，否则为false   || 或 a || b 当a和b中有一个为true，则结果为true；当a和b都为false时，结果为false     流程控制\r#\r\r C/C++支持最基本的三种程序运行结构：顺序结构、选择结构、循环结构。\n 顺序结构：程序按顺序执行，不发生跳转。 选择结构：依据条件是否满足，有选择的执行相应功能。 循环结构：依据条件是否满足，循环多次执行某段代码。   选择结构\r#\r\r if语句\r#\r\r 作用：执行满足条件的语句。\nif语句有三种形式：单行格式if语句、多行格式if语句、多条件的if语句。\nif语句可以进行嵌套。\n 单行格式if语句：if(条件){ 满足条件执行的语句 }\n 注意：if条件后不要加;\n 示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 用户输入一个整数 \tint a = 0; cout \u0026lt;\u0026lt; \u0026#34;请输入一个整数：\u0026#34;; cin \u0026gt;\u0026gt; a; // 打印用户输入的整数 \tcout \u0026lt;\u0026lt; \u0026#34;您输入的整数为：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; // 判断用户输入的整数大于100时，打印响应的语句 \tif (a \u0026gt; 100) { cout \u0026lt;\u0026lt; \u0026#34;您输入的整数大于100！\u0026#34; \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  多行格式if语句：if ( 条件 ) { 满足条件的执行语句 } else { 不满足条件的执行语句 }\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 用户输入一个整数 \tint a = 0; cout \u0026lt;\u0026lt; \u0026#34;请输入一个整数：\u0026#34;; cin \u0026gt;\u0026gt; a; // 打印用户输入的整数 \tcout \u0026lt;\u0026lt; \u0026#34;您输入的整数为：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; // 判断用户输入的整数大于或小于等于100时，打印响应的语句； \tif (a \u0026gt; 100) { cout \u0026lt;\u0026lt; \u0026#34;您输入的整数大于100\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;您输入的整数小于等于100\u0026#34; \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  多条件的if语句：if ( 条件1 ) { 满足条件1的执行语句 } else if ( 条件2 ){ 满足条件2的执行语句 } …… else { 所有条件都不满足时的执行语句 }\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 用户输入一个整数 \tint a = 0; cout \u0026lt;\u0026lt; \u0026#34;请输入一个整数：\u0026#34;; cin \u0026gt;\u0026gt; a; // 打印用户输入的整数 \tcout \u0026lt;\u0026lt; \u0026#34;您输入的整数为：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; if (a \u0026gt; 100) { cout \u0026lt;\u0026lt; \u0026#34;您输入的整数大于100\u0026#34; \u0026lt;\u0026lt; endl; } else if (a \u0026lt; 100) { cout \u0026lt;\u0026lt; \u0026#34;您输入的整数小于100\u0026#34; \u0026lt;\u0026lt; endl; } else { cout \u0026lt;\u0026lt; \u0026#34;您输入的整数等于100\u0026#34; \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  switch语句\r#\r\r 作用：执行多条件分支语句。\n语法：\nswitch (表达式) { case 结果1: 执行语句; break; case 结果2: 执行语句; break; ...... default: 执行语句; break; } 示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 提示用户操作 \tcout \u0026lt;\u0026lt; \u0026#34;[1] 用户登录\\n[2] 用户注册\\n[3] 退出系统\\n请输入功能数字：\u0026#34;; // 接收用户输入 \tint input = 0; cin \u0026gt;\u0026gt; input; cout \u0026lt;\u0026lt; \u0026#34;您输入的数字为：\u0026#34; \u0026lt;\u0026lt; input \u0026lt;\u0026lt; endl; // 通过switch语句根据用户的输入进入到相应的功能 \tswitch (input) { case 1: cout \u0026lt;\u0026lt; \u0026#34;正在进入用户登录，请稍后...\u0026#34; \u0026lt;\u0026lt; endl; break; case 2: cout \u0026lt;\u0026lt; \u0026#34;正在进入用户注册，请稍后...\u0026#34; \u0026lt;\u0026lt; endl; break; case 3: cout \u0026lt;\u0026lt; \u0026#34;正在退出系统，请稍后...\u0026#34; \u0026lt;\u0026lt; endl; break; default: cout \u0026lt;\u0026lt; \u0026#34;输入错误，请重新输入！\u0026#34; \u0026lt;\u0026lt; endl; break; } system(\u0026#34;pause\u0026#34;); return(0); }  if语句和switch语句的区别：\n switch语句的结构清晰，并且在执行效率上优于if语句； switch在判断的值或表达式，只能是整型或者字符型，且不可以是一个范围区间。    三目运算符（三元运算符）\r#\r\r 作用：通过三元运算符可以实现简单的判断。\n语法：表达式1 ? 表达式2 : 表达式3;\n语法解释：如果表达式1为true，执行表达式2，并返回表达式2的结果；如果表达式2为true，执行表达式3，并返回表达式3的结果。\n 在C++中，如果三元运算符返回的是一个变量，那么此变量可以继续赋值。\n 示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义3个变量a、b、c \tint a = 10; int b = 20; int c = 30; // 通过三元运算符比较a和b，将较大的值赋值给c \tc = a \u0026gt; b ? a : b; // 打印结果 \tcout \u0026lt;\u0026lt; \u0026#34;c的值是：\u0026#34; \u0026lt;\u0026lt; c \u0026lt;\u0026lt; endl; // c的值是：20  // 比较a和b的大小，并将100赋值给返回的变量  a \u0026gt; b ? a : b = 100 // 打印结果  cout \u0026lt;\u0026lt; \u0026#34;a的值是：\u0026#34; \u0026lt;\u0026lt; a \u0026lt;\u0026lt; endl; // a的值是：10 \tcout \u0026lt;\u0026lt; \u0026#34;b的值是：\u0026#34; \u0026lt;\u0026lt; b \u0026lt;\u0026lt; endl; // b的值是：100  system(\u0026#34;pause\u0026#34;); return(0); }  循环结构\r#\r\r while循环语句\r#\r\r 作用：当满足循环条件时，执行循环语句。\n语法：while ( 循环条件 ) { 循环语句 };\n语法解释：只要是循环条件为true，就一直执行循环语句。\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 循环输出0~10 \tint num = 0; while (num \u0026lt;= 10) { cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; num++; } system(\u0026#34;pause\u0026#34;); return(0); }  在使用while循环语句时要注意避免死循环\n  do\u0026hellip;while循环语句\r#\r\r 作用：先执行一次循环语句，在判断循环条件是否执行循环语句。\n语法：do { 循环语句 } while ( 循环条件 );\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { int num = 0; do { cout \u0026lt;\u0026lt; num \u0026lt;\u0026lt; endl; num++; } while (0); system(\u0026#34;pause\u0026#34;); return(0); }  do...while与while的区别在于do...while先要执行一次循环语句，在进行循环条件的判断。\n  for循环语句\r#\r\r 作用：当满足循环条件时，执行循环语句。\n语法：for ( 初始表达式; 条件表达式; 循环增量 ) { 循环语句; }\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 循环输出0~10 \tfor (int i = 0; i \u0026lt;= 10; i++) { cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  for循环的结构比较清晰，在日常开发中较为常用\n  嵌套循环\r#\r\r 作用：在循环体中嵌套循环，用于解决一些特定场景的实际问题。\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; // 打印机99乘法表 int main() { // 循环打印行 \tfor (int i = 1; i \u0026lt; 10; i++) { // 循环打印列 \tfor (int j = 1; j \u0026lt;= i; j++) { cout \u0026lt;\u0026lt; j \u0026lt;\u0026lt; \u0026#34;x\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; \u0026#34;=\u0026#34; \u0026lt;\u0026lt; i * j \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  跳转语句\r#\r\r break语句\r#\r\r 作用：用于跳出选择结构和循环结构。\n使用场景：\n 在switch选择语句中，case执行完毕跳出并终止switch； 在循环语句中跳出当前循环  示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 循环打印0～9，当遇到5时，停止打印 \tfor (int i = 0; i \u0026lt; 10; i++) { if (i == 5) { break; } cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  continue语句\r#\r\r 作用：跳过当前循环，执行下一次循环。\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 循环打印0～9，当遇到5时，跳过当前循环，执行下一次循环 \tfor (int i = 0; i \u0026lt; 10; i++) { if (i == 5) { continue; } cout \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return(0); }  goto语句\r#\r\r 作用：如果存在goto的标记，当代码执行到goto时会直接跳转到标记的位置。\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { cout \u0026lt;\u0026lt; \u0026#34;1\u0026#34; \u0026lt;\u0026lt; endl; goto flag; cout \u0026lt;\u0026lt; \u0026#34;2\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;3\u0026#34; \u0026lt;\u0026lt; endl; flag: cout \u0026lt;\u0026lt; \u0026#34;5\u0026#34; \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return(0); }  由于goto会造成代码结构混乱，非常不利于阅读，因此开发中不建议使用goto语句\n  数组\r#\r\r 基本概念：所谓数组，就是一个具有相同类型数据元素的集合。\n特点：\n 一个数组中，每个元素都是相同类型的数据； 数组占用一块连续的内存空间； 可以通过索引取值。   一维数组\r#\r\r 一维数组共有三种定义方式：\n 数据类型 数组名称[数组长度]; 数据类型 数组名称[数组长度] = {值1, 值2, ...}; 数据类型 数组名称[ ] = {值1, 值2, ...};   一维数组名称的用途：\n 通过sizeof(数组名称)统计数组所占用的内存空间； 通过cout \u0026lt;\u0026lt; 数组名称 \u0026lt;\u0026lt; endl;获取数组在内存中的首地址（十六进制）。   冒泡排序：\n是一种比较常用的排序算法，可以对数组内的元素进行排序。原理是通过数组的第一个位置开始依次比较相邻的元素，如果第一个比第二个的数值大，则交换位置，如果第二个比第三个大，则交换它们的位置，以此类推，执行完毕后，数组的最后一个值一定是数组中最大的值，因此在下一轮排序中就可以将最后一个值排除，即每轮排序的次数都会-1，直到数组内的元素不再需要比较。\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; // 利用冒泡排序实现数组内元素的升序排列 int main() { // 定义一个无序数组 \tint arr[9] = { 4,2,8,0,5,7,1,3,9 }; // 冒泡排序，总共排序的轮数为元素个数-1 \tfor (int i = 0; i \u0026lt; 9 - 1; i++) { // 循环对比的次数等于元素个数减 \tfor (int j = 0; j \u0026lt; 9 - i - 1; j++) { // 如果第一个元素比第二个元素大，则交换两个元素 \tif (arr[j] \u0026gt; arr[j+1]) { // 定义一个临时变量，用于保存交换位置时的临时元素数据 \tint temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; } } } // 数组排序后的结果 \tfor (int i = 0; i \u0026lt; 9; i++) { cout \u0026lt;\u0026lt; arr[i] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return(0); }  二维数组\r#\r\r 二维数组是在一维数组的基础上增加了一个维度，二维数组本质上是以数组作为数组元素的数组，即“数组的数组”。不严谨的说，二维数组可以理解为一个有横纵坐标的二维表。\n二维数组有4种定义方式：\n 数据类型 数组名称 [ 行数 ][ 列数 ]; 数据类型 数组名称 [ 行数 ][ 列数 ] = { {数据1,数据2} , {数据3,数据4} }; 数据类型 数组名称 [ 行数 ][ 列数 ] = { 数据1, 数据2, 数据3, 数据4 }; 数据类型 数组名称 [ ][ 列数 ] = { 数据1, 数据2, 数据3, 数据4 };   以上4种定义方式，第二种更为直观，可以提高代码的可读性\n二维数组的行和列的访问都是从0开始\n 示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义一个3行2列的二维数组 \tint arr[3][2] = { {1,2},{3,4},{5,6} }; // 通过嵌套循环将二维数组的所有值遍历出来 \t// 外层循环打印行 \tfor (size_t i = 0; i \u0026lt; 3; i++) { // 内层循环打印列 \tfor (size_t j = 0; j \u0026lt; 2; j++) { cout \u0026lt;\u0026lt; arr[i][j]; } cout \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return 0;  二维数组名称的用途：\n 通过sizeof(数组名称)统计数组所占用的内存空间； 通过cout \u0026lt;\u0026lt; 数组名称 \u0026lt;\u0026lt; endl;获取数组在内存中的首地址（十六进制）。   二维数组应用案例：\n案例描述：有三名同学（001、002、003），在一次考试中的成绩如下\n   学号 数学 语文 英语     1 100 100 100   2 100 90 90   3 80 70 60    请分别输出三名同学的总成绩。\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { // 定义一个3行2列的二维数组 \tint arr[3][4] = { {1,100,100,100},{2,100,90,90},{3,80,70,60} }; // 通过嵌套循环将二维数组的所有值遍历出来 \t// 外层循环打印行 \tfor (size_t i = 0; i \u0026lt; 3; i++) { //定义统计分数总和变量sum \tint sum = 0; // 内层循环打印列 \tfor (size_t j = 0; j \u0026lt; 4; j++) { if ( j != 0 ) { sum += arr[i][j]; } } cout \u0026lt;\u0026lt; arr[i][0] \u0026lt;\u0026lt; \u0026#34;号学生的总分数为：\u0026#34; \u0026lt;\u0026lt; sum \u0026lt;\u0026lt; endl; } system(\u0026#34;pause\u0026#34;); return 0; }  函数\r#\r\r 作用：将一段经常使用的代码封装起来，减少重复代码，增加代码的复用性。\n一个较大的程序，一般分为若干个程序块，每个程序块实现特定的功能。\n 函数的定义\r#\r\r 函数的定义一般包含5个部分：\n  返回值的类型\n  函数名称\n  参数列表\n 定义函数时的参数称之为“形参”，当调用函数时写入的参数称之为“实参”。\n   函数体语句\n  return 表达式\n 如果函数不需要返回值，可以在定义函数时使用void（表示无类型）作为返回值类型，同时return后为空。\n   语法：\n返回值类型 函数名称 (参数列表) { 函数体语句 return 表达式 } 示例：\n// 定义一个求和函数，当传入两个数据类型为整形的参数，可以算出这两参数的求和结果 int sum(int num1,int num2) { int sum = num1 + num2; return sum; } 函数的调用\r#\r\r 作用：使用定义好的函数，执行其内部的函数体语句和获取返回值。\n语法：函数名称(参数)\n示例：\n#include \u0026lt;iostream\u0026gt;using namespace std; int sum(int num1,int num2) { int sum = num1 + num2; return sum; } int main() { // 调用sum函数，并通过变量s接收sum函数的返回值 \tint s = sum(1,2); cout \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; system(\u0026#34;pause\u0026#34;); return 0; }  常见的函数样式\r#\r\r 常见的函数样式有：\n 无参数无返回值 无参数有返回值 有参数无返回值 有参数有返回值   函数的声明\r#\r\r 作用：告诉编译器函数名称以及如何调用函数。函数的实际主体可以单独定义。\n 函数可以多次声明，但是只能定义一次函数\n // 声明 max 函数，可以声明多次 int max(int a, int b); int max(int a, int b); // 定义 max 函数，只能定义一次 int max(int a,int b) { return a \u0026gt; b ? a : b; }  函数的分文件编写\r#\r\r 作用：让代码结构更清晰。\n函数分文件编写一般分为4个部分：\n 创建后缀名为.h的头文件 在缀名为.h头文件中写函数的声明 创建后缀名为.cpp的源文件 在缀名为.cpp源文件中写函数的定义  示例：\n// 创建 func.h 头文件 #include \u0026lt;iostream\u0026gt;using namespace std; // 在头文件中声明函数 void func(int a, int b); // 创建 func.cpp 的源文件 #include \u0026#34;func.h\u0026#34; 指针\r#\r\r 作用：通过指针可以间接访问内存。\n特点：\n 内存地址编号从0开始，一般用十六进制数字表示； 可以利用指针变量保存内存地址。   指针变量的定义和使用\n"},{"id":42,"href":"/docs/Linux/CentOS/CentOS-7%E5%80%9F%E5%8A%A9%E7%B3%BB%E7%BB%9F%E5%AD%98%E5%82%A8%E7%AE%A1%E7%90%86%E5%99%A8%E7%AE%A1%E7%90%86LVM/","title":"CentOS 7借助系统存储管理器管理LVM","section":"CentOS","content":"安装系统存储管理器\nsudo yum install system-storage-manager  查看关于现有磁盘存储设备、存储池、LVM卷和存储快照的信息\nsudo ssm list  将一个新的物理磁盘（例如： /dev/sdb）添加到现有的存储池（比如 centos）中\nsudo ssm add -p \u0026lt;pool-name\u0026gt; \u0026lt;device\u0026gt;  如果你在存储池中有额外空间，可以扩大存储池中现有的磁盘卷\nsudo ssm resize -s [size] [volume] 例如：需要给home挂载点增加 100G 的空间\nsudo ssm resize -s +100G /dev/centos_centos7/home  使用 xfs_growfs 来扩展现有的 XFS 文件系统\nsudo xfs_growfs /dev/centos_centos7/home  "},{"id":43,"href":"/docs/Linux/CentOS/CentOS-7%E6%90%AD%E5%BB%BAFTP%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"CentOS 7搭建FTP服务器","section":"CentOS","content":"安装 FTP 服务\r#\r\r 安装 vsftpd\nyum install vsftpd -y  启动 vsftpd\nsystemctl start vsftpd  设置开机自动启动vstpd\nsystemctl enable vsftpd  启动后，可以看到系统已经监听了 21 端口：\nnetstat -nltp | grep 21  此时，访问 ftp://127.0.0.1 就可浏览机器上的 /var/ftp 目录了。\n 配置 FTP 权限\r#\r\r 目前 FTP 服务登陆允许匿名登陆，也无法区分用户访问，我们需要配置 FTP 访问权限\n  了解V SFTP 配置 vsftpd 的配置目录为 /etc/vsftpd，包含下列的配置文件：\n vsftpd.conf 为主要配置文件 ftpusers 配置禁止访问 FTP 服务器的用户列表 user_list 配置用户访问控制    阻止匿名访问和切换根目录\n匿名访问和切换根目录都会给服务器带来安全风险，我们把这两个功能关闭。编辑 /etc/vsftpd/vsftpd.conf，找到下面两处配置并修改：\n# 禁用匿名用户 anonymous_enable=NO # 禁止切换根目录 chroot_local_user=YES  编辑/etc/pam.d/vsftpd\n# 将auth required pam_shells.so修改为 auth required pam_nologin.so  重新启动 FTP 服务\nsystemctl restart vsftpd  创建 FTP 用户\nuseradd ftpuser  为用户 ftpuser 设置密码：\necho \u0026#34;K9eM57ca\u0026#34; | passwd ftpuser --stdin  限制用户 ftpuser 只能通过 FTP 访问服务器，而不能直接登录服务器\nusermod -s /sbin/nologin ftpuser  为用户分配主目录\n 为用户 ftpuser 创建主目录并约定：\n /data/ftp 为主目录, 该目录不可上传文件 /data/ftp/pub 文件只能上传到该目录下   mkdir -p /data/ftp/public  创建登录欢迎文件\necho \u0026#34;Welcome to use FTP service.\u0026#34; \u0026gt; /data/ftp/welcome.txt  设置访问权限：\nchmod a-w /data/ftp \u0026amp;\u0026amp; chmod 777 -R /data/ftp/public  设置为用户的主目录：\nusermod -d /data/ftp ftpuser  "},{"id":44,"href":"/docs/Linux/CentOS/CentOS-7%E6%90%AD%E5%BB%BAGit%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"CentOS 7搭建Git服务器","section":"CentOS","content":"Git 是一款免费、开源的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。此实验以 CentOS 7 x64 的系统为环境，搭建 git 服务器。\n 下载安装 Git\r#\r\r 安装依赖库和编译工具\n为了后续安装能正常进行，我们先来安装一些相关依赖库和编译工具\nyum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel  安装编译工具\nyum install gcc perl-ExtUtils-MakeMaker  下载 Git\n选一个目录，用来放下载下来的安装包，这里将安装包放在 /usr/local/src 目录里\ncd /usr/local/src 到官网找一个新版稳定的源码包下载到 /usr/local/src 文件夹里\nwget https://www.kernel.org/pub/software/scm/git/git-2.10.0.tar.gz  解压和编译\n解压下载的源码包\ntar -zvxf git-2.10.0.tar.gz 解压后进入 git-2.10.0 文件夹\ncd git-2.10.0  执行编译\nmake all prefix=/usr/local/git  编译完成后, 安装到 /usr/local/git 目录下\nmake install prefix=/usr/local/git  配置环境变量\r#\r\r 将 git 目录加入PATH\n将原来的 PATH 指向目录修改为现在的目录\necho \u0026#39;export PATH=$PATH:/usr/local/git/bin\u0026#39; \u0026gt;\u0026gt; /etc/bashrc  重新加载环境变量\nsource /etc/bashrc 此时我们能查看 git 版本号，说明我们已经安装成功了。\ngit --version  创建 Git 账号密码\r#\r\r 创建 git 账号\n为我们刚刚搭建好的 git 创建一个账号\nuseradd -m gituser  设置账号密码\npasswd gituser  初始化 Git 仓库并配置用户权限\r#\r\r 创建 git 仓库并初始化\n我们创建 /data/repositories 目录用于存放 git 仓库\nmkdir -p /data/repositories 创建好后，初始化这个仓库\ncd /data/repositories/ \u0026amp;\u0026amp; git init --bare test.git  配置用户权限\n给git仓库目录设置用户和用户组并设置权限\nchown -R gituser:gituser /data/repositories chmod 755 /data/repositories 查找 git-shell 所在目录,编辑 /etc/passwd 文件，将最后一行关于gituser的登录shell配置改为git-shell的目录如下\ngituser:x:500:500::/home/gituser:/usr/local/git/bin/git-shell  使用搭建好的 Git 服务\n克隆 test repo 到本地\ncd ~ \u0026amp;\u0026amp; git clone gituser@123.207.27.137:/data/repositories/test.git  "},{"id":45,"href":"/docs/Linux/CentOS/CentOS-7%E6%90%AD%E5%BB%BASamba%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"CentOS 7搭建Samba服务器","section":"CentOS","content":"安装Samba服务\r#\r\r yum install -y samba samba-common  创建共享文件夹路径\r#\r\r mkdir /root/ShareFiles chmod 777 /root/ShareFiles  修改Samba配置文件\r#\r\r vi /etc/samba/smb.conf  在Samba配置文件的最后加入\r#\r\r [ShareFile] path = /root/ShareFiles available = yes browseable = yes # public = yes # 不需要密码 writable = yes  创建Samba账户(必须是系统中存在的用户)\r#\r\r touch /etc/samba/smbpasswd smbpasswd -a 用户名  重启Samba\r#\r\r /etc/init.d/smbd restart  "},{"id":46,"href":"/docs/Linux/CentOS/CentOS-7%E6%90%AD%E5%BB%BA%E7%A6%BB%E7%BA%BFYum%E6%BA%90/","title":"CentOS 7搭建离线YUM源服务器","section":"CentOS","content":"制作环境\r#\r\r Yum源仓库服务器\nIP地址：10.10.10.10\n系统版本：CentOS 7.9 2009\n Yum源客户端\nIP地址：10.10.10.20\n系统版本：CentOS 7.9 2009\n  可以使用多种方式搭建内部Yum源仓库，例如：file、ftp、http、https，本环境以http的方式进行内部yum源仓库的搭建。\n  更新系统\r#\r\r yum update -y  安装相关依赖和软件\r#\r\r yum install -y make gcc zlib-devel openssl openssl-devel httpd yum-utils createrepo  yum-utils：reposync同步工具\ncreaterepo：编辑Yum库工具\nhttpd：通过Apache软件提供Web服务，也可以使用Nginx\n  修改Yum源的配置文件\r#\r\r 使用阿里云Yum源\r#\r\r 更换CentOS-Base.repo配置文件的内容\ncurl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo 更换epel.repo配置文件的内容\ncurl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo  使用清华大学Yum源（推荐）\r#\r\r 更换CentOS-Base.repo配置文件的内容\nsudo sed -e \u0026#39;s|^mirrorlist=|#mirrorlist=|g\u0026#39; \\  -e \u0026#39;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g\u0026#39; \\  -i.bak \\  /etc/yum.repos.d/CentOS-*.repo  注意，如果需要启用其中一些 repo，需要将/etc/yum.repos.d/CentOS-Base.repo中的 enabled=0 改为 enabled=1。\n  更换epel.repo配置文件的内容\nyum install epel-release sed -e \u0026#39;s!^metalink=!#metalink=!g\u0026#39; \\  -e \u0026#39;s!^#baseurl=!baseurl=!g\u0026#39; \\  -e \u0026#39;s!//download\\.fedoraproject\\.org/pub!//mirrors.tuna.tsinghua.edu.cn!g\u0026#39; \\  -e \u0026#39;s!//download\\.example/pub!//mirrors.tuna.tsinghua.edu.cn!g\u0026#39; \\  -e \u0026#39;s!http://mirrors!https://mirrors!g\u0026#39; \\  -i /etc/yum.repos.d/epel*.repo  清空本地源缓存\nyum clean all  生成本地源缓存\nyum makecache  显示当前有效的Yum源\nyum repolist  同步Yum源中的软件包到本地\r#\r\r 在本地创建镜像目录\nmkdir -p /home/mirror  更改目录的属主属组\nchown -R apache:apache /home/mirror  更改目录权限\nchmod -R 755 /home/mirror  将Yum源中的软件同步到/home/mirror/目录中\nreposync -n --repoid=extras --repoid=updates --repoid=base --repoid=epel -p /home/mirror  -n：下载最新软件包\n-p：指定目录，指定本地的源\n--repoid：如果不指定就同步本地服务器所有的源\n下载过程比较久，请耐心等待\n  查看同步结果\ndu -sh /home/mirror/*  创建仓库索引\r#\r\r createrepo -po /home/mirror/base/ /home/mirror/base/ createrepo -po /home/mirror/extras/ /home/mirror/extras/ createrepo -po /home/mirror/updates/ /home/mirror/updates/ createrepo -po /home/mirror/epel/ /home/mirror/epel/  问题：如果创建仓库索引提示如下错误\nWorker 0: Error: Could not open local rpm file: /mirror/epel//Packages/p/python2-pycryptodomex-3.9.7-1.el7.x86_64.rpm: RPM Error opening Package 解决办法：提示哪个软件包打开错误就删除哪个软件包\nrm -rf /mirror/epel/Packages/p/python2-pycryptodomex-3.9.7-1.el7.x86_64.rpm   更新数据源\r#\r\r createrepo --update /home/mirror/base/ createrepo --update /home/mirror/extras/ createrepo --update /home/mirror/updates/ createrepo --update /home/mirror/epel/  启动并配置Apache服务\r#\r\r 启动Apache\nsystemctl start httpd  将Apache设置为开机自动启动\nsystemctl enable httpd  检查Apache的启动状态\nsystemctl status httpd  编辑Apache的配置文件/etc/httpd/conf/httpd.conf，找到并修改一下内容：\n...... DocumentRoot \u0026#34;/home/mirror/\u0026#34; ...... \u0026lt;Directory \u0026#34;/home/mirror/\u0026#34;\u0026gt; homeions Indexes FollowSymLinks AllowOverride None Order allow,deny Allow from all Require all granted \u0026lt;/Directory\u0026gt;  修改Apache默认首页的内容（复制后直接在终端中粘贴执行）\ncat \u0026gt; /usr/share/httpd/noindex/index.html \u0026lt;\u0026lt;EOF \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;CentOS 7 镜像\u0026lt;/title\u0026gt; \u0026lt;script\u0026gt;document.createElement(\u0026#34;myHero\u0026#34;)\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; myHero { display: block; background-color: #ddd; padding: 10px; font-size: 20px; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;简介\u0026lt;/h1\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;CentOS 是基于 RedHat Linux 提供的可自由使用源代码的企业级 Linux 发行版本，是一个稳定，可预测，可管理和可复制的免费企业级计算平台。\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;br\u0026gt; \u0026lt;h1\u0026gt;CentOS 7 配置内部YUM源\u0026lt;/h1\u0026gt; \u0026lt;br\u0026gt; \u0026lt;h2\u0026gt;1.备份配置文件\u0026lt;/h2\u0026gt; \u0026lt;myHero\u0026gt;mv /etc/yum.repos.d/* /opt/yum/\u0026lt;/myHero\u0026gt; \u0026lt;br\u0026gt; \u0026lt;h2\u0026gt;2.下载新的 CentOS-Base.repo 到 /etc/yum.repos.d/ \u0026lt;/h2\u0026gt; \u0026lt;myHero\u0026gt;curl -o /etc/yum.repos.d/CentOS-Base.repo http://10.10.10.10/repo/CentOS-Base.repo\u0026lt;/myHero\u0026gt; \u0026lt;br\u0026gt; \u0026lt;h2\u0026gt;3.生成本地缓存\u0026lt;/h2\u0026gt; \u0026lt;myHero\u0026gt;yum makecache\u0026lt;/myHero\u0026gt; \u0026lt;br\u0026gt; \u0026lt;h2\u0026gt;4.运行 yum repolist 查看已经生成缓存\u0026lt;/h2\u0026gt; \u0026lt;myHero\u0026gt;yum repolist\u0026lt;/myHero\u0026gt; \u0026lt;br\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; EOF  编辑客户端Yum源的配置文件\r#\r\r 在Yum源服务器端（10.10.10.10）创建repo文件夹\nmkdir -p /home/mirror/repo/  在Yum源服务器端（10.10.10.10）上编写客户端Yum源的配置文件（复制后直接在终端粘贴执行）\ncat \u0026gt; /home/mirror/repo/CentOS-Base.repo \u0026lt;\u0026lt;EOF [base] name=CentOS-$releasever - Base - 10.10.10.10 failovermethod=priority baseurl=http://10.10.10.10/base/ enable=1 gpgcheck=0 # released updates [updates] name=CentOS-$releasever - Updates - 10.10.10.10 failovermethod=priority baseurl=http://10.10.10.10/updates/ enable=1 gpgcheck=0 # additional packages that may be useful [extras] name=CentOS-$releasever - Extras - 10.10.10.10 failovermethod=priority baseurl=http://10.10.10.10/extras/ enable=1 gpgcheck=0 # additional packages that may be useful [epel] name=CentOS-$releasever - Epel - 10.10.10.10 failovermethod=priority baseurl=http://10.10.10.10/epel/ enable=1 gpgcheck=0 EOF  客户端配置Yum源\r#\r\r 在客户端（10.10.10.20）上配置Yum源\ncurl -o /etc/yum.repos.d/CentOS-Base.repo http://10.10.10.10/repo/CentOS-Base.repo  "},{"id":47,"href":"/docs/Linux/CentOS/CentOS-7%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0%E5%85%89%E7%9B%98%E6%BA%90/","title":"CentOS 7配置本地光盘源","section":"CentOS","content":"检查需要挂载的cdrom设备是否存在\nls /dev/ 创建挂载点文件夹\nmkdir /mnt/cdrom 挂载设备\nmount /dev/cdrom /mnt/cdrom 检查设备是否挂载成功\ndf -h 备份/etc/yum.repo.d/文件夹下的所有的文件，并将所有原文件删除\nrename .repo .repo.bak * 创建cdrom.repo文件，并添加以下内容\n[mycdrom] name=cdrom baseurl=file:///mnt/cdrom enbale=1 gpgcheck=0  gpgcheck的值为0不检查签名，为1则检查签名。\n 清理缓存\nyum clean all 重新建立缓存\nyum makecache "},{"id":48,"href":"/docs/Linux/CentOS/CentOS-7%E9%9D%99%E9%BB%98%E5%AE%89%E8%A3%85Oracle-19c/","title":"CentOS 7静默安装Oracle 19c","section":"CentOS","content":"基础配置\r#\r\r 修改主机名\nhostnamectl set-hostname Oracle  配置hosts文件\nvim /etc/hosts 10.10.10.201 oracle  关闭selinux\nvim /etc/selinux/config SELINUX=disable  关闭防火墙\nsystemctl stop firewalld.service systemctl stop firewalld.service  安装依赖\nyum -y install compat-libcap1 compat-libstbc++-33 gcc gcc-c++ glibc-devel ksh libaio-devel sysstat elfutils-libelf-devel fontconfig-devel libxcb smartmontools libX11 libXau libXtst libXrender libXrender-devel  通过脚本创建Oracle用户组\nvim CreatUserGroup.sh #!/bin/bash groupadd oinstall groupadd dba groupadd asmdba groupadd backupdba groupadd dgdba groupadd kmdba groupadd racdba groupadd oper useradd -g oinstall -G dba,asmdba,backupdba,dgdba,kmdba,racdba,oper -m oracle  系统优化\r#\r\r 修改内核参数\nvim /etc/sysctl.conf fs.aio-max-nr = 1048576 fs.file-max = 6815744 kernel.shmall = 16451328 kernel.shmmax = 33692319744 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576 使内核参数生效\nsysctl -p  安装前准备\r#\r\r 创建安装目录\nmkdir -p /home/oracle/app/19c 更改安装目录的属主属组\nchown -R oracle:oinstall /home/oracle 更改安装目录权限\nchmod -R 755 /home/oracle  修改用户的Shell限制\nvim /etc/security/limits.conf @oinstall soft nofile 2048 @oinstall hard nofile 65536 @oinstall soft nproc 16384 @oinstall soft stack 10240  修改oracle用户的环境变量\n# 切换至 oracle 用户 su - oracle vim .bash_profile export ORACLE_BASE=/home/oracle/app export ORACLE_HOME=/home/oracle/app/19c/ export PATH=$PATH:$ORACLE_HOME/bin:/usr/local/bin export ORACLE_HOSTNAME=oracle export ORACLE_SID=orcl export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$ORACLE_HOME/rdnms/lib:$ORACLE_HOME/network/lib:/lib:/usr/lib export CLASSPATH=$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib:$ORACLE_HOME/network/jlib 使环境变量生效\nsource .bash_profile  修改安装引导文件\ncd $ORACLE_HOME/install/responsecp cp db_install.rsp db_install.rsp.bak vim db_install.rsp # 修改如下参数 oracle.install.option=INSTALL_DB_SWONLY # 第29行 UNIX_GROUP_NAME=oinstall # 第34行 INVENTORY_LOCATION=/home/oracle/app/19c/oraInventory # 第41行 ORACLE_HOME=/home/oracle/app/19c # 第45行 ORACLE_BASE=/home/oracle # 第50行 oracle.install.db.InstallEdition=EE # 第62行 oracle.install.db.OSDBA_GROUP=dba # 第97行 oracle.install.db.OSOPER_GROUP=oper # 第85行 oracle.install.db.OSBACKUPDBA_GROUP=backupdba # 第90行 oracle.install.db.OSDGDBA_GROUP=dgdba # 第95行 oracle.install.db.OSKMDBA_GROUP=kmdba # 第100行 oracle.install.db.OSRACDBA_GROUP=racdba # 第105行 oracle.install.db.rootconfig.executeRootScript=false # 第120行  安装软件\r#\r\r 执行安装\ncd $ORACLE_HOME ./runInstaller -silent -responseFile /home/oracle/app/19c/install/response/db_install.rsp  以root用户执行脚本\nsh /home/oracle/app/19/coraInventory/orainstRoot.sh sh /home/oracle/app/19c/root.sh  以下是静默安装的文件路径\n软件：/home/oracle/app/19c/install/response/db_install.rsp\n监听：/home/oracle/app/19c/assistants/netca/netca.sbs\n建库：/home/oracle/app/19c/assistants/dbca/dbca.rsp\n  创建监听\nsu - oracle cd assistants/netca/ cp netca.rsp netca.rsp.bak netca /silent /responseFile /home/oracle/app/19c/assistants/netca/netca.rsp  建库\ncd $ORACLE_HOME/assistants/dbca cp dbca.rsp dbca.rsp.bak vim dbca.rsp 主要修改以下参数\ngdbName=orcl # 第32行 sid=orcl # 第42行 databaseConfigType=SI # 第52行 templateName=General_Purpose.dbc # 第223行 sysPassword=CNCS@cncs.C0M # 第233行 systemPassword=CNCS@cncs.C0M # 第243行 emConfiguration=NONE # 第262行 dbsnmpPassword=CNCS@cncs.C0M # 第295行 datafileDestination=/home/oracle/app/oradata # 第411行 recoveryAreaDestination=/home/oracle/flash_recovery_area # 第421行 storageType=FS # 第431行 characterSet=ZHS16GBK # 第468行 nationalCharacterSet=AL16UTF16 # 第478行 sampleSchema=true # 第565行 totalMemory=2048 # 第604行 # 如果要创建容器数据库，则需要配置以下参数，多个pdb以pdbname为前缀 createAsContainerDatabase=true # 第162行 numberOfPDBs=1 # 第172行 pdbName=cncs # 第182行 pdbAdminPassword=CNCS@cncs.C0M # 第203行 dbca -silent -createDatabase -responseFile /home/oracle/app/19c/assistants/dbca/dbca.rsp  验证安装及管理服务\r#\r\r 服务验证\nlsnrctl status # 查看监听状态 lsnrctl restart # 重启监听 lsnrctl stop # 停止监听 lsnrctl start # 启动监听  SQLPLUS验证\nsqlplus  启动服务（先启动监听，再启动数据库）\n$\u0026gt; lsnrctl start # 启动监听 $\u0026gt; sqlplus /nolog # 打开sqlplus SQL\u0026gt; conn / as sysdba # 打开sqlplus SQL\u0026gt; startup # 启动数据库 SQL\u0026gt; shutdown # 关闭数据库 SQL\u0026gt; exit # 退出 $\u0026gt; lsnrctl stop # 停止监听 "},{"id":49,"href":"/docs/Linux/Debian/Debian%E6%90%AD%E5%BB%BAAPT%E6%9C%8D%E5%8A%A1%E5%99%A8/","title":"Debian搭建APT服务器","section":"Debian","content":"更新软件列表\r#\r\r sudo apt update  安装apt-mirror\r#\r\r sudo apt install apt-mirror  配置mirror.list文件\r#\r\r mirror.list是apt-mirror的配置文件，通过它可以对apt-mirror的下载进行配置，路径是/etc/apt/mirror.list\n############# config ################## # # set base_path /var/spool/apt-mirror # # set mirror_path $base_path/mirror # set skel_path $base_path/skel # set var_path $base_path/var # set cleanscript $var_path/clean.sh # set defaultarch \u0026lt;running host architecture\u0026gt; # set postmirror_script $var_path/postmirror.sh # set run_postmirror 0 set nthreads 20 set _tilde 0 # ############# end config ############## deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-updates main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-updates main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-backports main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ bullseye-backports main contrib non-free deb https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free # deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security bullseye-security main contrib non-free # mirror additional architectures # deb-alpha http://ftp.us.debian.org/debian unstable main contrib non-free # deb-amd64 http://ftp.us.debian.org/debian unstable main contrib non-free # deb-armel http://ftp.us.debian.org/debian unstable main contrib non-free # deb-hppa http://ftp.us.debian.org/debian unstable main contrib non-free # deb-i386 http://ftp.us.debian.org/debian unstable main contrib non-free # deb-ia64 http://ftp.us.debian.org/debian unstable main contrib non-free # deb-m68k http://ftp.us.debian.org/debian unstable main contrib non-free # deb-mips http://ftp.us.debian.org/debian unstable main contrib non-free # deb-mipsel http://ftp.us.debian.org/debian unstable main contrib non-free # deb-powerpc http://ftp.us.debian.org/debian unstable main contrib non-free # deb-s390 http://ftp.us.debian.org/debian unstable main contrib non-free # deb-sparc http://ftp.us.debian.org/debian unstable main contrib non-free # clean http://ftp.us.debian.org/debian  说明：\nset base_path：镜像的路径，也就是源储存的位置，需要自己设置，一般来说需要确保相应的磁盘具有足够的空间来储存（大约130GB左右）\nset nthreads：线程数，一般20~30个就足够了，线程越多下载越快（取决于带宽限制）\ndeb-amd64 http://archive.debian.org/debian wheezy main contrib non-free：deb-amd64指定镜像amd64架构的软件包，可以换成其他需要的架构比如deb-i386，deb-armel等，只写deb默认镜像当前操作系统架构的软件包，deb-src表示镜像软件源代码，http://archive.debian.org/debian是镜像源地址，bullseye是指定镜像操作系统（用代号表示）的软件包，main，contrib，non-free为镜像的软件版本。\n  开始镜像\r#\r\r sudo apt-mirror  镜像过程时间较长，请耐心等待\n  安装Nginx服务\r#\r\r 安装服务\napt install -y nginx 启动服务\nsystemctl start nginx 设置开机启动\nsystemctl enable nginx  配置Nginx\r#\r\r 创建文建/etc/nginx/conf.d/mirrors.conf\nserver{ listen\t8080; server_name\tapt-mirror; charset\tutf-8; root\t/var/spool/apt-mirror/mirror/mirrors.tuna.tsinghua.edu.cn/; location / { autoindex on; autoindex_exact_size on; autoindex_localtime on; } }  重启Nginx\r#\r\r nginx -s reload  使用本地Mirrors\r#\r\r 在其他主机上，修改/etc/apt/sources.list文件就可以使用本地Mirrors了，最后一行加入以下内容，其中192.168.1.100是本地Mirrors服务器地址\ndeb http://192.168.1.100:8080/debian bullseye main contrib non-free apt update -y "},{"id":50,"href":"/docs/Linux/Debian/Debian%E7%B3%BB%E7%BB%9F%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/","title":"Debian系统常用配置","section":"Debian","content":"Debian系统常用配置\r#\r\r apt命令\r#\r\r    命令 取代的命令 命令的功能     apt install apt-get install 安装软件包   apt remove apt-get remove 移除软件包   apt purge apt-get purge 移除软件包及配置文件   apt update apt-get update 刷新存储库索引   apt upgrade apt-get upgrade 升级所有可升级的软件包   apt autoremove apt-get autoremove 自动删除不需要的包   apt full-upgrade apt-get dist-upgrade 在升级软件包时自动处理依赖关系   apt search apt-cache search 搜索应用程序   apt show apt-cache show 显示装细节   apt list / 列出包含条件的包（已安装，可升级等）   apt edit-sources / 编辑源列表     解决控制台显示乱码问题\r#\r\r apt install locales dpkg-reconfigure locales  重新登录或重启系统后生效\n  更换国内源\r#\r\r 备份源配置文件\ncp /etc/apt/sources.list /etc/apt/sources.list.bak 修改源配置文件\nvi /etc/apt/sources.list # 注释掉deb cdrom 使配置生效\nsudo apt -y update  卸载vim-tiny\r#\r\r sudo apt remove -y vim-tiny  安装常用软件\r#\r\rsudo apt install -y vim net-tools bash-completion lrzsz htop wget  固定IP地址\r#\r\r 备份网卡配置文件\ncp /etc/network/interfaces /etc/network/interfaces.bak 编辑网卡配置文件\nvim /etc/network/interfaces auto ens33 # 在系统启动的时候启动网络接口，无论网络接口有无连接(插入网线)，同时使ifup -a对其生效 # allow-hotplug ens33 # 只有当内核从该接口检测到热插拔事件后才启动该接口。 iface ens33 inet static # static表示使用固定ip，dhcp表示使用动态ip address 192.168.0.100 # 设置ip地址为：192.168.0.100 network 192.168.0.0 netmask 255.255.255.0 # 设置子网掩码为：255.255.255.0 broadcast 192.168.0.255 gateway 192.168.0.1 # 设置网关为：192.168.0.1 备份DNS配置文件\ncp /etc/resolv.conf /etc/resolv.conf.bak 编辑DNS配置文件\nvim /etc/resolv.conf search debian.local nameserver 8.8.8.8 # 设置首选dns（一般在安装Debian的时候，系统已经自动设置好了，这一步可以不修改） nameserver 8.8.4.4 # 设置备用dns 停用网卡\nifdown -a # -a表示全部网卡 启用网卡\nifup -a # -a表示全部网卡  配置SSH服务\r#\r\r 备份SSH服务配置文件\ncp /etc/ssh/sshd_config /etc/ssh/sshd_config.bak 编辑SSH服务配置文件\nvim /etc/ssh/sshd_config  添加用户\r#\r\r 使用adduser添加用户，在创建时会提示输入密码，并在/home下创建用户目录\nadduser postgres # 添加postgres用户 使用useradd添加用户，没有密码，创建的用户是不能登录的，需要使用passwd设置密码，同时，不会在/home下创建用户目录。\nuseradd postgres passwd ******  useradd is a low level utility for adding users. On Debian, administrators should usually use adduser(8) instead.\n  删除用户\r#\r\r使用deluser删除用户，会退出并删除所在的组，使用--remove-all-files可以删除用户拥有的所有文件\ndeluser --remove-all-files postgres 使用userdel删除用户，会退出并删除所在的组\nuserdel postgres  userdel is a low level utility for removing users. On Debian, administrators should usually use deluser(8) instead\n  "},{"id":51,"href":"/docs/Docker/Docker%E5%8D%83%E9%94%8B%E6%95%99%E8%82%B2/","title":"Docker基础","section":"Docker","content":"Docker\r#\r\r  使用Docker容器化封装应用程序的意义：\n Docker引擎统一了基础设施环境（Docker环境）  硬件配置 操作系统版本 运行环境的异构   Docker引擎统一了程序打包方式（Docker镜像） Docker引擎统一了程序部署和运行的方式 （Docker容器）    Docker Install（安装）\r#\r\r  安装Docker的依赖环境\n# yum-util 提供 yum-config-manager 功能 # device-mapper-persistent-data、lvm2是devicemapper驱动所依赖 sudo yum install -y yum-utils device-mapper-persistent-data lvm2    配置下载Docker的镜像源\nsudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo    安装Docker-CE\n# Docker-CE是Docker的社区版，默认安装最新版本的Docker sudo yum makecache fast # 将服务器上的软件包信息在本地缓存一份，用来提高搜索安装软件的速度 sudo yum install -y docker-ce docker-ce-cli containerd.io  注意： 官方软件源默认启用了最新的软件，您可以通过编辑软件源的方式获取各个版本的软件包。例如官方并没有将测试版本的软件源置为可用，您可以通过以下方式开启。同理可以开启各种测试版本等。\nvim /etc/yum.repos.d/docker-ee.repo 将 [docker-ce-test] 下方的enabled=0修改为enabled=1\n    安装指定版本的Docker\n# 查找Docker-CE的版本 yum list docker-ce --showduplicates | sort -r # 安装指定版本的Docker-CE: (VERSION例如上面的17.03.0.ce.1-1.el7.centos) sudo yum install docker-ce-\u0026lt;VERSION_STRING\u0026gt; docker-ce-cli-\u0026lt;VERSION_STRING\u0026gt; containerd.io    启动Docker服务并设置为开机自动启动\n# 启动Docker服务 systemctl start docker # 设置Docker开机自动启动 systemctl enable docker    安装校验\ndocker info docker version    相关链接\n   下载地址：https://mirrors.aliyun.com/docker-ce/ 官方主页：https://www.docker.com/community-edition\n  Dcoker Install（脚本安装）\r#\r\rcurl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun  Docker Registry（仓库）\r#\r\r Docker Registry（仓库）主要有三种：\n Docker的官方的中央仓库：https://hub.docker.com/ 国内的开放的中央仓库：网易蜂巢、daoCloud等。 企业内部自建的中央仓库（私有仓库）：速度最快。    Docker Image（镜像）\r#\r\r  查看本地全部的镜像\ndocker images    拉取镜像到本地\ndocker pull \u0026lt;镜像名称\u0026gt; # 例：从hub.daocloud.io上拉取一个Nginx的镜像 docker pull daocloud.io/library/nginx:latest    上传镜像到中央仓库\ndocker push \u0026lt;镜像名称\u0026gt;    查看镜像信息\ndocker inspect \u0026lt;镜像ID\u0026gt;    删除本地镜像\ndocker rmi \u0026lt;镜像ID\u0026gt;    镜像的导入导出（这种操作不规范，但可以用在网络环境较差的情境中）\n# 导出本地镜像 docker save -o \u0026lt;导出路径\u0026gt; \u0026lt;镜像ID\u0026gt; # 导入镜像到本地 docker load -i \u0026lt;镜像路径及名称\u0026gt; # 导入的镜像会丢失镜像名称和版本信息，需要手动修改名称 docker tag \u0026lt;镜像ID\u0026gt; \u0026lt;镜像名称\u0026gt;:\u0026lt;版本号\u0026gt;    Docker Container（容器）\r#\r\r  运行容器\ndocker run -d -p \u0026lt;映射的宿主机端口\u0026gt;:\u0026lt;容器端口\u0026gt; --name \u0026lt;容器名称\u0026gt; \u0026lt;镜像名称|镜像ID\u0026gt;:\u0026lt;版本号\u0026gt; # -d：后台（守护）运行容器 # -p：映射宿主机的端口和容器端口 # -name：指定容器的名称 # 示例 docker run -d -p 80:80 --name Nginx daocloud.io/library/nginx    停止容器\n# 停止指定的容器（等待进程结束后停止） docker stop \u0026lt;容器ID\u0026gt; # 停止全部容器（等待进程结束后停止） docker stop $(docker ps -qa) # 停止容器（直接杀掉进程停止） docker kill \u0026lt;容器ID\u0026gt;    再次启动容器\ndocker start \u0026lt;容器ID\u0026gt;    查看正在运行的容器\ndocker ps [-qa] # -q：只显示容器的标识 # -a：查看所有的容器，包括没有运行的容器    查看容器的信息\ndocker inspect \u0026lt;容器ID\u0026gt;    查看容器的日志\ndocker logs -f -t --tail \u0026lt;容器ID\u0026gt; # -f：可以滚动查看日志 # -t：日志上加上时间戳 # --tail：返回最后的多少行    进入容器\ndocker exec -it \u0026lt;容器ID\u0026gt; bash    将宿主机的文件复制到容器中\n# 虽然可以将宿主机的文件拷贝到容器中，但不推荐进入到容器内部去维护内容，一般会使用 “数据卷” 将宿主机的一个目录映射到容器的目录中 docker cp \u0026lt;文件路径/文件名称\u0026gt; \u0026lt;容器ID\u0026gt;:\u0026lt;容器内部路径\u0026gt;    删除容器（删除容器前需要先停止容器）\n# 删除指定容器 docker rm \u0026lt;容器ID\u0026gt; # 删除全部容器 docker rm $(docker ps -qa)    Docker Volume（数据卷）\r#\r\r将宿主机的一个目录映射到容器的一个目录中，使得在宿主机中操作目录中的内容时，容器内部所映射的目录中的内容也随之进行操作和改变。\n  创建数据卷\ndocker volume create \u0026lt;数据卷名称\u0026gt; # 在创建数据卷时，默认会将数据卷的内容存储在 /var/lib/docker/volumes/\u0026lt;数据卷名称\u0026gt;/_data # 注意，创建数据卷后，只是在宿主机上创建了一个数据卷的目录，此时并没有创建与容器内部目录的映射关系    查看数据卷的详细信息\n# 查看指定数据卷的详细信息 docker volume inspect \u0026lt;数据卷名称\u0026gt; # 查看全部数据卷的信息 docker volume ls    删除数据卷\ndocker volume rm \u0026lt;数据卷名称\u0026gt;    应用数据卷\n# 方式一：使用默认路径的数据卷做映射 # 当映射数据卷时，如果数据卷不存在，Docker会自动创建 docker run -v \u0026lt;数据卷路径/数据卷名称\u0026gt;:\u0026lt;容器内部的路径\u0026gt; \u0026lt;镜像ID\u0026gt; # 例： # 创建Tomcat_Volmue数据卷，将数据卷Tomcat_Volmue映射到Tomcat的Docker docker volume create Tomcat_Volmue docker run -d -p 8080:8080 --name Tomcat -v Tomcat_Volmue:/user/local/tomcat/webapps \u0026lt;镜像ID\u0026gt; # 注意：这种方式会将容器内部映射目录中的文件全部带到数据卷中  # 方式二：使用指定位置的数据卷做映射（推荐） # 可以通过以下方式在指定路径创建数据卷并映射数据卷 docker run -v \u0026lt;数据卷路径/数据卷名称\u0026gt;:\u0026lt;容器内部的路径\u0026gt; \u0026lt;镜像ID\u0026gt; # 例： # 在指定路径/opt/上创建Tomcat_Volmue数据卷同时将数据卷Tomcat_Volmue映射到Tomcat的Docker docker run -d -p 8080:8080 --name Tomcat -v /opt/Tomcat_Volmue:/user/local/tomcat/webapps \u0026lt;镜像ID\u0026gt; # 注意：使用这种方式不会将容器内部映射目录中的文件全部带到数据卷中，数据卷中将是空的    Docker Use（应用）\r#\r\r  通过Docker搭建Nginx服务\n# 运行Nginx容器 # 运行容器时，如果Docker发现运行的容器不存在，会自动从指定的中央仓库拉去镜像并运行容器 docker run -d -p 80:80 --name Nginx daocloud.io/library/nginx:latest    通过Docker搭建MySQL服务\n# 运行MySQL容器 # 运行容器时，如果Docker发现运行的容器不存在，会自动从指定的中央仓库拉去镜像并运行容器 docker run -d -p 3306:3306 --name MySQL -e MYSQL_ROOT_PASSWORD=123456 daocloud.io/library/mysql:latest # -e：指定一个一个环境名等于一个值    通过Docker搭建Tomcat服务\n# 运行Tomcat容器 # 运行容器时，如果Docker发现运行的容器不存在，会自动从指定的中央仓库拉去镜像并运行容器 docker run -d -p 8080:8080 --name Tomcat daocloud.io/library/tomcat:8.5.15-jre8 # 将宿主机上的项目复制到Docker的Tomcat中，但一般不这么用，通常会使用 “数据卷” 的方式 docker cp \u0026lt;项目文件\u0026gt; \u0026lt;容器ID\u0026gt;:/usr/local/tomcat/webapps/    Docker Custom Image（自定义镜像）\r#\r\r目标：根据业务需要，定制一个带有业务的镜像（不推荐使用这种方法创建自定义镜像）\n  获取一个基础系统镜像\ndocker pull centos    以交互式终端形式启动容器\ndocker run -i -t --name CentOS8 centos /bin/bash    在容器中部署我们所需要的服务以及业务\n# 在容器中安装ssh服务 yum install openssh-server -y # 启动ssh服务 systemctl start sshd # 设置开机启动 systemctl enable sshd # 退出容器 exit    提交更改的容器\ndocker commit -m=\u0026#34;install openssh-server\u0026#34; -a=\u0026#34;HC\u0026#34; \u0026lt;容器ID\u0026gt; \u0026lt;镜像名称\u0026gt;:\u0026lt;版本号\u0026gt; /usr/sbin/sshd -D # -m: 提交的描述信息 # -a: 指定镜像作者    Dockerfile（自定义镜像）\r#\r\rDocker通过从一个Dockerfile文件中读取指令来自动构建映像，该文本文件按顺序构建给定映像所需的所有命令。（Dockerfile是官方推荐自定义镜像的方法）\n  创建Dockerfile文件\nFROM ubuntu:20.04 COPY test.txt /app ADD test.tar.gz /home/test RUN sudo apt-get update -y \u0026amp;\u0026amp; apt-get upgrdae -y \u0026amp;\u0026amp; apt-get install openssh-server -y \u0026amp;\u0026amp; systemctl start sshd \u0026amp;\u0026amp; systemctl enable start EXPOSE 22 CMD [\u0026#39;/usr/sbin/sshd\u0026#39;,\u0026#39;-D\u0026#39;] # Docker映像由只读层组成，每个只读层代表一个Dockerfile指令。各个层堆叠在一起，每个层都是上一层的变化的增量。 # FROM：从ubuntu:20.04的Docker镜像创建一个图层 # COPY：只复制文件或者目录到容器（所拷贝的文件必须跟Dockerfile在同一目录） # ADD：除了COPY的功能外，如果复制的问价是tar相关的压缩文件，ADD命令会自动将其解压缩，同时支持URL # RUN：执行命令并创建新的镜像层，通常用于安装软件包，一个Dockerfile中可以有多个RUN命令 # EXPOSE：需要开放暴露的端口，可以写多个 # CMD：当Docker镜像被启动后Docker容器将会默认执行的命令，一个Dockerfile中只能有一个CMD命令    构建镜像\ndocker build -t \u0026lt;镜像名称|镜像ID\u0026gt;:\u0026lt;版本号\u0026gt; [-f dockerfiles/Dockerfile context] . # -F：指向Dockerfile并指定构建上下文的目录    Docker Compose\r#\r\r 官网网站：https://docs.docker.com/compose/\nGithub：https://github.com/docker/compose/releases\n Compose是用于定义和运行多容器Docker应用程序的工具。通过Compose，您可以使用YAML文件来配置应用程序的服务。然后，使用一个命令，就可以从配置中创建并启动所有服务。简单来说，Docker-Compose就是只需要一个docker-compose.yml文件和一条命令，就可以批量的管理容器的工具。\n  下载Docker-Compose\nsudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /opt/docker-compose    添加docker-compose的可执行权限\nchmod +x docker-compose    将docker-compose添加到环境变量中\n# 编辑环境变量文件 vim /etc/profile # 将docker-compose所在的/opt/路径添加到/etc/profile的最后一行 export PATH=/opt:$PATH # 重新加载环境变量  source /etc/profile    测试\n# 在任意目录下输入docker-compose查看命令是否生效 docker-compose    配置docker-compose的yml文件\n通过docker-compose的yml文件管理Nginx、MySQL和Tomcat的容器\n docker-compose的yml文件以key: value（注意：value前面有空格）的方式来指定配置信息 docker-compose的yml文件的多个配置信息以换行+两个空格的缩进的方式进行区分 docker-compose的yml文件中不要使用制表符  # docker-compose.yml文件内容 version: \u0026#39;3.3\u0026#39; services: Nginx: # 服务的名称 restart: always  # 只要docker启动，那么这个服务就跟着启动 image: daocloud.io/library/nginx:latest  # 指定镜像的路径 container_name: Nginx  # 容器名称 ports: # 配置端口 - 80:80 # 指定端口号80的映射 environment: # 配置环境 TimeZone: Asia/Shanghai  # 指定时区 MySQL: # 服务的名称 restart: always  # 只要docker启动，那么这个服务就跟着启动 image: daocloud.io/library/mysql:latest  # 指定镜像的路径 container_name: MySQL  # 容器名称 ports: # 配置端口 - 3306:3306 # 指定端口号3306的映射 - 22 # 指定端口号22的映射 environment: # 配置环境 MYSQL_ROOT_PASSWORD: 123456 # 指定MySQL root用户的登录密码 TimeZone: Asia/Shanghai  # 指定时区 volumes: # 配置数据卷 - /opt/Docker_Voulme/mysql_data:/var/lib/mysql  # 将docker中的/var/lib/mysql映射到宿主机的/opt/Docker_Voulme/mysql_data数据卷上 Tomcat: # 服务的名称 restart: always  # 只要docker启动，那么这个服务就跟着启动 image: daocloud.io/library/tomcat:8.5.15-jre8  # 指定镜像的路径 container_name: Tomcat  # 容器名称 ports: # 配置端口 - 8080:8080 # 指定端口号8080的映射 environment: # 配置环境 TimeZone: Asia/Shanghai  # 指定时区 volumes: # 配置数据卷 - /opt/Docker_Vompose/tomcat_webapps:/usr/local/tomcat/webapps - /opt/Docker_Voulme/tomcat_webapps:/usr/local/tomcat/logs # 在/opt中创建docker-compose文件夹 mkdir /opt/Docker_Voulme # 在docker-compose中创建docker-compose.yml文件，并将以上内容复制到docker-compose.yml中 vim docker-compose.yml    使用docker-compose管理容器\n在使用docker-compose的命令时，默认会在当前目录下找docker-compose.yml文件\n# 基于docker-compose.yml启动管理容器 docker-compose up -d # 关闭并删除容器 docker-compose down # 开启存在的并由docker-compose管理的容器 docker-compose start # 关闭存在的并由docker-compose管理的容器 docker-compose stop # 重启存在的并由docker-compose管理的容器 docker-compose restart # 查看由docker-compose管理的容器 docker-compose ps # 查看docker-compose日志 docker-compose logs -f    docker-compose配合Dockerfile使用自定义镜像\n使用docker-compose.yml文件以及Dockerfile文件在生成自定义镜像的同时启动当前镜像，并由docker-compose管理容器\ndocker-compose.yml\nversion: \u0026#39;3.3\u0026#39; services: Project: restart: always build: # 构建自定义镜像 context: ../  # 指定Dockerfile文件的路径 dickerfile: Dockerfile  # 指定Dockerfile的名称 image: Project:1.0  # 镜像名称和版本 container_name: Project  # 容器名称 ports: - 8080:8080 environment: TZ: Asia/Shanghai Dockerfile\nFROM daocloud.io/library/tomcat:8.5.15-jre8 COPY Project.war /usr/local/tomcat/webapps # 启动基于docker-compose和Dockerfile文件构建的自定义镜像 docker-compose up -d # 注意：如果自定义镜像不存在，docker-compose会帮助我们构建出自定义镜像；如果自定义镜像存在，则直接运行 # 重新构建自定义镜像 docker-compose build # 运行前，重新构建 docker-compose up -d --build    Docker CI/CD\r#\r\rCI（Continuous Intergration）即 持续集成，在编写代码时，完成了一个功能后，立即提交代码到Git仓库中，将项目重新构建并测试。\nCD（Continuous Deployment）即持续部署。\n使用CI/CD可以帮助我们：\n 快速发现错误 防止代码偏离主分支   搭建Gitlab及Gitlab-Runner服务器\n  搭建Gitlab及Gitlab-Runne服务器（至少4G内存）\n  安装Docker以及Docker-Compose\n  创建/opt/docker_gitlab文件夹，并创建docker-compose.yml\n  通过docker-compose.yml文件去安装Gitlab服务器（下载和运行时间较长）\n# docker-compose.yml文件内容 version: \u0026#39;3.3\u0026#39; services: Gitlab: image: \u0026#39;docker.io/gitlab/gitlab-ce:latest\u0026#39; container_name: \u0026#39;Gitlab\u0026#39; restart: always privileged: true hostname: \u0026#39;Gitlab\u0026#39; ports: - 80:80 - 443:443 - 22:22 # 注意修改宿主机的22端口，避免冲突 environment: TZ: \u0026#39;Asia/Shanghai\u0026#39; GITLAB_OMNIBUS_CONFIG: |external_url \u0026#39;http://10.0.0.100\u0026#39; gitlab_rails[\u0026#39;time_zone\u0026#39;] = \u0026#39;Asia/Shanghai\u0026#39; gitlab_rails[\u0026#39;smtp_enable\u0026#39;] = true gitlab_rails[\u0026#39;gitlab_shell_ssh_port\u0026#39;] = 22 volumes: - /opt/docker_gitlab/config:/etc/gitlab - /opt/docker_gitlab/data:/var/opt/gitlab - /opt/docker_gitlab/logs:/var/log/gitlab networks: - gitlab Gitlab-Runner: image: gitlab/gitlab-runner:latest container_name: \u0026#39;Gitlab-Runner\u0026#39; restart: always depends_on: - Gitlab privileged: true volumes: - /opt/gitlab-runner:/etc/gitlab-runner - /var/run/docker.sock:/var/run/docker.sock networks: - gitlab networks: gitlab:   通过http://10.0.0.100登陆Gitlab，默认用户名：root，默认密码：password\n  向Gitlab注册Gitlab-Runner\ndocker exec -it Gitlab-Runner gitlab-runner register   "},{"id":52,"href":"/docs/KVM/KVM/","title":"KVM","section":"KVM","content":"KVM简介\r#\r\r KVM（Kernel-based Virtual Machine，即基于内核的虚拟机）是一种采用硬件虚拟化技术的全虚拟化解决方案。\nKVM最初是由Qumranet公司的Avi Kivity所开发，作为他们的VDI产品后台虚拟化解决方案。为了简化开发，Avi Kivity并没有选择从底层开始写一个Hypervisor，而是选择了基于Linux Kernel通过加载模块变成一个Hypervisor。2006年10月，在先后完成了基本功能、动态迁移以及主要的性能优化后，Qumranet公司正式对外宣布了KVM的诞生。同月，KVM模块的源代码被正式纳入Linux Kernel，成为Linux内核源代码的一部分。\nKVM实现了CPU和内存的虚拟化，但KVM并不能模拟其他设备，还必须有个运行在用户空间的工具才行。KVM的开发者选择了比较成熟的开源虚拟化软件QEMU来作为这个工具，QEMU模拟IO设备（如：网卡，磁盘等），对其进行了修改，最后形成了QEMU-KVM。在QEMU-KVM中，KVM运行在内核空间，QEMU运行在用户空间，实际模拟创建、管理各种虚拟硬件，KVM加上QEMU后形成的QEMU-KVM就是完整意义上的服务器虚拟化。后来发现QEMU模拟IO设备（如：网卡，磁盘等），同样会影响这些设备的性能，于是又产生了Pass-Through半虚拟化设备virtio_blk, virtio_net，以提高设备性能。\n在Linux中，一个KVM虚拟机对应一个\rQEMU-KVM进程，在QEMU进程下，会有独立的线程分别对应vCPU和IO的处理请求。\n在虚拟化的架构中，通常分为三层，由下至上分别为硬件层（CPU、内存、硬盘）、操作系统层（Linux Kernel）、虚拟机层（KVM虚拟机）。KVM工作在操作系统层和虚拟机层之间，虚拟机所看到的硬件设备，实际是QEMU-KVM模拟出来的，例如，当虚拟机层的虚拟机需要使用CPU资源时，会将请求发送至QEMU进程的vCPU线程上，vCPU线程通过KVM模块调用操作系统层的硬件驱动来使用硬件层的CPU资源。\n KVM安装\r#\r\r 操作系统：CentOS 7\n 部署KVM虚拟化环境\r#\r\r 关闭防火墙\nsystemctl stop firewalld.service systemctl disable firewalld.service  关闭SeLinux\nsetenforce 0 sed -i \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/\u0026#39; /etc/selinux/config  更换清华大学YUM源\nsudo sed -e \u0026#39;s|^mirrorlist=|#mirrorlist=|g\u0026#39; \\  -e \u0026#39;s|^#baseurl=http://mirror.centos.org|baseurl=https://mirrors.tuna.tsinghua.edu.cn|g\u0026#39; \\  -i.bak \\  /etc/yum.repos.d/CentOS-*.repo yum makecache  安装KVM依赖包\nyum update -y yum install -y vim net-tools bridge-utils qemu-kvm libvirt virt-install libguestfs libguestfs-tools  bridge-utils：网桥管理工具。\nqemu-kvm：QEMU-KVM模块。\nlibvirt：用于管理虚拟化平台的开源的API，后台程序和管理工具。它可以用于管理KVM、Xen、VMware ESX，QEMU和其他虚拟化技术。\nvirt-install：是一个使用libvirt管理库构建新虚拟机的命令行工具。\nlibguestfs：是 Linux 下一组 C 语言的 API ，用于访问虚拟机的磁盘映像文件。\nlibguestfs-tools：用于一个访问镜像的工具。\n systemctl enable --now libvirtd.service  初始化KVM目录\nmkdir -p /kvm/{vdisks,isos,modify}  vdisks目录：用来存储磁盘。\nisos目录：用来存储安装虚拟机的系统镜像。\nmodify目录：在快速创建虚拟机的过程中，修改模板虚拟机的虚拟磁盘时使用的临时中间目录。\n  检测最新的内核包\ncurl -s https://elrepo.org/linux/kernel/el7/x86_64/RPMS/ | grep kernel-lt | awk -F\u0026#34;href=\u0026#34; \u0026#39;NR==1{ print $2 }\u0026#39; | awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;{ print $2 }\u0026#39; curl -s https://elrepo.org/linux/kernel/el7/x86_64/RPMS/ | grep kernel-lt-devel | awk -F\u0026#34;href=\u0026#34; \u0026#39;NR==1{ print $2 }\u0026#39; | awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;{ print $2 }\u0026#39;  下载最新的内核包\ncurl -o kernel-lt-5.4.227-1.el7.elrepo.x86_64.rpm https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-lt-5.4.227-1.el7.elrepo.x86_64.rpm curl -o kernel-lt-devel-5.4.227-1.el7.elrepo.x86_64.rpm https://elrepo.org/linux/kernel/el7/x86_64/RPMS/kernel-lt-devel-5.4.227-1.el7.elrepo.x86_64.rpm  在内核包所在目录下，安装最新的内核包\nyum -y localinstall kernel-lt-*  根据/boot/目录内的文件，自动创建GRUB内核配置开机选单\ngrub2-set-default 0 \u0026amp;\u0026amp; grub2-mkconfig -o /etc/grub2.cfg 修改内核启动顺序\ngrubby --args=\u0026#34;user_namespace.enable=1\u0026#34; --update-kernel=\u0026#34;$(grubby --default-kernel)\u0026#34; 载入所有KVM模块\nmodprobe -a kvm  重启系统\nreboot  一键部署KVM虚拟化环境脚本\r#\r\r 将如下内容，保存至deploy_kvm_environment.sh，制作成一键部署KVM虚拟化环境脚本。\n#!/usr/bin/env bash # coding: utf-8 # usage: Deploy KVM Environment. # Check Current System =? CentOS # The current script supports the use of the centos distribution,  # and centos 7 is recommended; the script execution environment is bash if [ -f /etc/redhat-release ];then echo \u0026#34;$(cat /etc/redhat-release)\u0026#34; else echo \u0026#34;this system is not CentOS\u0026#34; exit 1 fi function initial_environment() { # set off firewalld systemctl stop --now firewalld.service systemctl disable --now firewalld.service # set off selinux setenforce 0 sed -i \u0026#39;s/SELINUX=enforcing/SELINUX=disabled/\u0026#39; /etc/selinux/config # configure yum repo files mkdir -p /etc/yum.repos.d/repobak; mv /etc/yum.repos.d/* /etc/yum.repos.d/repobak/ curl -o /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-7.repo curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo yum clean all \u0026amp;\u0026amp; yum makecache \u0026amp;\u0026amp; yum update -y # install require software yum -y install vim net-tools bridge-utils qemu-kvm libvirt virt-install libguestfs libguestfs-tools systemctl enable --now libvirtd.service # initial directory mkdir -p /kvm/{vdisks,isos,modify} } function upgrade_kernel() { # upgrade kernel kernel_package_name=$(curl -s https://elrepo.org/linux/kernel/el7/x86_64/RPMS/ | grep kernel-lt | awk -F\u0026#34;href=\u0026#34; \u0026#39;NR==1{ print $2 }\u0026#39; | awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;{ print $2 }\u0026#39;) kernel_devel_name=$(curl -s https://elrepo.org/linux/kernel/el7/x86_64/RPMS/ | grep kernel-lt-devel | awk -F\u0026#34;href=\u0026#34; \u0026#39;NR==1{ print $2 }\u0026#39; | awk -F\u0026#39;\u0026#34;\u0026#39; \u0026#39;{ print $2 }\u0026#39;) cd /opt yum -y update --exclude=kernel* if [ ! -f $kernel_package_name ];then curl -o $kernel_package_name https://elrepo.org/linux/kernel/el7/x86_64/RPMS/$kernel_package_name fi if [ ! -f $kernel_devel_name ];then curl -o $kernel_devel_name https://elrepo.org/linux/kernel/el7/x86_64/RPMS/$kernel_devel_name fi yum -y localinstall kernel-lt-* grub2-set-default 0 \u0026amp;\u0026amp; grub2-mkconfig -o /etc/grub2.cfg grubby --args=\u0026#34;user_namespace.enable=1\u0026#34; --update-kernel=\u0026#34;$(grubby --default-kernel)\u0026#34; modprobe -a kvm } initial_environment upgrade_kernel # reboot machines, continue load kernel kvm module reboot  KVM网络模式\r#\r\r KVM支持三种网络模式，分别是NAT模式、桥接模式（Bridge）、仅主机模式（Host-Only）。\nNAT模式在个人桌面虚拟化中应用较为广泛。\n桥接模式在服务器虚拟化中应用较为广泛。\n仅主机模式一般在大型服务厂商内部应用较为广泛。\n KVM创建虚拟机\r#\r\r KVM虚拟机由虚拟磁盘文件和虚拟机硬件配置文件组成。\n虚拟磁盘文件的路径：/kvm/vdisks\n虚拟机硬件配置文件路径：/etc/libvirt/qemu\n查看物理机中有没有虚拟机\nvirsh list --all  KVM中的磁盘格式有两种，一种是raw，另一种是qcow2。在IO性能方面raw要明显高于qcow2。但基于raw格式创建出的虚拟磁盘属于厚置备，即分配多少空间就占用多少空间，且支持的虚拟化操作较少；而基于qcow2格式创建出的虚拟磁盘属于精简置备，即不管分配了多少空间，都是实际用多少空间占用多少空间，且支持的虚拟化操作较多。\n下面，将分别在NAT和桥接两种网络模式下演示创建KVM虚拟机。\n 在NAT模式下创建虚拟机\r#\r\r 创建虚拟磁盘\nqemu-img create -f qcow2 /kvm/vdisks/nat-network-vm.qcow2  注意，创建的虚拟磁盘文件格式后缀要与指定的磁盘文件格式保持一致。\n创建raw格式的虚拟磁盘，虚拟磁盘文件名称后缀也应为.raw。\n创建qcow2格式的虚拟磁盘，虚拟磁盘文件名称后缀也应为.qcow2。\n  创建虚拟机\nvirt-install --name=nat-network-vm \\ --vcpus=2 --memory=4096 --disk=/kvm/vdisks/nat-network-vm.qcow2 \\ --cdrom=/kvm/isos/CentOS-7-x86_64-Minimal-2009.iso --os-variant=rhel7 \\ --noautoconsole --autostart \\ --graphics vnc,listen=0.0.0.0,port=5901  创建虚拟机时不指定网络模式，默认为NAT模式\n 此时，通过VNC连接物理机IP:5901就可以看到虚拟机控制台了\n 在Bridge模式下创建虚拟机\r#\r\r 创建桥接网卡\nvim /etc/sysconfig/network-scripts/ifcfg-br0 DEVICE=\u0026#34;br0\u0026#34; NAME=\u0026#34;br0\u0026#34; BOOTPROTO=\u0026#34;static\u0026#34; ONBOOT=\u0026#34;yes\u0026#34; TYPE=\u0026#34;Bridge\u0026#34; IPADDR=\u0026#34;192.168.1.100\u0026#34; # 物理机的IP地址 NETMASK=\u0026#34;255.255.255.0\u0026#34; # 物理机的网关地址 GATEWAY=\u0026#34;192.168.1.1\u0026#34; DNS1=\u0026#34;8.8.8.8\u0026#34; DEFROUTE=\u0026#34;yes\u0026#34;  备份物理机ens33网卡的配置\ncp /etc/sysconfig/network-scripts/{ifcfg-ens33,ifcfg-ens33.bak}  将如下配置写入ifcfg-ens33\nDEVICE=\u0026#34;ens33\u0026#34; NAME=\u0026#34;ens33\u0026#34; BOOTPROTO=\u0026#34;none\u0026#34; NM_CONTROLLED=\u0026#34;no\u0026#34; ONBOOT=\u0026#34;yes\u0026#34; TYPE=\u0026#34;Ethernet\u0026#34; BRIDGE=\u0026#34;br0\u0026#34; DEFROUTE=\u0026#34;yes\u0026#34; IPV4_FAILURE_FATAL=\u0026#34;yes\u0026#34;  重启网卡\nsystemctl restart network  创建虚拟磁盘\nqemu-img create -f qcow2 /kvm/vdisks/nat-network-vm.qcow2  注意，创建的虚拟磁盘文件格式后缀要与指定的磁盘文件格式保持一致。\n创建raw格式的虚拟磁盘，虚拟磁盘文件名称后缀也应为.raw。\n创建qcow2格式的虚拟磁盘，虚拟磁盘文件名称后缀也应为.qcow2。\n  创建虚拟机\nvirt-install --name=bridge-network-vm \\ --vcpus=2 --memory=4096 --disk=/kvm/vdisks/bridge-network-vm.qcow2 \\ --cdrom=/kvm/isos/CentOS-7-x86_64-Minimal-2009.iso --os-variant=rhel7 \\ --noautoconsole --autostart \\ --network bridge=br0 \\ --graphics vnc,listen=0.0.0.0,port=5902  创建虚拟机时不指定网络模式，默认为NAT模式\n 此时，通过VNC连接物理机IP:5902就可以看到虚拟机控制台了\n KVM克隆虚拟机\r#\r\r KVM虚拟机是由虚拟磁盘文件和虚拟机硬件配置文件组成，因此，只需要复制虚拟磁盘文件和虚拟机硬件配置文件然后再注册一下虚拟机即可。\n KVM克隆虚拟机的过程\r#\r\r 使用qemu-img命令基于/kvm/vdisks/template.qcow2虚拟磁盘文件创建出/kvm/vdisks/template-quickly.qcow2\nqemu-img create -f qcow2 -b /kvm/vdisks/template.qcow2 /kvm/vdisks/template-quickly.qcow2  -b参数：对/kvm/vdisks/template.qcow2的唯一机器码进行修改，并创建一个新的唯一机器码赋予/kvm/vdisks/template-quickly.qcow2\n  如果template-quickly.qcow2中配置了静态IP地址，则需要手动更改，以避免IP冲突。\n使用guestmount命令将/kvm/vdisks/template-quickly.qcow2虚拟硬盘文件的/dev/centos/root目录挂载到/kvm/modify/目录下\nguestmount -a /kvm/vdisks/template-quickly.qcow2 -m /dev/centos/root /kvm/modify/ 修改IP地址\nsed -i \u0026#39;s/IPADDR=192.168.1.100/IPADDR=192.168.1.101/g\u0026#39; /kvm/modify/etc/sysconfig/network-script/ifcfg-ens33 删除ens33网卡配置文件的UUID\nsed -i \u0026#39;/UUID/d\u0026#39; /kvm/modify/etc/sysconfig/network-script/ifcfg-ens33 使用guestunmount命令将/kvm/modify/目录中的所有文件卸载掉\nguestunmount /kvm/modify/  复制虚拟机配置文件\ncp /etc/libvirt/qemu/{template.xml,template-quickly.xml}  修改/etc/libvirt/qemu/template-quickly.xml中的配置信息\nsed -i \u0026#39;s/template/template-quickly/g\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#39;/uuid/d\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#39;s/template.qcow2/template-quickly.qcow2/g\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#34;s/port=\u0026#39;5901\u0026#39;/port=\u0026#39;5902\u0026#39;/g\u0026#34; /etc/libvirt/qemu/template-quickly.xml  使用virsh命令注册虚拟机（定义克隆的虚拟机）\nvirsh define /etc/libvirt/qemu/template-quickly.xml  查看虚拟机列表\nvirsh list --all  启动template-quickly虚拟机\nvirsh start template-quickly  关闭template-quickly虚拟机\nvirsh shutdown nat-network-vm  一键克隆KVM虚拟机脚本\r#\r\r  使用一键脚本前，需要创建好模板虚拟机（template）\n  创建脚本createvm.sh\n#!/usr/bin/env bash # coding: utf-8 # usage: 创建虚拟机时固定IP地址以及主机名 HELPINFO=\u0026#34; 用法: createvm [hapn]... \\n Create a virtual machine and create a fixed \\n IP address, vnc port, virtual machine name \\n \\t -h, --help 获取帮助信息\\n \\t -a, --address 设置IP地址\\n \\t -p, --port 设置vnc端口\\n \\t -n, --name 设置虚拟机名称\\n 退出状态：\\n \\t 0 正常\\n \\t 1404 一般问题 (例如：没有对应的选项)\\n \\t x403 严重问题 (例如：设置参数不正确)\\n \u0026#34; options=$(getopt -l \u0026#34;help,autostart,address:,port:,name:\u0026#34; -o \u0026#34;h:a:p:n:\u0026#34; -a -- \u0026#34;$@\u0026#34;) if [ $? -ne 0 ];then exit 1404 fi eval set -- \u0026#34;${options}\u0026#34; while true;do case $1 in -h|--help) echo -e ${HELPINFO} exit 0 ;; -a|--address) ping -c3 $2 \u0026amp;\u0026gt;/dev/null if [ $? -eq 0 ];then echo \u0026#34;$2该地址在网络中的另外一台终端中使用, 请尝试其他IP地址\u0026#34; exit 1403 fi NEW_MACHINES_ADDRESS=$2 ;; -p|--port) ss -anptu | grep \u0026#34;:$2\u0026#34; \u0026amp;\u0026gt;/dev/null if [ $? -eq 0 ];then echo \u0026#34;$2该端口正在使用中, 请更换端口继续\u0026#34; exit 2403 fi NEW_MACHINES_VNC=$2 ;; -n|--name) virsh list --all | grep $2 \u0026amp;\u0026gt;/dev/null if [ $? -eq 0 ];then echo \u0026#34;$2虚拟机已经存在, 请更换其他虚拟机名字\u0026#34; exit 3403 fi NEW_MACHINES_NAME=$2 ;; --) shift break ;; esac shift done VM_CONFIG_PATH=\u0026#34;/etc/libvirt/qemu\u0026#34; VM_IMAGE_PATH=\u0026#34;/kvm/vdisks\u0026#34; VM_IMAGE_MODIFY_PATH=\u0026#34;/kvm/modify\u0026#34; TEMPLATE_IMAGE_NAME=\u0026#34;template.raw\u0026#34; TEMPLATE_CONFIG_NAME=\u0026#34;template.xml\u0026#34; # 修改IP地址 qemu-img create -f qcow2 -b ${VM_IMAGE_PATH}/${TEMPLATE_IMAGE_NAME} ${VM_IMAGE_PATH}/${NEW_MACHINES_NAME}.qcow2 guestmount -a ${VM_IMAGE_PATH}/${NEW_MACHINES_NAME}.qcow2 -m /dev/centos/root ${VM_IMAGE_MODIFY_PATH} sed -ri \u0026#34;s/^IPADDR.*/IPADDR=${NEW_MACHINES_ADDRESS}/\u0026#34; ${VM_IMAGE_MODIFY_PATH}/etc/sysconfig/network-scripts/ifcfg-eth0 sed -ri \u0026#34;s/template/${NEW_MACHINES_NAME}/\u0026#34; ${VM_IMAGE_MODIFY_PATH}/etc/hostname guestunmount ${VM_IMAGE_MODIFY_PATH} # 构建配置文件 cp ${VM_CONFIG_PATH}/{${TEMPLATE_CONFIG_NAME},${NEW_MACHINES_NAME}.xml} sed -ri \u0026#34;s/NAME/${NEW_MACHINES_NAME}/\u0026#34; ${VM_CONFIG_PATH}/${NEW_MACHINES_NAME}.xml sed -ri \u0026#34;s/VNCPORT/${NEW_MACHINES_VNC}/\u0026#34; ${VM_CONFIG_PATH}/${NEW_MACHINES_NAME}.xml virsh define ${VM_CONFIG_PATH}/${NEW_MACHINES_NAME}.xml virsh start ${NEW_MACHINES_NAME}  赋予createvm.sh执行权限\nchmod +x createvm.sh  在/usr/local/bin中创建creatvm.sh脚本的软连接createvm\nln -s creatvm.sh /usr/local/bin/createvm  为配合脚本，需要修改/etc/libvirt/qemu/template-quickly.xml中的配置信息\nsed -i \u0026#39;s/template/NAME/g\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#39;/uuid/d\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#39;/mac address/d\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#39;s/template.qcow2/NAME.qcow2/g\u0026#39; /etc/libvirt/qemu/template-quickly.xml sed -i \u0026#34;s/port=\u0026#39;5901\u0026#39;/port=\u0026#39;VNCPORT\u0026#39;/g\u0026#34; /etc/libvirt/qemu/template-quickly.xml  使用脚本克隆虚拟机\ncreatvm -a 192.168.1.102 -p 6902 -n test-createvm-vm  "},{"id":53,"href":"/docs/MySQL/MySQL/","title":"MySQL","section":"MySQL","content":"MySQL相关产品介绍\r#\r\r   Oracle MySQL Cloud Service（Commercial）\n商业付费软件，基于MySQL企业版和Oracle云服务提供企业级的MySQL数据库服务。\n  MySQL Enterprise Edition（Commercial）\n商业付费软件，除了提供MySQL数据库服务之外，又包含了connector（程序连接接口）、partition（分区表）、企业级的monitor（监控）、HA（高可用）、backup（备份）、Scalability（扩展）等服务。\n  MySQL Cluster CGE（Commercial）\n商业付费软件，基于MySQL Cluster和企业版拥有的各项功能提供企业级的高并发、高吞吐量的数据库服务。\n  MySQL Community Edition（Free）\n免费社区版，提供基础的数据库服务和其他衍生服务。\n  MySQL Cluster（但市场中很少使用，口碑不好）\n基于MySQL数据库而实现的集群服务，自身能提供高并发、高负载等特性。\n  MySQL Fabric\n官方提供的关于MySQL数据库高可用和数据分片的解决方案。\n  MySQL Connectors\n为应用程序提供JDBC/ODBC等访问MySQL数据库的接口服务。\n     MySQL版本介绍\r#\r\r 各操作系统与MySQL版本兼容性参照表：https://www.mysql.com/support/supportedplatforms/database.html\n MySQL安装\r#\r\r 安装版本的选择\r#\r\r  首先需要考虑生产环境中的其他MySQL数据库的版本，优先部署与生产其他MySQL一致的版本。 如果是全新部署，则一般会选择安装最新版本。 生产环境不要选择Development Release，应该选择General Availability Release。   二进制文件安装\r#\r\r  官方文档链接：https://dev.mysql.com/doc/refman/8.0/en/binary-installation.html\n警告\n  如果您之前使用操作系统原生软件包管理系统（如Yum或APT）安装过MySQL，您可能会在使用本机二进制文件安装时遇到问题。确保您之前的MySQL安装已完全删除（使用您的软件包管理系统），并且任何其他文件，如旧版数据文件，也已删除。您还应该检查/etc/my.cnf或/etc/mysql目录等配置文件并删除它们。\n有关将第三方软件包替换为官方MySQL软件包的信息，请参阅相关的\rAPT指南或\rYum指南。\n  MySQL依赖于libaio库。如果没有在本地安装此库，数据目录初始化和后续服务器启动步骤失败。如有必要，请使用适当的软件包管理器进行安装。\n   要安装压缩文件的二进制发行版，请在您选择的安装位置（通常是/usr/local/mysql）解压它。这将创建下表中显示的目录。\n   Directory Contents of Directory     bin mysqld server, client and utility programs   docs MySQL manual in Info format   man Unix manual pages   include Include (header) files   lib Libraries   share Error messages, dictionary, and SQL for database installation   support-files Miscellaneous support files    环境准备\r#\r\r 清理历史环境\r#\r\r RedHat/CentOS系下：  $\u0026gt; rpm -qa | grep mariadb # 搜索是否安装了 MariaDB $\u0026gt; yum remove -y mariadb-libs # 卸载 MariaDB  Debian/Ubuntu系下：  $\u0026gt; dpkg -l | grep mariadb # 搜索是否安装了 MariaDB $\u0026gt; apt remove -y mariadb-libs # 卸载MariaDB  安装MySQL依赖\r#\r\r RedHat/CentOS系下：  $\u0026gt; yum search libaio # 搜索 library $\u0026gt; yum install -y libaio # 安装 library  Debian/Ubuntu系下：  $\u0026gt; apt-cache search libaio # 搜索 library $\u0026gt; apt install -y libaio1 # 安装 library $\u0026gt; apt install -y libncurses5 # 安装 libncurses5 $\u0026gt; apt install -y numactl # 安装 numactl,解决 libraries: libnuma.so.1 报错  创建用户和组\r#\r\r如果您的系统还没有用于运行\rmysqld的用户和组，您可能需要创建它们。以下命令添加了mysql组和mysql用户。\n$\u0026gt; groupadd mysql # 创建组 $\u0026gt; useradd -r -g mysql -s /bin/false mysql # 创建用户，并设置 mysql 用户不能登录，注意：/bin/false 相比 /bin/nologin 更为严格，禁用一切服务 $\u0026gt; id mysql # 验证 mysql 账户  创建相关目录\r#\r\r 注意：在生产环境中，一般软件目录、数据目录和日志目录需要分别放在不同的磁盘上\n  软件目录  $\u0026gt; /usr/local # 官方推荐的软件安装路径  数据目录  $\u0026gt; mkdir -p /opt/mysql/3306/data # 在 /home/mysql/ 下创建数据目录data $\u0026gt; chown -R mysql:mysql /opt/mysql/3306/data # 更改数据目录属主和属组 $\u0026gt; chmod -R 750 /opt/mysql/3306/data # 设置数据目录权限  日志目录  $\u0026gt; mkdir -p /opt/mysql/3306/log # 在 /home/mysql/ 下创建日志目录mysql-log $\u0026gt; chown -R mysql:mysql /opt/mysql/3306/log # 更改日志目录属主和属组 $\u0026gt; chmod -R 750 /opt/mysql/3306/log # 设置日志目录权限  安装软件\r#\r\r 软件下载\r#\r\r \rMySQL : Download MySQL Community Server\n  解压软件  $\u0026gt; tar -xvf mysql-VERSION-OS.tar $\u0026gt; tar -xvf mysql-VERSION-OS.tar.xz  将软件移至安装目录并添加软连接  $\u0026gt; mv mysql-VERSION-OS /usr/local $\u0026gt; cd /usr/local $\u0026gt; ln -s full-path-to-mysql-VERSION-OS mysql  设置环境变量\r#\r\r为了避免在使用MySQL时始终键入客户端程序的路径名称，您可以将/usr/local/mysql/bin目录添加到PATH变量中：\n$\u0026gt; vim /etc/profile # 添加以下内容 export PATH=$PATH:/usr/local/mysql/bin # 告诉系统 mysql 命令的路径 $\u0026gt; source /etc/profile # 使环境变量配置生效  初始化MySQL\r#\r\r 要初始化数据目录，请使用--initialize或\u0026ndash;initialize-insecure选项调用mysqld，具体取决于您是希望服务器为'root'@'localhost'帐户生成随机初始密码，还是在没有密码的情况下创建该帐户：\n 使用--initialize进行“默认安全”安装（即包括生成随机初始root密码）。在这种情况下，密码被标记为过期，您必须选择新的密码。 使用--initialize-insecure，不会生成root密码。这是不安全的；假设您打算在将服务器投入生产使用之前及时为帐户分配密码。   数据库目录和文件必须归mysql登录帐户所有，这样服务器在您稍后运行时就可以对它们进行读写访问。为了确保这一点，请从系统root帐户启动\rmysqld，并包含\r--user选项，如下所示：\n$\u0026gt; cd /usr/local/mysql/bin $\u0026gt; mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/opt/mysql/3306/data/  配置文件\r#\r\r 通过命令：mysqld --help --verbose | grep my.cnf 可以查看到运行 mysqld 时都加载了哪些路径下的 my.cnf ，有就读取，没有就跳过。\nMySQL配置文件的读取顺序为：/etc/my.cnf \u0026mdash;\u0026gt; /etc/mysql/my.cnf \u0026mdash;\u0026gt; /usr/local/mysql/etc/my.cnf \u0026mdash;\u0026gt; ~/.my.cnf\n如果需要自定义MySQL的配置文件路径，例如：多实例从不同端口启动MySQL的时候，则需要通过直接调用mysqld服务并增加启动参数的方式启动MySQL\n$\u0026gt; mysqld --default-file=/opt/my.cnf \u0026amp; # \u0026#34;\u0026amp;\u0026#34;符号表示让这条命令在系统后台运行 MySQL配置文件中有两种标签，[服务器端]标签负责设定数据库服务端参数，[客户端]标签负责设定本地客户端连接参数（不影响远程连接）\nMySQL配置文件中都要用小写字母，大写字母不被识别，切记！\n 在/etc/my.cnf文件中添加一下内容：\n[mysql] # 客户端标签 socket=/tmp/mysql.sock # 客户端读取套接字文件的路径（多实例时不要写这个） [mysqld] # 服务器端标签 user=mysql # 负责管理数据库的用户 basedir=/usr/local/mysql # 软件的安装位置 datadir=/opt/mysql/3306/data # 数据的存放位置 port=3306 # 端口号 server_id=1 # 表示节点的唯一编号（主从复制的时候需要用到，单机下无用） socket=/tmp/mysql.sock # 套接字文件 log_error=/opt/mysql/3306/log/mysql.log # 错误日志的存放路径（需要提前创建mysql.log文件并授权） log_bin=/opt/mysql/3306/log/mysql-bin # 二进制日志的存放路径 sync_binlog=1 # binlog日志落盘策略，含义为：每次事务提交，立即将binlog落盘 binlog_format=row # binlog日志记录格式为row gtid-mode=on # 开启GTID模式 enforce-gtid-consistency=true # 强制GTID的一致性 slow_query_log=1 # 开启慢日志查询 slow_query_log_file=/opt/mysql/3306/log/mysql-slow.log #配置慢日志文件路径 long_query_time=10 # 定义慢语句时间标准 log_queries_not_using_indexes=1 # 开启未使用索引语句记录到慢日志  注意：需要提前在/opt/mysql/3306/log/目录下创建并授权mysql.log文件\n  启动服务\r#\r\r 准备MySQL的启动脚本\r#\r\r$\u0026gt; cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqld $\u0026gt; cp /usr/local/mysql/support-files/mysql.server /etc/systemd/system/mysqld -- 将服务添加到 systemctl $\u0026gt; systemctl daemon-reload -- 刷新 systemctl  启动MySQL服务\r#\r\r$\u0026gt; systemctl enable mysql.server -- 将 mysql 服务添加到开机启动 $\u0026gt; systemctl start mysql.service -- 启动 mysql 服务  mysql.server 调用的 mysqld_safe, mysqld_safe 调用的 mysqld\n直接运行 mysqld 或者 mysqld_safe时可以添加启动参数，例如：--skip-grant-tables 、--skip-networking、--default-file=/opt/my.cnf 等\n  修改MySQL初始密码\r#\r\r$\u0026gt; mysqladmin -h 127.0.0.1 -u root -p password  允许ROOT用户远程访问\r#\r\rmysql\u0026gt; CREATE USER \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;123\u0026#39;; mysql\u0026gt; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;%\u0026#39; WITH GRANT OPTION; mysql\u0026gt; FLUSH PRIVILEGES;  关闭MySQL服务\r#\r\r$\u0026gt; systemctl stop mysqld -- 关闭 mysql 服务  通过 /usr/local/bin/mysqld 的方式启动的MySQL服务，需要连接MySQL后使用 shutdown 命令关闭服务，或者通过 mysql -u root -p -e \u0026quot;shutdown\u0026quot; 命令来关闭服务\n  MySQL体系结构\r#\r\r MySQL登录方式\r#\r\r  Socket方式  $\u0026gt; mysql -S /tmp/mysql.sock -u root -p 123456  TCP/IP方式（远程、本地）  $\u0026gt; mysql -h 127.0.0.1 -u root -p password 123456  MySQL实例\r#\r\r 实例 = mysqld后台守护进程 + 主线程（master thread）+ 工作线程（worker thread） + 预分配内存\n 管理工具和服务（Management Serveices \u0026amp; Utilities）\r#\r\r  系统管理和控制工具，例如：备份、恢复、MySQL复制、集群等\n  连接池（Connection Pool）\r#\r\r  数据库连接是一种关键的、有限的、昂贵的资源，这一点在多用户的网页应用程序中体现得尤为突出。对数据库连接的管理能显著影响到整个应用程序的伸缩性和健壮性，影响到程序的性能指标。数据库连接池正是针对这个问题提出来的。\n连接池基本的思想是在系统初始化的时候，将数据库连接作为对象存储在内存中，当用户需要访问数据库时，并非建立一个新的连接，而是从连接池中取出一个已建立的空闲连接对象。使用完毕后，用户也并非将连接关闭，而是将连接放回连接池中，以供下一个请求访问使用。而连接的建立、断开都由连接池自身来管理。同时，还可以通过设置连接池的参数来控制连接池中的初始连接数、连接的上下限数以及每个连接的最大使用次数、最大空闲时间等等。也可以通过其自身的管理机制来监视数据库连接的数量、使用情况等。\n   提供连接协议：TCP/IP、Unix SOCKET\n  加载授权表（mysql.user、mysql.db、mysql.table_priv、mysql.columns_priv、mysql.table_proc、mysql.table_proxy），对连接进行身份认证：用户名、密码、IP、SOCKET\n  提供专用连接线程\n MySQL中可以通过 show processlist; 命令查询已建立的连接\n    SQL接口（SQL Interface）\r#\r\r 接收用户的SQL命令，并且返回用户需要查询的结果。\n 解析器（Parser）\r#\r\r SQL命令传递到解析器的时候会被解析器验证和解析。解析器是由Lex和YACC实现的，是一个很长的脚本。 主要功能：\n  检查所接收的SQL语法是否满足 SQL_MODE\n  语义检查：判断SQL的语句类型\n DDL：数据定义语句 DCL：数据控制语句 DML：数据操作语句 DQL：数据查询语句    对用户的权限进行校验，检查用户对数据库、数据表有没有操作权限\n  进行SQL的预处理，生成解析树（执行计划）并统计执行代价\n 统计信息表：\ninnodb_index_stats\ninnodb_table_stats\n    查询优化器（Optimizer）\r#\r\r 根据解析器生成的多种执行计划，判断并选择出最优的执行计划\n查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化，他使用的是 “选取-投影-联接” 策略进行查询\n 根据资源（CUP、IO、MEM）的损耗进行选择执行计划\n  缓存器（Caches \u0026amp; Buffers）\r#\r\r MySQL 8.0已经去掉此功能。可以使用Redis代替。\n 存储引擎（Pluggable Storage Engines）\r#\r\r 负责 MySQL 中数据的存储与提取。 服务器中的查询执行引擎通过 API 与存储引擎进行通信，通过接口屏蔽了不同存储引擎之间的差异。MySQL 采用插件式的存储引擎。MySQL 为我们提供了许多存储引擎，每种存储引擎有不同的特点。我们可以根据不同的业务特点，选择最适合的存储引擎。如果对于存储引擎的性能不满意，可以通过修改源码来得到自己想要达到的性能。\n特点：\n MySQL 采用插件式的存储引擎 存储引擎是针对于表的而不是针对库的（一个库中不同表可以使用不同的存储引擎），服务器通过 API 与存储引擎进行通信，用来屏蔽不同存储引擎之间的差异 不管表采用什么样的存储引擎，都会在数据区，产生对应的 frm 文件（表结构定义描述文件）   文件系统（File System）\r#\r\r 操作系统的文件系统\n MySQL基础管理\r#\r\r 用户管理\r#\r\r  增  # 创建用户 CREATE USER guest@\u0026#39;localhost\u0026#39;; # 创建用户的同时创建密码 CREATE USER guest@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;123\u0026#39;;   删  DROP USER guest@\u0026#39;localhost\u0026#39;;   改  ALTER USER guest@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;123\u0026#39;;   查  SELECT Host, User, authentication_string FROM mysql.user;  用户授权\r#\r\r 查看系统权限\r#\r\rSHOW PRIVILEGES;  对用户授权\r#\r\r MySQL 8.0开始必须先创建用户，才能对用户进行授权\nMySQL授权表：\nuser：存放全局实例级别权限的用户信息\ndb：存放数据库级别权限的用户信息\ntables_priv：存放表级别权限的用户信息\ncolumns_priv：存放字段级别权限的用户信息\nprocs_priv：存放存储过程权限的用户信息\n  语法  GRANT 权限 ON 数据库.表 TO \u0026#39;用户名\u0026#39;@\u0026#39;IP地址\u0026#39;;  给用户授权db数据库的查询、插入和更改的权限  GRANT SELECT,INSERT,UPDATE ON db.* TO \u0026#39;用户名\u0026#39;@\u0026#39;%\u0026#39;;  给用户授予除grant权限外的所有权限  GRANT ALL PRIVILEGES ON *.* TO \u0026#39;用户名\u0026#39;@\u0026#39;%\u0026#39;;  权限中的ALL表示除GRANT权限之外的所有权限\n  给用户授予所有权限  GRANT ALL PRIVILEGES ON *.* TO root@\u0026#39;%\u0026#39; WITH GRANT OPTION;  查看授权  SHOW GRANTS FOR \u0026#39;用户名\u0026#39;@\u0026#39;IP地址\u0026#39;;  回收授权  REVOKE 权限 ON 数据库.表 FROM \u0026#39;用户名\u0026#39;@\u0026#39;IP地址\u0026#39;;  刷新权限  FLUSH PRIVILEGES;  破解管理员密码\r#\r\r 先关闭mysqld服务  $\u0026gt; /etc/init.d/mysqld stop  使用安全模式启动  $\u0026gt; mysqld_safe --skip-grant-tables --skip-networking \u0026amp; # 跳过授权表并跳过TCP/IP连接  service mysqld start --skip-grant-tables --skip-networking 也可以跳过密码登陆\n  客户端直接以无密码的方式登录root用户  $\u0026gt; mysql -u root -p  修改密码  FLUSH PRIVILEGES; # 手动加载授权 ALTER USER root@\u0026#39;localhost\u0026#39; INDENTIFIED BY \u0026#39;123\u0026#39;; # 修改root用户密码为123  用户权限相关数据保存在MySQL数据库的user表中，可以直接对其操作（不建议）  UPDATE mysql.user SET PASSWORD=password(\u0026#34;123\u0026#34;) WHERE USER=\u0026#34;root\u0026#34; AND host=\u0026#34;localhost\u0026#34;; FLUSH PRIVILEGES;  重启数据到正常模式  $\u0026gt; service mysqld restart  在Windows命令行中用taskkill杀死mysqld服务，然后正常启动mysqld  $\u0026gt; tasklist | findstr mysqld $\u0026gt; taskkill /F /PID 进程号  连接管理\r#\r\r  MySQL 8.0以后的版本，必须提前创建好用户，才可以进行远程连接\n  本地连接\r#\r\r$\u0026gt; mysql -h /temp/mysql.sock -P 3306 -u root -p  远程连接\r#\r\r$\u0026gt; mysql -h 127.0.0.1 -P 3306 -u root -p  免交互执行SQL语句\r#\r\r$\u0026gt; mysql -h 127.0.0.1 -P 3306 -u root -p123456 -e \u0026#34;SELECT * FROM mysql.user\u0026#34;  MySQL多实例\r#\r\r 简而言之，MySQL的多实例就是在一台服务器上启动多个MySQL服务，由于MySQL是单进程多线程的方式运行，因此，也可以说MySQL的多实例是在一台服务器上启动多个MySQL进程\n 相同MySQL版本的多实例\r#\r\r 规划\r#\r\r在同一台服务器上启动两个实例\n 端口： 33061 、 33062 server_id： 1 、 2 数据目录： /opt/mysql/33061/data 、 /opt/mysql/33062/data 日志目录： /opt/mysql/33061/binlog 、 /opt/mysql/33062/binlog 配置文件： /opt/mysql/33061/my.cnf 、 /opt/mysql/33062/my.cnf socket文件： /tmp/mysql_33061.socket 、/tmp/mysql_33062.socket   配置过程\r#\r\r 创建数据目录  $\u0026gt; mkdir -p /opt/mysql/33061/data /opt/mysql/33061/data  创建日志目录  $\u0026gt; mkdir -p /opt/mysql/33061/binlog /opt/mysql/33062/binlog  变更目录的属主属组  $\u0026gt; chown mysql:mysql -R /opt/mysql  创建配置文件  $\u0026gt; vim /opt/mysql/33061/my.cnf # 添加以下内容 [mysqld] # 服务器端标签 user=mysql # 负责管理数据库的用户 basedir=/usr/local/mysql # 软件的安装位置 datadir=/opt/mysql/33061/data # 数据的存放位置 log_error=/opt/mysql/33061/binlog/mysql.log # 错误日志的存放路径 log_bin=/opt/mysql/33061/binlog/mysql-bin # 二进制日志的存放路径 sync_binlog=1 # binlog日志落盘策略，含义为：每次事务提交，立即将binlog落盘，双一中的第二个一 binlog_format=row # binlog日志记录格式为row server_id=1 # 表示节点的唯一编号（主从复制的时候需要用到，单机下无用） port=33061 # 端口号 socket=/tmp/mysql_33061.sock # 套接字文件 [mysql] # 客户端标签 socket=/tmp/mysql_33061.sock # 客户端读取套接字文件的路径（多实例时不要写这个） $\u0026gt; vim /opt/mysql/33062/my.cnf # 添加以下内容 [mysqld] # 服务器端标签 user=mysql # 负责管理数据库的用户 basedir=/usr/local/mysql # 软件的安装位置 datadir=/opt/mysql/33061/data # 数据的存放位置 log_error=/opt/mysql/33061/binlog/mysql.log # 错误日志的存放路径 log_bin=/opt/mysql/33061/binlog/mysql-bin # 二进制日志的存放路径 sync_binlog=1 # binlog日志落盘策略，含义为：每次事务提交，立即将binlog落盘，双一中的第二个一 binlog_format=row # binlog日志记录格式为row server_id=1 # 表示节点的唯一编号（主从复制的时候需要用到，单机下无用） port=33061 # 端口号 socket=/tmp/mysql_33062.sock # 套接字文件 [mysql] # 客户端标签 socket=/tmp/mysql_33062.sock # 客户端读取套接字文件的路径（多实例时不要写这个）  跳过/etc/my.cnf文件的读取  $\u0026gt; mv /etc/my.cnf /etc/my.cnf.bak  初始化数据  $\u0026gt; cd /usr/local/bin mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/opt/mysql/33061/data $\u0026gt; cd /usr/local/bin mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/opt/mysql/33062/data   准备启动脚本\n \rMySQL :: MySQL 8.0 Reference Manual :: 2.5.9 Managing MySQL Server with systemd\n    MySQL基础语句\r#\r\r MySQL开发规范：\rSQL样式指南 · SQL style guide by Simon Holywell\n客户端命令帮助信息：\nhelp 服务器端命令分类信息：\nhelp contents  MySQL语言结构\r#\r\r  MySQL官网对于语言结构的介绍：https://dev.mysql.com/doc/refman/8.0/en/language-structure.html\n  MySQL中字符集和排序规则\r#\r\r sql_mode：SQL模式，用于规范SQL语句的书写方式，使SQL语句不能违背现实常识的一种约束，例如：数学运算中除数不能为0，日期中的0年0月0日等写法\ncharset ：字符集，影响数据是否能正常显示，MySQL 5.7以后默认使用utf8mb4\ncollation：校对（排序）规则，影响到数据的排序规则，在数据库中查询字符ASCII的命令：SELECT ASCII('字符');\n MySQL官网对于字符集和校对的介绍：https://dev.mysql.com/doc/refman/8.0/en/charset.html\n  MySQL数据类型\r#\r\r MySQl官网对于数据类型的介绍：https://dev.mysql.com/doc/refman/8.0/en/data-types.html\n  MySQL约束\r#\r\r Primary Key：主键约束，要求非空且唯一，每张表只能有一个主键，用于聚簇索引。\nNot Null：非空约束，要求必须非空，建议将每个列都设置成非空\nUnique Key：唯一约束，要求唯一不能重复\nUnsigned：非负数约束，针对数字类型的字段，要求数字不能为负数\n MySQL数据类型默认值和注释\r#\r\r default：默认值\ncomment：注释（别名）\n DDL：数据定义语言\r#\r\r  数据定义语言（DDL）：DROP、CREATE、ALTER等操作\n在MySQL中，DDL语句在对表进行操作时，是要锁元数据表的，此时所有修改类的语句无法在此期间执行\n  数据库定义\r#\r\r 增  CREATE DATABASE `数据库名称` CHARACTER SET \u0026#39;utf8mb4\u0026#39;;   删\n 生产中禁止任何用户拥有数据库的删除权限\n   DROP DATABASE 数据库名称;   改\n 数据库不能更改名称，更改字符集时字符集一般都是从小往大改\n   ALTER DATABASE 数据库名称 CHARACTER SET utf8;  查  SHOW DATABASES;  查看创建数据库语句：\nSHOW CREATE DATABASE 数据库名称;   数据表定义\r#\r\r  增\nCREATE TABLE `testdb`.`Untitled` ( `userid` int UNSIGNED NOT NULL AUTO_INCREMENT COMMENT \u0026#39;用户ID\u0026#39;, `username` varchar(255) NOT NULL COMMENT \u0026#39;用户名称\u0026#39;, `password` varchar(255) NOT NULL COMMENT \u0026#39;用户密码\u0026#39;, `gender` char(1) NOT NULL DEFAULT \u0026#39;男\u0026#39; COMMENT \u0026#39;性别\u0026#39;, `age` tinyint UNSIGNED NOT NULL COMMENT \u0026#39;年龄\u0026#39;, PRIMARY KEY (`userid`) ) ENGINE = InnoDB CHARACTER SET = utf8mb4;  建表规范：\n 使用集合名称，或在不那么理想的情况下使用复数形式。如 staff（建议使用）和 employees。 不要使用类似 tbl 或其他的描述性的前缀或匈牙利命名法。 表不应该同它的列同名，反之亦然。 尽量避免连接两个表的名字作为关系表（relationship table）的名字。与其使用 cars_mechanics 做表名不如使用 services。  建列规范：\n 总是使用单数形式。 避免直接使用 id 做表的主标识符。 避免列名和表名同名，反之亦然。 总是使用小写字母，除非是特殊情况，如专有名词。     删\nDROP TABLE `user`;   改\nALTER TABLE `test`.`user` MODIFY COLUMN `email` varchar(200) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL COMMENT \u0026#39;电子邮箱\u0026#39; AFTER `city`;   查\nSHOW TABLES; -- 查看数据库中有哪些表 DESC `user`; -- 查看user表中有哪些字段（表结构） SHOW CREATE TABLE `user`; -- 查看创建user表时的SQL语句    DCL：数据控制语言\r#\r\r  数据控制语言（DCL）：GRANT、REVOKE、COMMIT、ROLLBACK语句。\n  DML：数据操作语言\r#\r\r  数据库操作语言（DML）：INSERT、UPDATE、DELETE语句。\nDML主要针对数据表中的数据行进行增、删、改、查的操作\n    插入数据（INSERT）\n# 查看表结构 DESC 表名称 # 标准insert语句 INSERT INTO 表名称(字段1, 字段2, 字段3, ......) VALUES(值1, 值2, 值3, ......);  具有自增或默认值的字段可以不录入\n   更新数据（UPDATE）\nUPDATE 表名称 SET 字段名称=\u0026#39;需要更新后的值\u0026#39; WHERE 条件;  必须要明确修改哪些行的数据，一般update语句都会跟随where条件\n   删除数据（DELETE）\n 必须要明确删除哪些行的数据，一般delete语句都会跟随where条件\n DELETE FROM 表名称 WHERE 条件;  扩展：\n 伪删除：修改表结构，加入状态列，例如：状态0为存在，状态1为删除，需要删除数据的时候，更改数据状态 delete、drop table、truncate table 都可以将全表的数据删除，区别在于：  delete是逐行删除，属于逻辑性操作，并不会真正从磁盘上删除数据，只是在存储层面打上标记，磁盘空间不会立即释放，自增的HWM（高水位线）不会降低，数据行多的话，这条语句非常慢； drop table将表结构（元数据）和物理层面的数据行进行删除；恢复数据只能靠备份； truncate table清空表段中的所有数据页，属于物理层面的删除，磁盘空间会立即释放，自增的HWM（高水位线）会降低。        DQL：数据查询语言\r#\r\r  数据查询语句（DQL）：SELECT语句。\n从官方来讲，查询语句属于DML，但由于查询语句非常重要，所以单独归类为DQL\n  SELECT\r#\r\r 获取数据表中的数据行\n   SELECT配合内置函数单独查询（MySQL独有的方式）\n# 通过内置函数查看MySQL版本 SELECT version(); # 通过内置函数查看当前使用的表 SELECT database(); # 通过内置函数查看当前登录的用户 SELECT user(); # 通过内置函数查看当前时间 SELECT now(); # 通过内置函数进行字符串拼接 SELECT concat();  通过 help contents; \u0026mdash;\u0026gt; help Function; 查看MySQL内置函数\n   SELECT用于计算（MySQL独有的方式）\nSELECT 1+2;   SELECT查询数据库的参数（MySQL独有的方式）\n# 查询数据库端口 SELECT @@port; # 查询数据存储路径 SELECT @@datadir;    SHOW\r#\r\r SHOW variables;：查看所有数据库参数\n  UNION和UNION ALL\r#\r\r UNION：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序。\nUNION All：对两个结果集进行并集操作，包括重复行，不进行排序。\n  MySQL索引\r#\r\r  索引提供了类似于书中目录的作用，目的是为了优化查询，索引并不是越多越好，索引过多时，索引的频繁更新会导致业务阻塞，并且还会导致优化器选择偏差。因此，需要分析业务语句创建核实的索引。\n那些经常、高频次出现在WHERE、GROUP BY、ORDER BY、JOIN ON语句后面的字段比较适合作为索引。\nMySQL中索引的算法：\n B树索引 Hash索引 R树 Full text GIS    主键索引\r#\r\r  InnoDB主键索引又称为聚簇索引，它不是一种单独的索引类型，而是一种数据存储方式。比如，InnoDB的聚簇索引使用B+Tree的数据结构有序的存储索引和数据。当表有聚簇索引时，它的数据行实际上存放在索引的叶子页(leaf page)中。因为无法同时把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引（不过，覆盖索引可以模拟多个聚簇索引的情况）。\n增、删、改数据表时，主键索引会立即更新。\n 生成聚簇索引的条件：\n 表中设置了主键,主键列就会自动被作为聚集索引 如果没有主键，会选择唯一键作为聚簇索引 聚簇索引必须在建表时才有意义,一般是表的无关列(ID)  查询表的索引\nDESC 数据表名称; # PRI表示主键索引、MUL表示辅助索引、UNI表示唯一索引 显示索引信息\nSHOW INDEX FROM 数据表名称;  辅助索引\r#\r\r  辅助索引又分为：普通索引、联合索引、前缀索引、唯一索引。\n在InnoDB中增、删、改数据表时，辅助索引不会立即更新，而是将要更新的索引内容放到Change Buffer中，在查询到Change Buffer时，会将changebuffer的索引与内存中的索引进行merge（合并）操作，然后将merge后的索引进行落盘。\n  普通索引\r#\r\r 以单个字段生成的索引\n 创建普通索引命令\nALTER TABLE `数据库名称`.`数据表名称` ADD INDEX `索引名称`(`字段名称`) USING BTREE COMMENT \u0026#39;索引注释\u0026#39;; 删除索引命令\nALTER TABLE `数据库名称`.`数据表名称` DROP INDEX `索引名称`;  联合索引\r#\r\r 以多个字段生成的索引。联合索引注意最左原则。建立联合索引时需要选择重复值最少的字段作为最左列。\n 创建联合索引命令\nALTER TABLE `数据库名称`.`数据表名称` ADD INDEX `索引名称`(`字段名称1`, `字段名称2`) USING BTREE COMMENT \u0026#39;索引名称注释\u0026#39;; 删除联合索引命令\nALTER TABLE `数据库名称`.`数据表名称` DROP INDEX `索引名称`;  前缀索引\r#\r\r 通过索引开始的部分字符，提高索引效率且可以节约索引空间，但会降低索引的选择性(选择性:不重复的索引值和数据表的记录总数)，索引选择性越高则查询效率越高。\n 创建前缀索引命令\nALTER TABLE `数据库名称`.`数据表名称` ADD INDEX `索引名称`(`字段名称`(6)) USING BTREE COMMENT \u0026#39;索引注释\u0026#39;; 删除前缀索引命令\nALTER TABLE `数据库名称`.`数据表名称` DROP INDEX `索引名称`;  唯一索引\r#\r\r 以具有唯一属性字段建立的索引，例如：手机号、身份证号等。\n 创建前缀索引命令\nALTER TABLE `数据库名称`.`数据表名称` ADD UNIQUE INDEX `索引名称`(`字段名称`) USING BTREE COMMENT \u0026#39;索引注释\u0026#39;; 删除前缀索引命令\nALTER TABLE `数据库名称`.`数据表名称` DROP INDEX `索引名称`;  执行计划\r#\r\r 查看执行计划\r#\r\rEXPLAIN SELECT * FROM 数据库名称.数据表名称 WHERE 条件; DESC SELECT * FROM 数据库名称.数据表名称 WHERE 条件;  以上两条命令都可以查看执行计划，效果等同\n  执行计划结果\r#\r\r   字段名称 含义     table 此次查询涉及到的表   type 查询类型：全表扫描（all）、索引扫描（index、range、ref、eq_ref、const）   possible_keys 可能用到的索引   key 最后选择的索引   key_len 索引覆盖长度   rows 此次查询需要扫描的行数   Extra 额外的信息     索引扫描类型：index（全索引扫描）、range（索引范围扫描，例如：\u0026lt;、\u0026lt;=、\u0026gt;、\u0026gt;=、like、in、or、between and）\n索引扫描类型的性能：const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index\n  索引应用规范\r#\r\r  为了使索引命中率更高，在创建索引时，必须考虑哪些字段上创建索引以及创建什么类型的索引\n    建表时一定要有主键，一般是个无关列\n  选择唯一性索引（唯一性索引的值时唯一的，可以更快的通过该索引找到某条数据）\n 优化方案：\n  如果非得使用重复值较多的列作为查询条件，例如性别：男，女，可以将表逻辑拆分为“男”和“女”\n  还可以将此列和其他列作为联合索引\n     限制索引的数目\n 索引的数目并不是越多越好，索引过多可能会产生以下问题：\n 占用磁盘空间，每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间越大 在对表进行增删改等操作时，过多的索引在更新和重构时可能会造成业务阻塞 过多的索引会影响到优化器的的选择     删除不再使用或者很少使用的索引\n percona-toolkit中有个工具，专门分析索引是否有用\n   大表加索引，要在业务不繁忙的时候进行操作\n  尽量少在频繁更新的列上创建索引\n   创建索引的原则\r#\r\r  必须要有主键，如有没有作为主键条件的列，那么就创建一个无关列作为主键 高频次出现在WHERE、GROUP BY、ORDER BY、JOIN ON语句后面的字段比较适合作为索引 最好使用唯一值多的列作为索引，如果索引列重复值较多，可以考虑使用联合索引 列值较长的索引列，建议使用前缀索引 降低索引条目，不要创建无用的索引，清理不再使用或不常使用的索引 索引维护要避开业务繁忙时期   导致索引失效的常见原因\r#\r\r 索引查询失效有以下几种情况：\n like以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效 or语句前后条件没有同时使用索引。当or左右查询字段只有一个是索引，该索引失效，只有当or左右查询字段均为索引时，索引才会生效 联合索引，不是使用第一列索引，索引失效 数据类型出现隐式转化。如varchar不加单引号的话可能会自动转换为int型，使索引无效，产生全表扫描 在索引字段上使用not、\u0026lt;\u0026gt;、!=。!=操作符是永远不会用到索引的，对它的处理只会产生全表扫描。 优化方法： key\u0026lt;\u0026gt;0 改为 key\u0026gt;0 or key\u0026lt;0 对索引字段进行计算操作、字段上使用函数。（索引为 emp(ename,empno,sal)） 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效   优化器针对索引的算法介绍\r#\r\r AHI（Adaptive Hash Index） 自适应 Hash 索引\r#\r\rMySQL的InnoDB引擎，能够创建的只有BTree索引，即使创建时选择的是Hash类型的索引，最终还是BTree。Hash索引只能创建于In-Memory Structures中。\nAHI会自动评估内存索引的Page，生成Hash索引表，帮助InnoDB快速读取索引页，加快索引读取的速度。相当于索引的索引。\n Change Buffer\r#\r\r在InnoDB中增、删、改数据表时，辅助索引不会立即更新，而是将要更新的索引内容放到Change Buffer中，在查询到Change Buffer时，会将Change Buffer的索引与内存中的索引进行merge（合并）操作，然后将merge后的索引进行落盘。\n ICP（Index Condition Pushdown）索引下推\r#\r\r在InnoDB中，筛选条件先在Server层做索引优化，未匹配到索引的筛选条件会在engine层先进行筛选，然后在筛选的结果中通过索引获取结果。\n MRR算法\r#\r\r略\n SNLJ算法\r#\r\r略\n BNLJ算法\r#\r\r略\n BKA算法\r#\r\r略\n MySQL存储引擎\r#\r\r 存储引擎是数据库的核心，对于MySQL来说，存储引擎是以插件的形式运行的。通俗来说，MySQL的存储引擎相当于MySQL内置的文件系统。\n 查看当前MySQL支持的存储引擎种类  SHOW ENGINES;  查看当前MySQL的默认存储引擎  SELECT @@default_storage_engine;  查看当前表的存储引擎  SHOW CREATE TABLE \u0026#39;表名称\u0026#39;; # 或 SHOW TABLE STATUS LIKE \u0026#39;表名称\u0026#39;;  将当前会话的存储引擎更改为InnoDB（仅影响当前会话，生产中禁止使用这种方式）  SET default_storage_engine=innodb;  将全局会话的存储引擎更改为InnoDB（仅影响新会话，生产中禁止使用这种方式）  SET GLOBAL default_storage_engine=innodb;  修改数据表的存储引擎为Innodb  ALTER TABLE \u0026#39;表名称\u0026#39; engine=innodb;  注意：此命令除了有修改数据表存储引擎的功能，还有整理InnoDB表碎片的功能，因此在生产中经常用到。\n查看数据表碎片命令\nDESC information_schema.tables; # 查看DATA_FREE项   生产中要变更默认存储引擎，需要修改/etc/my.cnf配置文件  [mysqld] default_storage_engine=innodb  建议将MySQL的存储引擎设置为InnoDB，MySQL 5.1之后的版本默认存储引擎均为InnoDB。\n  InnoDB的特性\r#\r\r MySQL InnoDB官方介绍：\rMySQL :: MySQL 8.0 Reference Manual :: 15 The InnoDB Storage Engine\n    功能 是否支持     存储限制 64TB   MVCC 是   B树索引 是   群集索引（聚簇索引） 是   压缩数据 是   加密数据 是   查询高速缓存 是   事务 是   锁定粒度 是（行级）   外键 是   文件格式管理 是   多个缓冲区池 是   更改缓冲（Change Buffer） 是   索引高速缓存 是   数据告诉缓存 是   自适应散列索引 是   复制 是   更新数据字典 是   地理空间数据类型 是   地理空间索引 是   全文搜索引擎 是   群集数据库 是   备份和恢复 是   快速索引创建 是   PERFORMANCE_SCHEMA 是   自动故障恢复 是     MVCC（Multi-Version Concurrency Control）：多版本并发控制，MVCC的实现，是通过保存数据在某个时间点的快照来实现的。InnoDB的MVCC是通过在每行记录后面保存2个隐藏的列来实现的，一列保存了行的创建时间，一列保存了行的过期时间(或删除时间)，但它们都存储的是系统版本号。MVCC最大的作用是: 实现了非阻塞的读操作，写操作也只锁定了必要的行。\n群集索引（Cluster Index）：又称之为聚簇索引。\n索引体系结构分为集群或非集群。\n集群索引是这样的索引：其在数据页面中的行的顺序对应于索引中的行的顺序。此顺序是任何表中只能存在一个集群索引的原因，而该表中可存在大量非集群索引。在某些数据库系统中，集群索引的叶节点对应于实际数据，而不是对应于指向在其他位置上找到的数据的指针。\n集群索引和非集群索引都只包含索引结构中的键和记录标识。这些记录标识始终指向数据页面中的行。在使用集群索引的情况下，数据库管理器会尝试按照相应的键在索引页面中的顺序来将数据保存在数据页面中。因此，数据库管理器会尝试将具有相似键的行插入到相同页面上。如果对表进行了重组，那么会按照索引键的顺序将数据插入数据页面中。数据库管理器不会维护数据的任何顺序（与非集群索引的对应键的顺序相比时）。\n重组具有所选索引的表会重新集群数据。建立了集群的索引对于带有范围谓词的列非常有用，因为它允许对表中的数据作更有效的顺序访问。因此，由于相似的值在同一数据页面上，系统会访存更少页面。\n通常，表中只有一个索引可以具有较高的集群度。如果集群索引是唯一的，那么集群维护起来就更有效率。\n由于集群索引使存储在页面中的数据的访问路径更线性化，因此它们可提高大多数查询操作的性能。此外，由于具有相似索引键值的行都存储在一起，因而在使用集群索引时顺序检测预取效率更高。\n不能将集群索引指定为与 CREATE TABLE 语句配合使用的表定义的一部分。相反，只通过运行指定了 CLUSTER 选项的 CREATE INDEX 语句来创建集群索引。如果要针对主键集群表，那么 ALTER TABLE 语句必须用来在表上添加与创建的集群索引对应的主键。然后，会将此集群索引用作表的主键索引。\n 看到Day8-7\n MySQL日志管理\r#\r\r 错误日志\r#\r\r 记录从MySQL启动开始，所有的状态、警告和错误。可以为管理员定位数据库出现问题的原因。默认为开启状态，默认路径为:datadir/hostname.err，也可以通过my.cnf自定义错误日志文件的存储路径。\n 二进制日志（binlog）\r#\r\r 主要应用于数据库备份与恢复、主从复制，二进制日志会记录改变数据库（DDL、DCL、DML）的日志，属于逻辑性质的日志，但在MySQL 8.0以前的版本默认没有开启。建议对数据敏感的生产环境下一定要开启此日志！\n 配置方法\r#\r\r  在 /etc/my.cnf 中添加配置信息\n[mysqld] log_bin=/opt/mysql/33061/binlog/mysql-bin server_id=1 sync_binlog=1 # binlog日志落盘策略，含义为：每次事务提交，立即将binlog落盘，双一中的第二个一 binlog_format=row # binlog日志记录格式为row   重启MySQL服务后生效（重启服务后，即可开启binlog日志）\n  在MySQL中查看二进制日志\nselect @@log_bin; # 查看binlog是否开启，打印 1 为开启 select @@log_bin_basename; # 查看binlog的文件位置 show binary logs; # 查看在用的所有binlog日志文件 show master status; # 查看当前在用的binlog日志文件状态 show binlog events in \u0026#39;当前在用的binlog日志文件名称\u0026#39;; # 查看当前在用的binlog日志文件内容   将binlog日志文件内容导出到sql文件\n$\u0026gt; mysqlbinlog mysql-bin.000002 \u0026gt; /opt/data/log/mysql-bin.000002.sql $\u0026gt; cat /opt/data/log/mysql-bin.000002.sql # 查看DML的操作需要添加参数对内容进行翻译 $\u0026gt; mysqlbinlog --base64-output=decode-rows -vvv mysql-bin.000002 \u0026gt; /opt/data/log/mysql-bin.000002.sql cat /opt/data/log/mysql-bin.000002.sql    event 事件：\nevent 是二进制日志中的最小记录单元，对于DDL、DCL语句，一条语句就是一个event，而对于DML语句，只记录已提交的事务。\nevent 由三部分组成：事件的开始标识（begin;）、事件内容和事件的结束标志（commit;），为了方便截取事件，每个部分都有自己的Position（位置）号，Position号包含开始标识（Pos）和结束标识（End_log_pos）。\n   截取binlog日志文件并导出到sql文件（通过增加-d参数，可以指定数据库）\n$\u0026gt; mysqlbinlog --start-position=开始位置标识 --stop--position=结束位置标识 mysql-bin.000002 \u0026gt; /opt/data/log/mysql-bin.000002.sql   使用截取的binlog日志文件恢复数据库\n$\u0026gt; set sql_log_bin=0 # 在当前会话临时关闭binlog日志的记录 $\u0026gt; source /opt/data/log/mysql-bin.000002.sql # 执行sql文件恢复数据库 $\u0026gt; set sql_log_bin=1 # 在当前会话开启binlog日志的记录    维护操作\r#\r\r  日志滚动\n# 手工触发滚动日志 flush logs; # 查看binlog日志大小限制，超过此限制自动滚动 select @@max_binlog_size;  数据库重启也会触发日志滚动\n   日志删除\n 切记不要使用系统的 rm 命令删除日志！rm 命令不是数据库的操作，会造成数据库异常。\n # 查看日志保留时间，默认是0，表示永不删除（日志保留时间最小阈值一般设置为：至少2个全备周期+1） select @@expire_logs_days; # 手工删除日志 purge binary logs to \u0026#39;mysql-bin.000002\u0026#39;; # 删除指定binlog日志之前的所有binlog日志 purge binary logs before \u0026#39;2021-01-01 00:00:00\u0026#39;; # 删除指定时间之前的所有binlog日志 reset master; # 慎用！清空所有日志，所有日志从头开始计数。在主库进行此操作，主从必宕！   binlog的GTID模式\n GTID（Global Transaction ID，全局事务ID）是MySQL 5.6版本之后为了主从而新加入的功能，它是一个已提交事务的编号，并且是一个全局唯一的编号。\n官方定义如下：\nGTID = server_uuid : transaction_id\n查询server_uuid的命令：\nselect @@server_uuid; 或者查看/opt/mysql/data/auto.cnf文件也可以获取server_uuid\n 开启GTID需要在配置文件/etc/my.cnf中添加如下内容\ngtid-mode=on enforce-gtid-consistency=true 重启MySQL\n$\u0026gt; /etc/init.d/msyql.server restart 验证GTID是否开启\nselect @@gtid_mode;   通过binlog的GTID截取并恢复日志\n GTID的幂等性：幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因多次点击而产生副作用。因此，开启GTID后，MySQL恢复binlog时，重复GTID的事务不会再执行了。\n如果想恢复时避免GTID的幂等性，需要在截取日志时增加参数：--skip-gtids\n如果需要排除某些GTID，需要在截取日志时增加参数：--exclude-gtids\n 获取想要恢复日志的起点和终点\nshow binlog events in \u0026#39;mysql-bin.00000x\u0026#39;; 通过获取到的GTID(起点：5，终点：200)和Binlog文件进行截取\n$\u0026gt; mysqlbinlog --skip-gtids --icloude-gtids=\u0026#39;server_uuid:5-200\u0026#39; mysql-bin.000002 mysql-bin.000003 mysql-bin.000004 \u0026gt; /opt/mysql/log/gtid.sql    慢日志（slowlog）\r#\r\r 慢日志（slowlog）主要用来记录MySQL运行过程中较慢的语句，是帮助管理对SQL语句进行优化的一个工具日志。\n 配置方法\r#\r\r默认慢日志是没有开启的，查看方法如下：\nselect @@slow_query_log; # 查看慢日志是否开启，0表示未开启，1表示开启 select @@slow_query_log_file; # 查看慢日志的文件路径 select @@long_query_time; # 查看评估慢语句的时间标准 select @@log_queries_not_using_indexes; # 查看不使用索引的语句记录是否开启，0表示未开启，1表示开启 开启慢日志，需要在/etc/my.cnf中加入以下配置项：\nslow_query_log=1 slow_query_log_file=/opt/mysql/log/mysql-slow.log long_query_time=10 log_queries_not_using_indexes=1 重启数据库生效\n/etc.init.d/mysql.server restart 查看与分析慢日志\n MySQL提供了慢日志的查看与分析工具：mysqldumpslow，生产环境中还可以使用pt-query-digest+Amemometer生成可视化展示平台。\n $\u0026gt; mysqldumpslow -s c -t 10 /data/log/mysql-slow.log  MySQL备份与恢复\r#\r\r  MySQL备份与回复官方介绍：\rMySQL :: MySQL 8.0 Reference Manual :: 7 Backup and Recovery\n  DBA备份与恢复的职责\r#\r\r 设计备份策略（包括：备份工具的选择、备份周期、备份监控） 设计容灾策略（抵御灾难的方式，是使用备份还是高可用） 定期检查备份与容灾的文件 定期对备份与容灾进行故障恢复演练 业务数据损坏时的快速、准确的恢复数据 数据迁移   MySQL常用备份工具\r#\r\r 逻辑备份方式\r#\r\r  mysqldump（简称：MDP，必须要连接MySQL后才能进行备份，查看mysqldump备份的参数：mysqldump --help）\n InnoDB 表的备份，原理是开启一个独立的事务，获取当前最新的一致性快照，将快照数据放在一个临时表中，然后把快照数据转换成创建数据库（CREATE DATABASE）、创建数据表（CREATE TABLE）、插入数据（INSERT ）等的SQL语句，保存到一个后缀为 .sql 的文件中。\n非InnoDB表的备份，需要锁表备份，触发FTWRL（全局锁表），然后再转换成SQL语句，保存到一个后缀为 .sql 的文件中。\n优点：可读性强、压缩比高、节省空间\n缺点：备份时间相对于物理备份长、恢复时间长\n应用场景：数据量较小（100G以内）的数据，建议使用mysqldump。在分布式架构中，可以采用mysqldump备份\n   # 备份所有数据库（参数 -A） $\u0026gt; mysqldump -uroot -p密码 -S /tmp/mysql.sock -A \u0026gt; /data/backup/文件名称.sql # 备份一个或多个指定的数据库（参数 -B） $\u0026gt; mysqldump -uroot -p密码 -S /tmp/mysql.sock -B 数据库1名称 数据库2名称 \u0026gt; /data/backup/文件名称.sql # 备份一个或多个指定的数据表（不加参数） $\u0026gt; mysqldump -uroot -p密码 -S /tmp/mysql.sock 数据库名称 表1名称 表2名称 \u0026gt; /data/backup/文件名称.sql # 在进行“全备 + binlog”恢复数据库的时候为获取全备时binlog的起点（位置点），使用mysqldump进行备份时需要增加参数 --master-data=2 $\u0026gt; mysqldump -uroot -p密码 -S /tmp/mysql.sock -A --master-data=2 \u0026gt; /data/backup/文件名称.sql # 在进行备份的时候，通过转储所有表来创建一致性快照，减少锁表时间，且具备自动锁定、解锁表功能，需要增加参数 --single-transaction $\u0026gt; mysqldump -uroot -p密码 -S /tmp/mysql.sock -A --master-data=2 --single-transaction \u0026gt; /data/backup/文件名称.sql # 正式生产环境中MySQL的备份 $\u0026gt; mysqldump -uroot -p -S /tmp/mysql.sock -A -R -E --master-data=2 --single-transaction --triggers --max_allowed_packet=128M \u0026gt; /opt/mysql/backup/full_backup_`date +%F_%H:%M:%S`.sql  如果不想在终端上输入用户名和密码，可以创建隐藏文件：~/.my.cnf，文件内容如下：\n[mysql] user=root pasword=123 [mysqldump] user=root password=123   mydumper（自行扩展，不做介绍） load data in file（自行扩展，不做介绍） 主从方式（replication）   物理备份方式\r#\r\r  MySQL社区版：Percona Xtrabackup（简称：PBK或XBK）\n Percona Xtrabackup 8仅支持MySQL 8.0，Percona Xtrabackup 7支持MySQL 5.7\nPercona Xtrabackup是一个运行在服务端的工具，而不是运行在客户端的工具\n 安装\n$\u0026gt; wget https://repo.percona.com/apt/percona-release_latest.$(lsb_release -sc)_all.deb $\u0026gt; dpkg -i percona-release_latest.$(lsb_release -sc)_all.deb $\u0026gt; percona-release enable-only tools release $\u0026gt; apt-get update $\u0026gt; apt-get install percona-xtrabackup-80 $\u0026gt; apt-get install qpress 修改/etc/my.cnf文件\n# 增加以下内容 [client] socket=/tmp/mysql.sock 使用 Percona Xtrabackup 对MySQL进行全量备份\n$\u0026gt; innobackupex --user=root --password=123 --no-timestamp /opt/mysql/data/backup/xbk/full_backup_`date +%F`  备份结果中有两个文件比较重要\nxtrabackup_binlog_info：记录备份后的binlog位置点信息，方便获取binlog日志的起点\nxtrabackup_checkpoints：备份过程中的LSN记录，方便做增量备份\n 使用 Percona Xtrabackup 对MySQL进行备份恢复\n 使用 Percona Xtrabackup 进行恢复时，需要目标目录为空目录\n 对备份的文件进行处理（prepare）\n 实际上就是对redo的前滚和undo的回滚，模仿CSR的过程\n $\u0026gt; innobackupex --apply-log /opt/mysql/data/backup/xbk/full_backup_2021-11-30/ 恢复备份\n$\u0026gt; cp -a /opt/mysql/data/backup/xbk/full_backup_2021-11-30/* /opt/mysql/data/ $\u0026gt; chown -R mysql.mysql /opt/mysql/data/*     MySQL企业版：MySQL Enterprise Backup   MySQL备份恢复\r#\r\r  恢复思路：\n 挂维护页 找测试库，恢复全备 截取全备至数据库出问题之前的binlog，并恢复 测试业务功能是否正常 恢复业务    检查全备\r#\r\r$\u0026gt; vim /opt/mysql/backup/full_back_2021-11-29.sql # 记录下如下信息： -- CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;mysql-bin.000003\u0026#39;, MASTER_LOG_POS=5308689;  恢复全备\r#\r\r$\u0026gt; set sql_log_bin=0 # 开了GTID就不用设置此步骤了 $\u0026gt; source /opt/mysql/backup/full_back_2021-11-29.sql  截取二进制日志（binlog）\r#\r\r获取起点：\nvim /opt/mysql/backup/full_back_2021-11-29.sql # 获取到如下信息： -- CHANGE MASTER TO MASTER_LOG_FILE=\u0026#39;mysql-bin.000003\u0026#39;, MASTER_LOG_POS=5308689; # MASTER_LOG_POS作为position起点 SET @@GLOBAL.GTID_PURGED=\u0026#39;server_uuid : 5\u0026#39;; # 6为GTID起点 获取终点方式一（基于position截取终点）：\n# 连接数据库，输入以下语句 show binlog events in \u0026#39;mysql-bin.000003\u0026#39;; # 获取到数据库出问题之前的position为：5308754 # 截取binlog日志 $\u0026gt; mysqlbinlog --skip-gtids --start-position=5308689 --stop-position=5308754 ll /opt/mysql/log/mysql-bin.000003 \u0026gt; /opt/mysql/log/binlog.sql 获取终点方式二（基于GTID截取终点）：\n# 连接数据库，输入以下语句 show binlog events in \u0026#39;mysql-bin.000003\u0026#39;; # 获取到数据库出问题之前的GTID为：\u0026#39;server_uuid : 200\u0026#39; # 截取binlog日志 $\u0026gt; mysqlbinlog --skip-gtids --icloude-gtids=\u0026#39;server_uuid:5-200\u0026#39; mysql-bin.000003 \u0026gt; /opt/mysql/log/binlog.sql  恢复二进制日志（binlog）\r#\r\r$\u0026gt; source /opt/mysql/log/binlog.sql $\u0026gt; set sql_log_bin=1 # 开了GTID就不用设置此步骤了  主从复制\r#\r\r  主从复制（Replication）MySQL官方介绍：\rMySQL :: MySQL 8.0 Reference Manual :: 17 Replication\n  通俗来说，主从复制就是两个或两个以上数据库实例之间通过二进制日志（binlog）实现数据的同步效果（其工作模式为异步）\n 部署主从复制\r#\r\r  准备两台或两台以上可以通过网络互相访问的数据库实例 时间同步 两台或两台以上的数据库实例server_id不同   设置方法（略）\n检查命令：\n$\u0026gt; mysql -u用户名 -p密码 -e \u0026#34;select @@server_id\u0026#34;   在主数据库开启binlog   设置方法（略）\n检查命令：\n$\u0026gt; mysql -u用户名 -p密码 -e \u0026#34;select @@log_bin\u0026#34;   在主数据库建立复制用户   注意：复制用户有明确的权限规定，必须为replication slave\n创建命令：\n# 创建用户：repl，并设置密码为：123 CREATE USER repl@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;123\u0026#39;; # 给用户repl授权replication slave权限 GRANT replication slave ON *.* TO repl@\u0026#39;%\u0026#39;;   将主库备份恢复到从库   备份主库（略）\n将主库恢复到从库命令：\n$\u0026gt; mysql -u用户名 -p密码 \u0026lt;/opt/mysql/backup/主库备份.sql   告知从库复制信息   在从库中通过CHANGE MASTER TO命令可以告知从库连接主库的信息（在数据库中执行）\n在数据库中通过help change master to命令可以查看相关命令信息\nCHANGE MASTER TO MASTER_HOST=\u0026#39;source2.example.com\u0026#39;, MASTER_USER=\u0026#39;replication\u0026#39;, MASTER_PASSWORD=\u0026#39;password\u0026#39;, MASTER_PORT=3306, MASTER_LOG_FILE=\u0026#39;source2-bin.001\u0026#39;, MASTER_LOG_POS=4, MASTER_CONNECT_RETRY=10; 在主库中，通过grep \u0026quot;\\-- CHANGE MASTER TO\u0026quot; /opt/mysql/backup/主库备份.sql命令可以查看到MASTER_LOG_FILE和MASTER_LOG_POS信息\n  开启专用的复制线程   在从库中开启专用的复制线程命令\nSTART SLAVE;   检查主从复制状态   通过在从库上检查专用的复制线程状态，用以检查主从复制状态\nSHOW SLAVE STATUS;   清空主从复制\r#\r\r 在从库的数据库中关闭专用的复制线程\nSTOP SLAVE; 在从库的数据库中清除从库的同步复制信息\nRESET SLAVE ALL;  主从复制原理\r#\r\r 主从复制的中涉及到的资源\r#\r\r 文件资源\n 主库（master）：binlog文件 从库（slave）：relay-log文件、relay-log.info文件、master.info文件   relay-log：主要用于存储接收的binlog日志内容。主库的binlog文件内容从主库发送到从库，从库使用relay-log文件将主库的binlog文件内容接收、保存下来。relay-log默认存储在从库的数据目录下，以文件名称db**-relay-bin.******进行保存，通过在从库的MySQL配置文件中增加relay_log_basename=存储路径可以修改relay-log的默认存储路径。\nrelay-log.info：主要用于记录relay-log回放到的位置点信息。避免从库因某些原因造成日志回放中断时再从头进行重复回放。relay-log.info默认也是存储在从库的数据目录下，relay-log.info除了可以存储为文件，还可以存储在数据表中，通过在从库的MySQL配置文件中增加relay_log_info=file/table可以切换relay-log.info的存储方式，存储在数据表中可以提高性能。\nmaster.info：主要用于存放连接主库的信息和已经接收binlog的位置点信息。master.info默认也是存储在从库的数据目录下，master.info除了可以存储为文件，还可以存储在数据表中，通过在从库的MySQL配置文件中增加master_info_repository=file/table可以切换master.info的存储方式，存储在数据表中可以提高性能。\n  线程资源\n  主库（master）：Binlog_Dump线程\n Binlog_Dump线程（Binlog_Dump Thread）：主要用来接收从库请求，并投递binlog日志给从库。在主库中通过SHOW PROCESSLIST;可以查看到Binlog_Dump Thread。\n   从库（slave）：IO线程、SQL线程\n IO线程（IO Thread）：主要用于请求binlog日志和接收binlog日志。\nSQL线程（SQL Thread）：主要用于回放relay-log日志。\n    主从复制工作原理的描述\r#\r\r 主从复制工作原理的描述将以从库连接主库开始\n第一步：从库（slave）通过CHANGE MASTER TO命令获取主库的连接信息（IP地址、端口号、用户名、密码、binlog日志及位置点），这些信息将被写入到从库的master.info文件中。\n第二步：从库（slave）通过执行start slave命令启动专用的复制线程（IO Thread和SQL Thread），通过IO Thread从第一步获取到的信息连接主库（master）。\n第三步：主库（master）与从库（slave）建立连接后，主库（master）开启Binlog_Dump Thread与从库（slave）的IO Thread进行交互（接收从库请求并投递binlog日志）。详细来说，主库（master）的Binlog_Dump Thread会监测本地binlog的变化，一旦发生改变，会通过Binlog_Dump Thread给从库（slave）的IO Thread发送信号（signal）。\n第四步：从库（slave）的IO Thread向主库（master）的Binlog_Dump Thread请求新的binlog日志。\n第五步：主库（master）的Binlog_Dump Thread接收到binlog日志请求后，会分析并截取binlog日志返回给从库（slave）的IO Thread。\n第六步：从库（slave）的IO Thread通过TCP/IP接收并缓存返回的binlog日志后，写入至relay-log文件中，同时master.info文件也会被更新。\n第七步：从库（slave）的SQL Thread开始工作，SQL Thread先读取relay-log.info文件，获取上次执行回放位置点，根据获取到的位置点向后执行relay-log文件的日志，执行完毕后，更新relay-log.info，记录执行回放的位置点。\n第八步：从库（slave）如果设定了参数relay_log_purge=on，应用过的relay-log会自动被删除。\n 主从复制的状态监控\r#\r\r 一般来说，MySQL的主从复制状态的监控会放在从库，并且监控项都会加入到Zabbix监控系统中\n 主库（master）\n在主库（master）中，一般通过以下两条命令检查主从复制状态\n# 显示正在运行的线程 SHOW processlist; # 显示已连接的从主机 SHOW slave hosts;  从库（slave）\n在从库（slave）中，一般会通过以下命令检查主从复制状态\nSHOW slave status;  主库相关信息\n Master_Host：10.0.0.10\nMaster_User：repl\nMaster_Port：3306\nConnect_Retry：10\nMaster_Log_File：mysql-bin.000002\nRead_Master_Log_Pos：888\n 从库relay-log的执行情况，来自于relay-log.info文件，一般用来判断主从延时\n Relay_Log_File：master-relay-bin.000002\nRelay_Log_Pos：666\nRelay_Master_Log_File：mysql-bin.000002\nRead_Master_Log_Pos：600\n 从库线程状态以及具体报错信息\n Slave_IO_Running：YES\nSlave_SQL_Running：YES\nLast_IO_Errno：0\nLast_IO_Error：\nLast_SQL_Errno：0\nLast_SQL_Error：\n 过滤复制信息\n Replicate_Do_DB：\nReplicate_Ignore_DB：\nReplicate_Do_Table：\nReplicate_Ignore_Table：\nReplicate_Wild_Do_Table：\nReplicate_Wild_Ignore_Table：\n 延迟从库的配置信息（注意：不是从库延时，延时从库是人为想要将从库与主库数据同步延时多长时间）\n SQL_Delay：0\nSQL_Remaining_Delay：NULL\n GTID相关复制信息\n Retrieved_Gtid_Set：\nExecuted_Gtid_Set：\n  主从故障分析及处理\r#\r\r IO线程故障\r#\r\r  从库（slave）无法连接主库（master）：在从库（slave）上使用SHOW slave status;查看Slave_IO_Running的状态为：Connecting。\n 故障原因：主库（slave）的IP地址、端口号、用户名、密码等连接信息填写错误，或者防火墙、网络连接、网络连接数上限等原因引起。\n处理故障思路：先排查网络连接是否正常，是否可以在从库（slave）正常连接到主库，再排查连接主库（slave）的信息是否正确。\n   请求和接收binlog日志故障：在从库（slave）上使用SHOW slave status;查看Slave_IO_Running的状态为：No。\n 故障原因：主库日志损坏或丢失。例如：在主库执行reset master;命令后，主从复制会立刻瘫痪。\n处理故障思路：\n 在从库（slave）上先停掉专用的主从复制线程：stop slave; 在从库（slave）上重置所有的主从复制信息：reset slave all; 在从库上，使用CHANGE MASTER TO命令重新搭建主从复制，然后使用start slave;命令启动专用的主从复制线程。      SQL线程故障\r#\r\r  从库（slave）无法同步主库（master）\n 故障原因：\n 从库（slave）读写relay-log.info时，发现relay-log不完整、丢失或者损坏。 relay-log中的SQL语句不能在从库中回放。主要原因有：  主、从数据库版本有差异或SQL MODE的差异导致同一条SQL的语义不同 需要创建的数据库对象在从库中已经存在，或需要修改或删除的数据库对象在从库中不存在 DML语句不符合表定义及约束，例如：主键约束、唯一键约束等。    处理故障思路：在处理主从故障时把握一个原则：一切以主库为标准。因此，最安全的做法就是重构主从复制。SQL线程故障的原因大多来自从库被人为进行了写入操作。因此，可以在从库使用set global read_only=1命令或在从库的配置文件中加入read_only=1，设置从库只读（对普通用户生效，管理员无效）。或者在主从复制之上加入中间件，形成读写分离架构，让写入操作落到主库上，读取操作落到从库上，就可以有效规避SQL线程故障。\n    主从延迟分析及处理\r#\r\r 主从延迟一般表现为主库的数据发生变更后，从库的数据很长时间才能同步一致。\n 主库（master）原因\r#\r\r  主库（master）的数据库操作没有及时写入到binlog二进制日志上。\n 解决思路：在主库（master）的配置文件中写入sync_binlog=1，让主库（master）的数据操作及时写入到binlog上。\n   MySQL 5.7版本之前的主从复制中，主库（master）的Binlog_Dump线程是以事件作为单元，以串行的方式通过网络将binlog发送给从库（slave），因此，当主库（master）并发事务量大的时候，在网络状况不佳的情况下，通过串行发送给从库（slave）的binlog会有较为明显的延迟。\n 解决思路：MySQL 5.6加入了GTID的功能，即全局事务ID (global transaction identifier), 其保证为每一个在主库上提交的事务在从库（slave）中可以生成一个唯一的ID，实现了GC（Group Commit）机制。从MySQL 5.7开始，即使不开启GTID，MySQL也会自动维护匿名GTID，但生产中仍然建议手工开启GTID。同时，将大事务拆成多个小事务，也可以有效减少主从延时。\n    从库（slave）原因\r#\r\r  默认情况下，从库（slave）只有一个SQL线程执行回放日志，当面对主库（master）高并发执行事务时，从库（slave）串行执行事务必然导致延迟。\n 解决思路：MySQL 5.6 开启了GTID后，拥有开启多SQL线程的特性，但只能针对不同库（database）下的事务进行并发回放。而MySQL 5.7开启GTID后，在binlog中加入了seq_no，在多SQL线程方面，真正的实现了基于逻辑时钟（Logical_Clock）的并发事务，这种技术称之为MTS（Multi-Threaded Slave）\n   当主库（master）发生了较大的事务，从库在回放较大的事务时，也会阻塞后续事务的回放，导致延迟。\n 解决思路：在MySQL中没有太好的方案，只能将较大的事务拆成较小的事务。\n    特殊从库的应用\r#\r\r 延时从库\r#\r\r延时从库时一种根据业务需要，人为配置的从库（slave）与主库（master）延迟同步一段时间。一般来说，延时从库不承接日常业务。\n**使用延时从库的意义：**主从复制用来解决的是主库（master）物理损坏时，从库（slave）可以快速承接业务，而面对逻辑故障（例如：误删数据库、数据表或数据行等人为因素产生的故障）主从复制时没有办法解决的，因此，需要使用延时从库（slave）来解决主库（master）的逻辑故障，缩短业务恢复的时间。\n**配置延迟从库的思路：**让从库（slave）的正常接收主库的binlog，但人为的让SQL线程晚一些回放relay-log，一般生产环境中，建议延迟3至6个小时，具体需要看运维人员对故障的反应时间。\n配置延迟从库：\nstop slave; CHANGE MASTER TO MASTER_DELAY = 21600; start slave; show slave status; **主库逻辑故障的恢复思路：**发现主库发生逻辑故障之后，立即停止延时从库的SQL线程，挂维护页面，截取从库（slave）的relay-log，起点为停止SQL线程的位置点，终点为逻辑故障发生时的位置，将截取的日志恢复到延时从库（slave），解除延时从库的从库身份，提升为主库。\n主库逻辑故障恢复方法：\n# 在延时从库上停掉SQL线程 stop slave sql_thread; # 获取Relay_Log_File和Relay_Log_Pos的信息作为relay-log的起点 show slave status; # 获取获取事件信息的POS作为relay-log的终点 show relaylog events in \u0026#39;dbxx-relay-bin.xxxxxx\u0026#39;; # 截取relay-log日志 $\u0026gt; mysqlbinlog --start-position=666 --stop-position=888 /data/dbxx-relay-bin.xxxxxx \u0026gt; /tmp/relay.sql # 在延迟从库中恢复截取的relay-log日志 set sql_log_bin=0; #设为0后，在Master数据库上执行的语句都不记录binlog source /tmp/relay.sql; # 解除延时从库的从库身份，提升为主库 stop slave; reset slave all;  半同步复制\r#\r\r半同步复制（Semi-Synchronous Replication）用来解决主从数据一致性的问题，主要用于对主从数据一致性有高要求的环境。半同步复制在MySQL 5.5中出现，在MySQL 5.6中增强，在MySQL 5.7中完善，但由于性能较差，被5.7中出现的数据库高可用与高扩展的解决方案MGR（MySQL Group Replication，又被称为无损复制）替代。\n 过滤复制\r#\r\r过滤复制是指主库（master）中有多个数据库，而在复制的过程中并不是将所有的数据库都复制到从库（slave），而是有选择的将数据库复制到从库（slave）。过滤复制在实际业务中经常会被用到。\n过滤复制在主库（master）和从库（slave）中都可以进行控制，通过主库（master）进行过滤复制，只有复制的数据库才会记录binlog，不复制的数据库不会记录binlog，因此，在生产环境中一般会在从库中进行控制。\n主库（master）控制过滤复制的参数：\n Binlog_Do_DB # 相当于白名单 Binlog_Ignore_DB # 相当于黑名单  从库（slave）控制过滤复制的参数：\n Replicate_Do_DB Replicate_Ignore_DB Replicate_Do_Table Replicate_Ignore_Table Replicate_Wild_Do_Table Replicate_Wild_Ignore_Table  在从库配置过滤复制\n# 在配置文件中加入参数 replicate_do_db=数据库名称1 replicate_do_db=数据库名称2  GTID复制\r#\r\rGTID（Global Transaction ID）由主库上生成的与事务绑定的唯一标识，这个标识不仅在主库上是唯一的，在MySQL集群内也是唯一的。相对于之前版本基于Binlog+Position的主从复制，基于GTID的主从复制，数据一致性更高，主从数据复制更健壮，主从切换、故障切换不易出错，很少需要人为介入处理。\n主库（master）开启GTID需要在配置文件/etc/my.cnf中添加如下内容\ngtid-mode=on enforce-gtid-consistency=true 主库（master）重启MySQL\n$\u0026gt; /etc/init.d/msyql.server restart 主库（master）验证GTID是否开启\nselect @@gtid_mode; 从库（slave）配置文件/etc/my.cnf中添加如下内容\nlog-slave-update=1 从库（slave）执行change master to命令\nCHANGE MASTER TO MASTER_HOST=\u0026#39;source2.example.com\u0026#39;, MASTER_USER=\u0026#39;replication\u0026#39;, MASTER_PASSWORD=\u0026#39;password\u0026#39;, MASTER_PORT=3306, MASTER_AUTO_POSITION=1; # 如果主从复制同步搭建的时候可以写这条命令，如果主库运行很长时间了才开始搭建主从复制，则仍然需要使用全备的方式 从库（slave）开启专用的复制线程\nSTART SLAVE;  GTID主从复制与传统的主从复制的区别：\n从库（slave）在执行change master to的时候不在需要binlog文件名和position号了，直接通过MASTER_AUTO_POSITION=1就可以使从库（slave）连接上主库（master），在复制过程中，从库也不再依赖master.info文件，而是直接读取最后一个relay-log的GTID号。\n在主库（master）使用mysqldump进行备份时，默认会在备份中包含事务操作，以SET @@GLOBAL.GTID_PURGED='8s89d87aa-6e66-34i8-8765-3244dfd33346:1';告知从库（slave）备份中已经包含的事务操作，直接从下一个GTID开始请求binlog。\n  主从复制架构演变\r#\r\r 主从复制基础架构（不需要第三方软件支持）一般分为：1主1从、1主多从、双主机构、多级主从、循环复制等。\n在主从复制的基础架构上又演变出高可用架构、高性能架构和分布式架构等高级架构（需要其他第三方软件支持）。\n高可用架构：\n 单活：MMM（Keepalived+2主1从），MHA（1主2从），TMHA（1主1从） 多活：NDB Cluster（收费），InnoDB Cluster，PXC（Percona XtraDB Cluster，国内用的较少），MGC（MariaDB Galera Cluster ）  高性能架构：\n 读写分离架构：Atlas（360开发的，已停止维护），Cobar，ProxySQL（Percona），MySQL Router（Oracle），Maxscale，Mycat  **分布式架构：**Mycat，TDDL（阿里巴巴开发的）\n 高可用架构\r#\r\r  MHA Github：\rInstallation · yoshinorim/mha4mysql-manager Wiki · GitHub\nMHA是“一次性”的高可用功能，每次出现主库宕机后，MHA的Manager节点都会将其从配置文件中删掉，节点恢复后需要手动将恢复后的主库节点信息再加入到配置文件中。\n  MHA高可用架构软件构成\r#\r\r  Manager工具包主要包括以下几个工具（脚本）：\nmasterha_manger：用于启动MHA Manager的脚本\nmasterha_stop：用于关闭MHA Manager的脚本\nmasterha_check_ssh：检查MHA的SSH配置状况\nmasterha_check_repl：检查MySQL复制状况\nmasterha_master_monitor：检测Master是否宕机\nmasterha_check_status：检测当前MHA运行状态\nmasterha_master_switch：控制故障转移（自动或者手动）\nmasterha_conf_host：添加或删除配置的Server信息\n  Node工具包主要包括以下几个工具：\n 这些工具通常由MHA Manager的脚本触发，无需人为操作\n save_binary_logs：保存和复制master的二进制日志 apply_diff_relay_logs：识别差异的中继日志事件并将其差异的事件应用于其他的 purge_relay_logs：清除中继日志（不会阻塞SQL线程）\n   MHA高可用架构工作原理\r#\r\r 通过MHA配置文件获取所有节点的信息，监控节点的网络、操作系统、SSH软件的连通性和主从状态。 主库选举：如果主库（Master）宕机，MHA架构将会在2个从库之间进行主库的选举，通过从库（Salve）show slave status;命令查询到的Position或GTID与relay-log进行对比，当2个从库（Slave）与主库（Master）的的数据一致时，按照MHA配置文件的顺序进行主库的选举；当2个从库（Slave）与主库（Master）的数据有差异时，选择数据最接近主库的从库（Slave）为备选主库。如果在MHA配置文件中设定了从库的权重candidate_master=1，则按照权重强制指定相应的从库（Slave）为备选主库。默认情况下，如果一个从库（Slave）落后主库（Master）100M的relay-log，即使有权重也会失效；但如果check_repl_delay=0,即使落后很多日志，也会强制选择其为备选主机。 数据补偿：当SSH能连接到主库（Master）时，从库（Slave）对比主库（Master）的Position或GTID，如果数据不一致，从库的save_binary_logs脚本会将主库的binlog获取到本地；当SSH不能连接到主库（Master）时，从库的apply_diff_relay_logs脚本将检查与relay-log的差异。 故障切换（Failover）：将备选主库切换成主库（Master），开始对外提供服务，其余从库（Slave）和新主库确认新的主从关系。 应用透明（VIP） 故障切换通知（report_script） 二次数据补偿（单独设置一台Binlog_Server，记录主库的binlog日志）   部署MHA高可用架构\r#\r\r  搭建主从复制（1主2从），确保主从复制状态正常。\n  如果MySQL没有安装在/usr/bin目录下，需要创建软连接（MHA脚本中写入的是绝对路径）。\n  配置个节点互信\n$\u0026gt; rm -rf /root/.ssh $\u0026gt; ssh-keygen $\u0026gt; cd /root/.ssh $\u0026gt; mv id_rsa.pub authorized_keys $\u0026gt; scp -r /root/.ssh/authorized_keys 从库1（Slave）IP:/root $\u0026gt; scp -r /root/.ssh/authorized_keys 从库2（Slave）IP:/root   在三个节点上均安装Node软件\n# 安装环境依赖 $\u0026gt; yum install -y perl-DBD-MySQL # 安装Node（需提前下载） $\u0026gt; rpm -ivh mha4mysql-node-0.56-0.el6.noarch.rpm   在主库（master）上安装Manager软件\n# 安装环境依赖 $\u0026gt; yum install -y perl-Config-Tiny epel-release perl-Log-Dispatch perl-Parallel-ForkManager perl-Time-HiRes # 安装Master（需提前下载） $\u0026gt; rpm -ivh mha4mysql-manager-0.56-0.el6.noarch.rpm   在主库（Master）上创建MHA监控管理用户\n# 创建用户的同时创建密码 CREATE USER mha@\u0026#39;10.0.0.%\u0026#39; IDENTIFIED BY \u0026#39;mha\u0026#39;; # 对mha用户进行授权 GRANT ALL PRIVILEGES ON *.* TO mha@\u0026#39;10.0.0.%\u0026#39;;   在主库（Master）上准备MHA配置文件\n# 创建配置文件目录 $\u0026gt; mkdir -p /etc/mha # 创建日志目录 $\u0026gt; mkdir -p /var/log/mha/app1 # 编辑 /etc/mha/app1.cnf 文件，内容如下： [server default] manager_log=/var/log/mha/app1/manager manager_workdir=/var/log/mha/app1 master_binlog_dir=/data/mysql/binlog user=mha password=mha ping_interval=2 repl_user=repl repl_password=123 ssh_user=root [server1] hostname=10.0.0.x port=3306 [server2] hostname=10.0.0.x port=3306   检查节点的SSH互信状态\n$\u0026gt; masterha_check_ssh --conf=/etc/mha/app1.cnf   检查主从状态\n$\u0026gt; masterha_check_repl --conf=/etc/mha/app1.cnf   启动MHA的Manager\n$\u0026gt; nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u0026lt;/dev/null\u0026gt; /var/log/mha/app1/manager.log 2\u0026gt;\u0026amp;1 \u0026amp;   检查MHA状态\n$\u0026gt; masterha_check_status --conf=/etc/mha/app1.cnf    MHA的应用透明（VIP）\r#\r\r  准备master_ip_failover脚本\n#!/usr/bin/env perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL =\u0026gt; \u0026#39;all\u0026#39;; use Getopt::Long; use MHA::DBHelper; my ( $command, $ssh_user, $orig_master_host, $orig_master_ip, $orig_master_port, $new_master_host, $new_master_ip, $new_master_port, $new_master_user, $new_master_password ); my $vip = \u0026#39;192.168.168.100/24\u0026#39;; my $key = \u0026#34;1\u0026#34;; my $ssh_start_vip = \u0026#34;/sbin/ifconfig ens33:$key $vip\u0026#34;; my $ssh_stop_vip = \u0026#34;/sbin/ifconfig ens33:$key down\u0026#34;; GetOptions( \u0026#39;command=s\u0026#39; =\u0026gt; \\$command, \u0026#39;ssh_user=s\u0026#39; =\u0026gt; \\$ssh_user, \u0026#39;orig_master_host=s\u0026#39; =\u0026gt; \\$orig_master_host, \u0026#39;orig_master_ip=s\u0026#39; =\u0026gt; \\$orig_master_ip, \u0026#39;orig_master_port=i\u0026#39; =\u0026gt; \\$orig_master_port, \u0026#39;new_master_host=s\u0026#39; =\u0026gt; \\$new_master_host, \u0026#39;new_master_ip=s\u0026#39; =\u0026gt; \\$new_master_ip, \u0026#39;new_master_port=i\u0026#39; =\u0026gt; \\$new_master_port, \u0026#39;new_master_user=s\u0026#39; =\u0026gt; \\$new_master_user, \u0026#39;new_master_password=s\u0026#39; =\u0026gt; \\$new_master_password, ); exit \u0026amp;main(); sub main { if ( $command eq \u0026#34;stop\u0026#34; || $command eq \u0026#34;stopssh\u0026#34; ) { # $orig_master_host, $orig_master_ip, $orig_master_port are passed. # If you manage master ip address at global catalog database, # invalidate orig_master_ip here. my $exit_code = 1; eval { # updating global catalog, etc $exit_code = 0; }; if ($@) { warn \u0026#34;Got Error: $@\\n\u0026#34;; exit $exit_code; } exit $exit_code; } elsif ( $command eq \u0026#34;start\u0026#34; ) { # all arguments are passed. # If you manage master ip address at global catalog database, # activate new_master_ip here. # You can also grant write access (create user, set read_only=0, etc) here. my $exit_code = 10; eval { print \u0026#34;Enabling the VIP - $vip on the new master - $new_master_host \\n\u0026#34;; \u0026amp;start_vip(); \u0026amp;stop_vip(); $exit_code = 0; }; if ($@) { warn $@; exit $exit_code; } exit $exit_code; } elsif ( $command eq \u0026#34;status\u0026#34; ) { print \u0026#34;Checking the Status of the script.. OK \\n\u0026#34;; `ssh $ssh_user\\@$orig_master_host \\\u0026#34; $ssh_start_vip \\\u0026#34;`; exit 0; } else { \u0026amp;usage(); exit 1; } } sub start_vip() { `ssh $ssh_user\\@$new_master_host \\\u0026#34; $ssh_start_vip \\\u0026#34;`; } # A simple system call that disable the VIP on the old_master  sub stop_vip() { `ssh $ssh_user\\@$orig_master_host \\\u0026#34; $ssh_stop_vip \\\u0026#34;`; } sub usage { print \u0026#34;Usage: master_ip_failover --command=start|stop|stopssh|status --orig_master_host=host --orig_master_ip=ip --orig_master_port=port --new_master_host=host --new_master_ip=ip --new_master_port=port\\n\u0026#34;; }   将master_ip_failover脚本上传至MHA Manager的/usr/local/bin中，并赋予执行权限\n  在MHA Manager的/etc/mha/app1.cnf配置文件中增加如下内容，调用脚本文件\nmaster_ip_failover_script=/usr/local/bin/master_ip_failover   第一次配置VIP的时候，需要在主库（Master）上手动生成VIP\n$\u0026gt; ifconfig ens33:1 192.168.168.100   在MHA Manager上重启Manager\n$\u0026gt; masterha_stop --conf=/etc/mha/app1.cnf $\u0026gt; nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u0026lt;/dev/null\u0026gt; /var/log/mha/app1/manager.log 2\u0026gt;\u0026amp;1 \u0026amp;    MHA故障提醒\r#\r\r  准备report_script脚本文件\n#!/usr/bin/perl # Copyright (C) 2011 DeNA Co.,Ltd. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License as published by # the Free Software Foundation; either version 2 of the License, or # (at your option) any later version. # # This program is distributed in the hope that it will be useful, # but WITHOUT ANY WARRANTY; without even the implied warranty of # MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the # GNU General Public License for more details. # # You should have received a copy of the GNU General Public License # along with this program; if not, write to the Free Software # Foundation, Inc., # 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA ## Note: This is a sample script and is not complete. Modify the script based on your environment. use strict; use warnings FATAL =\u0026gt; \u0026#39;all\u0026#39;; use Mail::Sender; use Getopt::Long; #new_master_host and new_slave_hosts are set only when recovering master succeeded my ( $dead_master_host, $new_master_host, $new_slave_hosts, $subject, $body ); my $smtp=\u0026#39;smtp.163.com\u0026#39;;　# 这里的smtp可以查看要使用的邮箱的smtp值, 或者百度 my $mail_from=\u0026#39;from@163.com\u0026#39;;　# 填写邮箱 my $mail_user=\u0026#39;from@163.com\u0026#39;;　# 填写邮箱 my $mail_pass=\u0026#39;password\u0026#39;;　# 注意这里的密码是邮箱开启smtp服务时设定的密码, 不是邮箱的登陆密码 #my $mail_to=[\u0026#39;to1@qq.com\u0026#39;,\u0026#39;to2@qq.com\u0026#39;]; my $mail_to=\u0026#39;to@qq.com\u0026#39;;　# 接受邮件的邮箱 GetOptions( \u0026#39;orig_master_host=s\u0026#39; =\u0026gt; \\$dead_master_host, \u0026#39;new_master_host=s\u0026#39; =\u0026gt; \\$new_master_host, \u0026#39;new_slave_hosts=s\u0026#39; =\u0026gt; \\$new_slave_hosts, \u0026#39;subject=s\u0026#39; =\u0026gt; \\$subject, \u0026#39;body=s\u0026#39; =\u0026gt; \\$body, ); # Do whatever you want here mailToContacts($smtp,$mail_from,$mail_user,$mail_pass,$mail_to,$subject,$body); sub mailToContacts { my ($smtp, $mail_from, $mail_user, $mail_pass, $mail_to, $subject, $msg ) = @_; open my $DEBUG, \u0026#34;\u0026gt;/var/log/masterha/app1/mail.log\u0026#34;　# 这里的路径需要修改,改成一个真是存在的路径即可 or die \u0026#34;Can\u0026#39;t open the debug file:$!\\n\u0026#34;; my $sender = new Mail::Sender { ctype =\u0026gt; \u0026#39;text/plain;charset=utf-8\u0026#39;, encoding =\u0026gt; \u0026#39;utf-8\u0026#39;, smtp =\u0026gt; $smtp, from =\u0026gt; $mail_from, auth =\u0026gt; \u0026#39;LOGIN\u0026#39;, TLS_allowed =\u0026gt; \u0026#39;0\u0026#39;, authid =\u0026gt; $mail_user, authpwd =\u0026gt; $mail_pass, to =\u0026gt; $mail_to, subject =\u0026gt; $subject, debug =\u0026gt; $DEBUG }; $sender-\u0026gt;MailMsg( { msg =\u0026gt; $msg, debug =\u0026gt; $DEBUG } ) or print $Mail::Sender::Error; return 1; } exit 0;   将report_script脚本上传至MHA Manager的/usr/local/bin中，并赋予执行权限\n  在MHA Manager的/etc/mha/app1.cnf配置文件中增加如下内容，调用脚本文件\nreport_script=/usr/local/bin/report_script   在MHA Manager上重启Manager\n$\u0026gt; masterha_stop --conf=/etc/mha/app1.cnf $\u0026gt; nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u0026lt;/dev/null\u0026gt; /var/log/mha/app1/manager.log 2\u0026gt;\u0026amp;1 \u0026amp;    二次数据补偿\r#\r\r  如果使用其中一个从库作为Binlog_Server，需要提前建立好备份binlog的文件夹，在MHA Manager的/etc/mha/app1.cnf配置文件中增加如下内容\n[binlog1] no_master=1 hostname=x.x.x.x master_binlog_dir=/data/mysql/binlog   进入binlog的备份文件夹，拉取主库的binlog日志\n$\u0026gt; mysqlbinlog -R --host=x.x.x.x --user=mha --password=mha --raw --stop-nnever mysql-bin.000001 \u0026amp;   在MHA Manager上重启Manager\n$\u0026gt; masterha_stop --conf=/etc/mha/app1.cnf $\u0026gt; nohup masterha_manager --conf=/etc/mha/app1.cnf --remove_dead_master_conf --ignore_last_failover \u0026lt;/dev/null\u0026gt; /var/log/mha/app1/manager.log 2\u0026gt;\u0026amp;1 \u0026amp;    高性能架构（读写分离）\r#\r\r MyCAT官网：\rMycat2\n分布式架构\r#\r\r MyCAT官网：\rMycat2\n"},{"id":54,"href":"/docs/PostgreSQL/PostgreSQL/","title":"PostgreSQL","section":"PostgreSQL","content":"简介\r#\r\r PostgreSQL简称PG或PGSQL，是使用C和C++语言开发的，开源的，关系型数据库，支持多种操作系统平台，是一种比较好的Oracle数据库替代方案。\n 官方网站：https://www.postgresql.org\n中文社区：http://www.postgres.cn\n  安装\r#\r\r Yum Repository\r#\r\r  \rPostgreSQL: Linux downloads (Red Hat family)\n # Install the repository RPM: sudo dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-9-x86_64/pgdg-redhat-repo-latest.noarch.rpm # Disable the built-in PostgreSQL module: sudo dnf -qy module disable postgresql # Install PostgreSQL: sudo dnf install -y postgresql14-server # Optionally initialize the database and enable automatic start: sudo /usr/pgsql-14/bin/postgresql-14-setup initdb sudo systemctl enable postgresql-14 sudo systemctl start postgresql-14  Apt Repository\r#\r\r  \rPostgreSQL: Linux downloads (Debian)\n # Create the file repository configuration: sudo sh -c \u0026#39;echo \u0026#34;deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\u0026#34; \u0026gt; /etc/apt/sources.list.d/pgdg.list\u0026#39; # Import the repository signing key: wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - # Update the package lists: sudo apt-get update # Install the latest version of PostgreSQL. # If you want a specific version, use \u0026#39;postgresql-12\u0026#39; or similar instead of \u0026#39;postgresql\u0026#39;: sudo apt-get -y install postgresql  源码编译安装（Source）\r#\r\r  PostgreSQL各版本下载地址：\rPostgreSQL: File Browser\nLinux下软件源码编译安装“三板斧”：\n 配置（./configure） 编译（make） 安装（make install）  二进制与源码安装的区别：\n 二进制包是官方已经完成编译，可以直接运行的程序，通过下载和解压缩软件后就可以直接使用，适用于不需要定制化的场景。 源代码包中是程序的源代码，需要进行编译后，生成可执行的二进制文件才可以使用，在编译时可以定制各种参数，例如：安装路径、数据路径、端口号以及其他所需的功能，自由度相较于二进制包的方式更高一些，因此适用于需要定制化的场景。    创建用户和组\r#\r\r adduser postgres 或\nuseradd postgres passwd postgres  验证创建的用户\nid postgres  所有PostgreSQL的操作都要在postgres用户下。\n  安装依赖包\r#\r\r  最小依赖：gcc、gcc-c++、zlib-devel、readline-devel\n其他依赖：perl-ExtUtils-Embed、pam-devel、libxml2-devel、libxslt-devel、openldap-devel、python-devel、openssl-devel、cmake\n  CentOS\ndnf install -y gcc readline* zlib-devel python-devel openssl-devel libxml2-devel libxslt-devel  Debian\napt install -y gcc make readline* libreadline-dev zlib1g-dev python-dev libssh-dev libxml2-dev libxslt-dev libsystemd-dev  创建目录及授权\r#\r\r 创建PostgreSQL安装目录\nmkdir -p /usr/local/PostgreSQL-14.1  创建软连接\nln -s /usr/local/PostgreSQL-14.1 pgsql  创建PostgreSQL数据目录\nmkdir -p /home/postgres/pgsql/data  更改PostgreSQL数据目录的属主和属组\nchown -R postgres:postgres /home/postgres/pgsql  更改PostgreSQL数据目录的权限\nchmod -R 700 /home/postgres/pgsql  系统参数优化\r#\r\r Linux操作系统内核调整，配置/etc/sysctl.conf\nkernel.shmmax = 68719476736 # 默认值，以字节为单位，该参数定义了共享内存段的最大值(建议内存的80%) kernel.shmmni = 4096 # 该参数用于设置系统范围内共享内存段的最大数量 kernel.shmall = 4294967296 # 默认值，以页为单位，该参数表示系统任意时刻可以分配的所有共享内存段的最大值(以页为单位) kernel.sem = 50100 64128000 50100 1280 # 50100表示系统范围内每个信号对象集放入最大信号对象数 # 64128000表示最大信号对象数 # 50100表示每个信号对象支持的最大操作数 # 1280表示系统范围内最大信号对象集数 fs.file-max = 76724600 # 可使用的最大文件句柄数量,也就是可以打开最大的文件数量 net.ipv4.ip_local_port_range = 9000 65000 # 应用程序可以使用的IPv4端口范围 net.core.rmem_default = 1048576 # 套接字接收缓冲区大小的缺省值 net.core.rmem_default = 262144 # 套接字发送缓冲区大小的缺省值 net.core.wmem_max = 1048576 # 套接字发送缓冲区大小的最大值  使/etc/sysctl.conf配置生效\nsysctl -p  调整Linux操作系统的资源限制，配置/etc/security/limits.conf\n* soft nofile 131072 # 当前系统生效的，打开文件的最大数量 * hard nofile 131072 # 当前系统设定的，打开文件的最大数量 * soft nproc 131072 # 当前系统生效的，开启进程的最大数量 * hard nproc 131072 # 当前系统设定的，开启进程的最大数量 * soft core unlimited # 当前系统生效的，内核文件的最大值 * hard core unlimited # 当前系统设定的，内核文件的最大值 * soft memlock 50000000 # 当前系统生效的，锁定内存地址空间的最大值 * hard memlock 50000000 # 当前系统设定的，锁定内存地址空间的最大值  PostgreSQL与Oracle类似，是多进程的运行方式，因此生产环境下需要做一些系统参数的优化。\n建议关闭Numa。\nIO策略\n机械硬盘设置为：Deadline\nSSD硬盘设置为：Noop\n  下载软件并解压\r#\r\r 下载软件\nwget https://ftp.postgresql.org/pub/source/v14.1/postgresql-14.1.tar.gz -P /opt/installed/  校验软件的MD5值\nmd5sum postgresql-14.1.tar.gz  解压软件\ntar -zxvf postgresql-14.1.tar.gz  进入解压的文件目录\ncd postgresql-14.1/  源码目录中的目录或文件说明：\n src：存放源代码的目录 doc：存放文档的目录 config：存放配置文件的目录 contrib：存放已打包到PostgreSQL源码中的第三方插件的源码的目录 aclocal.m4：区域编码配置文件 configure：源码安装的配置脚本 HISTORY：版本变更的历史记录 INSTALL：安装说明    编译安装软件\r#\r\r 配置安装参数\n./configure --prefix=/usr/local/pgsql --with-openssl --with-python --with-libxml --with-libxslt --enable-thread-safety --with-systemd  查看可配置参数命令：./configure --help\n注意：\n --with-blocksize的默认值是8K，如果需要对数据库进行频繁的插入操作，可以将--with-blocksize的值设置大一些。 --enable-dtrace和--enable-debug生产环境下不要加。    编译并安装所有功能\nmake world \u0026amp;\u0026amp; make install-world  切换到postgres用户，并将目录切换到postgres用户的home目录\nsu - postgres  配置环境变量，CentOS环境变量配置文件：~/.bash_profile，Debian环境变量配置文件：~/.bashrc\nexport PGHOME=/usr/local/pgsql export PGDATA=/home/postgres/pgsql/data export LANG=en_US.UTF8 export LD_LIBRARY_PATH=$PGHOME/lib:lib:usr/lib:/usr/local/lib:/lib64:/usr/lib64:/usr/local/lib64:$LD_LIBRARY_PATH export DATE=`date +\u0026#34;%Y%m%d%H%M%S\u0026#34;` export PATH=$PGHOME/bin:$PATH export MANPATH=$PGHOME/share/man:$MANPATH export PGUSER=postgres  以Debian环境为例，使环境变量生效\nsource ~/.bashrc  验证环境变量和安装\npsql --version  初始化数据\r#\r\r 切换到postgres用户\nsu - postgres  初始化数据\ninitdb -D /home/postgres/pgsql/data -E UTF8 --local=C -U postgres -W  添加-W参数会在初始化的过程中提示输入数据库超级用户的密码，默认情况下该密码为空。\n  启动PostgresSQL\r#\r\r pg_ctl -D /home/postgres/pgsql/data -l logfile start  pg_ctl --help\n  连接测试PostgresSQL\r#\r\r  PostgresSQL默认只允许本地Socket连接\n psql  添加开机启动启动\r#\r\r 将/opt/installed/postgresql-14.1/contrib/start-scripts/目录下的linux脚本文件重命名为postgresql。\n可以将postgresql启动脚本放到/etc/init.d目录下，然后使用chkconfig --add postgresql命令，将postgresql启动脚本添加到启动服务。\n也可以编写postgresql.service的systemd服务配置文件，放到/lib/systemd/system/目录下，然后使用systemctl enable postgresql命令将postgresql启动脚本添加到启动服务。\n systemd服务配置文件范例：\n[Unit] Description=PostgreSQL Server After=network.target [Service] Type=forking ExecStart=/usr/local/pgsql/bin/pg_ctl -D /home/postgres/pgsql/data start User=postgres Group=postgres [Install] WantedBy=multi-user.target systemd的使用大幅提高了系统服务的运行效率, 而unit的文件位置一般主要有三个目录：\n/etc/systemd/system\n/run/systemd/system\n/lib/systemd/system\n这三个目录的配置文件优先级依次从高到低，如果同一选项三个地方都进行了配置了，优先级高的会覆盖优先级低的。\n  卸载\r#\r\r 卸载编译安装的PostgreSQL有三种方式：\n 删除安装目录。如果编译安装时使用了--prefix指定了安装目录，直接将这个安装目录删除就可以完成卸载。 执行卸载程序。如果编译安装时没有使用了--prefix安装目录，进入软件解压后的目录，执行sudo make uninstall命令进行反编译。 搜索相关目录进行删除。使用whereis postgresql命令将找到目录都删除。   基础管理\r#\r\r 启动、关闭和重启服务\r#\r\r 启动服务\r#\r\rpg_ctl -D /home/postgres/pgsql/data -l logfile start  关闭服务\r#\r\rpg_ctl stop -m fast  重启服务\r#\r\rpg_ctl restart -m fast  重新加载配置\r#\r\rpg_ctl reload  访问控制\r#\r\r PostegreSQL安装完毕之后，默认情况下只允许从本机连接数据库，若需要其他主机连接到数据库，需要修改配置文件：/home/postgres/pgsql/data/pg_hba.conf进行访问控制，该配置问文件共有5个参数，TYPE（主机类型）、DATABASE（数据库名）、USER（用户名）、ADDRESS（IP地址和子网掩码）、METHOD（加密方法）\nTYPE中的关键字\n local：表示匹配规则为使用Unix域套接字。如果TYPE中没有为local的条目，则不允许通过Unix域套接字连接。 host：表示匹配规则为使用TCP/IP建立的连接，同时匹配SSL和非SSL的连接。 hostssl：表示匹配规则为必须使用SSL的TCP/IP连接。客户端和服务器都需要安装OpenSSL，在使用./configure配置安装参数的时候需要添加\u0026ndash;with-openssl参数，开启SSL支持，同时需要在postgresql.conf文件中配置ssl = on。 hostnossl：表示匹配规则为只使用非SSL的TCP/IP连接。  METHOM的关键字\n trust：表示无条件允许（信任）连接。允许任何可以与PostgreSQL数据库服务器连接的用户身份登入。如果规则允许，甚至可以不需要任何口令或者认证进行登入。 reject：表示无条件拒绝连接。常用于拒绝一个组中的特定主机，在下一行允许其余主机的连接。 md5：表示使用双重md5加密的方式。 password：表示使用明文密码的方式。注意在非信任网络环境中禁止使用password方式。 peer：表示从本地操作系统中获取系统用户，并检查它是否与请求连接的数据库用户匹配，但仅限于本地连接。 其他连接方式参见：https://www.postgresql.org/docs/current/static/auth-methods.html。   PostegreSQL安装完毕之后，默认情况下只监听本地localhost的连接，不允许使用TCP/IP连接，若启用远程连接，需要修改主配置文件：/home/postgres/pgsql/data/postgresql.conf的listen_adresses监听地址。postgresql.conf配置文件的结构为key = value的形式，value的值支持布尔类型、整数类型、浮点数类型、字符串类型、枚举类型和include指令（允许嵌套）。\n 注意：\nvalue的参数值为数字类型的时候可以直接写，其他类型的参数值最好以单引号包围，避免参数值无法识别。\n如果参数值本身包含单引号，可以使用单引号（推荐）或反斜杠包围。\n  在/home/postgres/pgsql/data/pg_hba.conf配置文件中增加如下内容：\nhost all all 0.0.0.0/0 trust  在/home/postgres/pgsql/data/postgresql.conf配置文件中修改如下内容，对所有可用IP接口进行监听：\nlisten_addresses = \u0026#39;*\u0026#39;  重启PostgreSQL\npg_ctl restart -m fast  用户管理\r#\r\r 创建用户\r#\r\r  使用\\help create user user;获取帮助\n  CREATE USER 用户名;  使用CREATE ROLE 用户名;也可以创建用户，但创建出来的用户不带有LOGIN权限。\n 创建用户时授权管理员权限（SUPERUSER），并设置密码\nCREATE USER 用户名 WITH SUPERUSER PASSWORD \u0026#39;密码\u0026#39;;  删除用户\r#\r\r  使用\\help drop user;获取帮助\n  DROP USER 用户名;  修改用户\r#\r\r  使用\\help alter user;获取帮助\n  # 修改用户密码 ALTER USER 用户名 WITH PASSWORD \u0026#39;密码\u0026#39;; # 修改用户权限 ALTER USER 用户名 WITH NOSUPERUSER;  查看用户\r#\r\r \\du  权限管理\r#\r\r 权限级别\r#\r\r Cluster权限：实例级别的权限通过pg_hba.conf进行配置。\nDatebase权限：数据库级别的权限通过GRANT和REVOKE命令对Schema进行配置。\nTableSpeace权限：表空间权限通过GRANT和REVOKE命令进行操作表、视图、索引等。\nSchema权限：模式权限通过GRANT和REVOKE命令进行操作。\nObject权限：对象权限通过GRANT和REVOKE命令进行操作。\n 权限定义\r#\r\r Datebases授权\nGRANT create ON DATABASE 数据库 TO 用户名;  Schema授权\nALTER SCHEMA Schema名称 OWNER to 用户名; GRANT select,insert,update ON ALL TABLES IN SCHEMA Schema名称 TO 用户名;  Object授权\nGrant select,insert,update ON 数据库.数据表 TO 用户名;  查看配置参数\r#\r\r 在数据库中，通过SHOW ALL;命令可以查看当前数据的所有配置参数。\n通过\\d pg_settings命令可以查看到pg_setting视图中都有哪些字段。\n而通过select name, context, setting, min_val, max_val, unit from pg_settings;命令查询pg_setting视图,可以查询到更加详细的配置参数和实现方法。\n 修改配置参数\r#\r\r 修改配置可以分为全局和非全局。\n 修改全局配置参数\r#\r\r修改全局配置可以通过以下方法实现：\n 通过Linux命令（vim、echo、sed）修改全局配置文件 启动时设置（不推荐，除非进入单用户模式） 通过在操作系统中通过psql -c configparameter=newvalue命令修改全局配置 在PostgreSQL中通过ALTER SYSTEM命令修改全局配置，可以通过\\h ALTER SYSTEM命令获取帮助   修改非全局配置参数\r#\r\r  数据库（Database）级别：使用ALTER DATABASE命令。 会话（Session）级别：使用SET命令。 用户（User/Role）级别：使用ALTER ROLE命。通过pg_user和pg_db_role_setting数据表可以查询到某个参数在用户级别的设置信息。   配置参数生效说明\r#\r\r 在数据库中，使用以下命令可以查看各个参数的上下文（context）配置说明\nSELECT distinct(context), name FROM pg_settings;    context 生效方式     sighup 给服务器发送HUP信号会使服务器重新加载postgresql.conf配置，立即生效   postmaster 重启服务后生效   internal 重新编译才能生效   backend 启用新会话后生效   superuser 超级用户才能修改，立即生效   user 只影响该用户的会话    使配置生效方法主要有以下四种：\n 使用超级用户，在数据库中执行SELECT pg_reload_conf();命令使修改的配置生效。 在操作系统中使用pg_ctl reload命令触发sighup信号使修改的配置生效。 通过Linux的kill命令，手动发起HUP信号，ps -ef | grep -i postmaster | grep -v grep | xargs kill -HUP。 在操作系统中通过pg_ctl restart命令重启数据库使修改的配置生效。   修改日志相关配置\r#\r\r 数据库运行日志相关的参数可以在postgresql.auto.conf文件中进行配置和修改，该文件不能直接编辑，需要在数据库中通过ALTER SYSTEM命令进行参数的配置和修改。\nALTER SYSTEM SET logging_collector = on; # 开启日志控制器 ALTER SYSTEM SET log_destination = \u0026#39;csvlog\u0026#39;; # 设置日志的存储格式 ALTER SYSTEM SET log_directory = \u0026#39;log\u0026#39;; # 设置日志存储的目录 ALTER SYSTEM SET log_filename = \u0026#39;postgresql_%Y-%m-%d_%H%M%S.log\u0026#39;; # 设置日志名称 ALTER SYSTEM SET log_rotation_age = \u0026#39;1d\u0026#39;; # 设置每天生成一个新的日志 ALTER SYSTEM SET log_rotation_size = 0; # 不限制单个日志文件的大小 ALTER SYSTEM SET log_truncate_on_rotation = on; # 控制日志文件存在时，是否覆盖日志文件 ALTER SYSTEM SET log_hostname = on; # 控制是否记录客户端的主机名 ALTER SYSTEM SET log_line_prefix = \u0026#39;%m %p %u %d %r\u0026#39;; # 设置日志内容输出的格式，默认为空 ALTER SYSTEM SET log_statement = \u0026#39;all\u0026#39;; # 控制日志记录哪些SQL语句。可设置为：none、ddl、mod、all等  参数修改完成，需要重启数据库后生效\npg_ctl restart -m fast   WAL和归档日志相关的参数也是在postgresql.auto.conf文件中进行配置和修改。\nALTER SYSTEM SET wal_level = \u0026#39;replica\u0026#39;; # 控制写入到WAL的信息量 ALTER SYSTEM SET archive_mode = on; # 允许使用archive_command命令将完成的WAL段发送到归档存储。 ALTER SYSTEM SET archive_command = \u0026#34;test ! -f /mnt/pgsql/pg_wal/%f \u0026amp;\u0026amp; cp %p /mnt/pgsql/pg_wal/%f\u0026#34;; # 执行本地shell命令来归档一个完成的WAL文件段。字符串中的任何%p都会被替换为被归档文件的路径名,而%f只被文件名替换（路径名是相对于服务器的工作目录，即集簇的数据目录）。如果要在命令里嵌入一个真正的%字符，可以使用%%。有一点很重要，该命令只在成功时返回一个零作为退出状态。  参数修改完成，需要重启数据库后生效\npg_ctl restart -m fast   psql的基本用法\r#\r\r  psql的官方介绍：https://www.postgresql.org/docs/current/app-psql.html\n  psql是PostgreSQL的一个交互式的命令行终端，通过使用私有的元命令（内置命令）或通用的SQL语句对数据库对象进行管理。在psql中可以通过tab键自动补全命令，还可以查看执行命令的历史记录。\n在系统终端中运行psql时，可以通过psql --help命令获取到所有的参数信息。\n通过psql使用IP地址连接PostgreSQL数据库示例：\npsql -h 192.168.1.100 -p 5432 -U postgres -d postgres 通过psql查看PostgreSQL的版本信息：\npsql -V 通过psql查看创建的数据库列表：\npsql -l 通过psql连接到默认数据库，并且使用元命令的时候将其翻译成标准的SQL语句：\npsql -E 在psql中所有以反斜杠\\开始的命令都是元命令，是只有psql能够处理的私有命令（方言），通过这些元命令可以让psql的管理更加高效。psql的常用命令有：\n\\?：显示PostgreSQL客户端所有以\\开头的内置命令。\n\\? options：显示psql命令的帮助信息，与在系统中执行psql --help命令结果一致。\n\\? variables：显示psql变量的帮助信息。\n\\h：显示SQL命令的帮助信息。\n\\h：后面跟需要显示帮助信息的SQL语句，后面跟*可以查询所有SQL语句的帮助信息。\n\\l：相当于MySQL的show databases;，用来查询现有的数据库信息。\n\\c：相当于MySQL的use tablename;，切换到指定的数据库。\n\\d：显示数据库中所有的数据表。\n\\d+：显示数据库中所有的数据表的详细信息。\n\\d 数据表：显示数据表结构。\n\\du：查询用户信息。\n\\x：将信息竖着显示。\n使用SELECT * FROM pg_tables;可以查询所有表的信息。\n pgAdmin的基本用法\r#\r\r  pgAdmin is the most popular and feature rich Open Source administration and development platform for PostgreSQL, the most advanced Open Source database in the world.\n官方网站：https://www.pgadmin.org\n  pgAdmin的主要功能\r#\r\r 连接数据库，并通过图形化界面管理数据库和对象 备份、恢复数据库以及维护数据库 执行SQL操作，查看和分析SQL的执行计划   系统表、视图和函数\r#\r\r 系统表\r#\r\r 系统视图\r#\r\r 系统函数\r#\r\r 体系架构\r#\r\r PostgreSQL是一个典型的C/S模型，PostgreSQL的体系结构由实例（Instance）和存储结构（On-Disk）组成，实例（Instance）由进程（Process）和内存结构（In-Mem）组成，进程（Process）由PostMaster、SP（Session Process）和BP（Background Process）组成，内存结构（In-Mem）由SGA（System Global Area）和PGA（Program Global Area）组成。\n 存储结构\r#\r\r PostgreSQL的数据存储结构分为：逻辑存储结构和物理存储结构。其中，逻辑存储结构是PostgreSQL内部的组织和管理数据的方式，物理存储结构是操作系统中组织和管理数据的方式。\n 逻辑存储结构\r#\r\r所有数据库对象都有各自的oid(object identifiers)，oid是一个无符号的四字节整数，相关对象的oid都存放在相关的System Catalog表中，比如数据库的oid和表的oid分别存放在pg_database和pg_class表中。\n 在PostgreSQL数据库终端中，使用\\dS+命令可以看到所有的System Catalog。\n  数据库集群（Database Cluster）\r#\r\r数据库集群也成为数据库集簇。它是指有单个PostgreSQL服务器实例管理的数据库集合，组成数据库集群的这些数据库使用相同的全局配置文件和监听端口、共用进程和内存结构。一个Database Cluster可以包括：多个Database、多个User、以及Database中的所有对象。\n 数据库（Database）\r#\r\r在PostgreSQL中，数据库本身也是数据库对象，并且在逻辑上彼此分离，除数据库之外的其他数据库对象（例如：表、索引等等）都属于他们各自的数据库。\n 表空间（Tablespace）\r#\r\r数据库在逻辑上分成多个存储单元，称作表空间。表空间用作把逻辑上相关的结构放在一起。数据库逻辑上是由一个或多个表空间组成。初始化的时候，会自动创建pg_default和pg_global两个表空间。其中pg_default的表空间物理文件存储在数据目录中的base目录中，pg_global用于存放系统表。表空间实际上是为表指定一个存储目录。\n 在PostgreSQL数据库终端中，可以使用\\db命令可以查看到表空间。\n创建表空间\nCREATE TABLESPACE 表空间名称 LOACTION \u0026#39;目录路径\u0026#39;; 在表空间上创建表\nCREATE TABLE 表名称(id int primary key) TABLESPACE 表空间名称;   模式（Schema）\r#\r\r当创建一个数据库时，会为其创建一个名为public的默认Schema。Schema是数据库中的命名空间，数据库中创建的所有对象都是在Schema中创建，一个用户可以从同一个客户端连接中访问不同的Schema。而不同的Schema中可以有多个同名的Table、Index、View、Sequence、Function等等数据库对象。\n 在PostgreSQL数据库终端中，可以使用\\dn查看当前数据库的Schema。\n  段（Segment）\r#\r\r一个段（Segment）是分配给一个逻辑结构（一个表、一个索引或其他对象）的一组区（Extent），是数据库对象使用空间的集合；段（Segment）可以有表段、索引段、回滚段、临时段和高速缓存段等。\n每个表和索引都存储在单独的数据文件中，以表或索引的文件节点（filenode）编号命名，如果表或索引超过1GB就会被分割成为多段，第一个段以文件节点（filenode）编号命名，第二个及以后的段以filenode1，filenode2形式命名。\n 区（Extent）\r#\r\r区（Extent）是数据库存储空间分配的一个逻辑单位，它由连续的数据块（Block）所组成。一个段（Segment）是由一个或多个盘区组成。当一个段（Segment）中的所有空间使用完毕，PostgreSQL会为该段（Segment）分配一个新的范围。\n 块（Block）\r#\r\r在PostgreSQL中，将保存在磁盘中的块（Block）称为数据页（Page），而在内存中则称为Buffer。数据的读写是以Page为最小单位，每个Page默认的大小是8K。数据页（Page）是PostgreSQL管理数据文件中存储空间的单位，是数据库引擎使用的最小I/O单位，是最小的逻辑部件。\n在编译PostgreSQL时指定BLCKSZ大小将决定Page的大小。每个表文件由多个BLCKSZ字节大小的Page组成。在分析型数据库中，适当增加BLCKSZ大小可以小幅度提升数据库的性能。\n 数据库对象（Database Object）\r#\r\r数据库对象（Database Object）包含：表、视图、索引、序列、函数等。在PostgreSQL中的所有数据库对象都由各自的对象标识符（OID）进行内部的管理。而物理位置则是通过relfilenode进行标识。\n OID：对象标识符，在数据库系统内部使用，具有唯一性，用作系统表的主键。OID不会自动添加到用户定义的表中，但可以通过设置将OID加入到用户定义的表中，但不推荐这样使用，因为一旦用户定义的表行数超过了OID的最大限制数（4 bytes int）时，就无法再插入新行了。\nrelfilenode：relfilenode默认与OID相同，但relfilenode标号会随着数据存储位置的改变而变化。在数据库中通过SELECT oid, relname, relkind, relfilenode FROM pg_class WHERE relname ='数据表名称';或者select pg_relation_filenode('数据表名称')获得对象的relfilenode标号。\n  表或索引（Relation）\r#\r\r 空闲空间映射表（FreeSpaceMap）\r#\r\r每一个表和索引(除了哈希索引)都有一个空闲空间映射(FSM)来保持对关系中可用空间的跟踪。随着表中不断插入和删除元组，文件块中必然会产生空闲空间（Free Space）。在插入元组时优先选择将其存放在空闲空间内是利用存储的好方法。如何管理这些空闲空间才能最大化地提高效率呢？ PG 8.4以前采用了一种全局FSM文件来记录所有表文件的空闲状况，复杂且低效。PG 8.4以后采用了新的策略，即对于每个表文件（包括系统表在内），同时创建一个名为“关系表OID_fsm” 的文件，用于记录该表的空闲空间大小。\n 参考书籍：《PostgreSQL数据库内核分析》\n参考博客：http://events.jianshu.io/p/4064dbb72414\n 原理：FSM机制采用一个字节表示空闲空间的大小范围，我们将这个字节叫做FSM级别（category）。FSM级别和真实的FSM范围之间的映射关系如下表所示。 FSM级别和空闲空间范围之间的映射关系\n   字节取值 表示的空闲空间范围（字节）     0 0 ~ 31   1 32 ~ 63   \u0026hellip;\u0026hellip; \u0026hellip;\u0026hellip;   255 8164 ~ 8192     可见性映射(VM)\r#\r\r 官网对于可见性映射的描述：https://www.postgresql.org/docs/14/storage-vm.html\n 为了加快VACUUM清理的速度和降低对系统I/O的影响，PG 8.4版本之后为每个数据文件增加了一个后缀为“_vm”的文件。每一个表都有一个可见性映射(VM)用来跟踪哪些页面只包含已知对所有活动事务可见的元组，它也跟踪哪些页面只包含未被冻结的元组。它随着主关系数据被存储在一个独立的关系分支中，以该关系的文件节点号（relfilenode）加上后缀“_vm”进行命名。在PostgreSQL中，更新、删除行后，数据并不会马上从数据块中清理掉，而是将每个数据块中是否需要清理的数据进行标记，通过VACUUM命令扫描这个文件时，通过这些标记，可以快速找到需要清理的数据。\n 元组（Tuple）\r#\r\r 元组（tuple）是关系数据库中的基本概念，关系是一张表，表中的每行（即数据库中的每条记录）就是一个元组，每列就是一个属性。 在二维表里，元组也称为行。\n 物理存储结构\r#\r\r PostgreSQL的物理存储结构主要是指硬盘上存储的文件，包括：数据文件、日志文件、参数文件、控制文件、redo日志（WAL）等。\n在执行initdb命令的时候，PostgreSQL会初始化一个数据目录，通常会在操作系统中配置$PGDATA环境变量来表示数据目录，初始化完成后，会在这个数据目录中生成一些相关的子目录和文件。在PostgreSQL中，表空间（Tablespace）的概念不同于其他关系型数据库，在这里，一个表空间（Tablespace）会对应一个目录。\n $PGDATA数据目录中的目录或文件介绍\n   目录或文件名称 说明     base 该目录包含数据库用户所创建的各个数据库，同时也包括用户postgres、template0和template1的表空间pg_default   global 该目录包含集群范围的各个表和相关视图   pg_commit_ts 该目录包含已提交事务的时间   pg_dynshmem 该目录包含动态共享内存子系统使用的文件   pg_hba.conf 该文件用于客户端认证控制（黑白名单的设置）   pg_ident.conf 该文件用来配置操作系统用户映射成为数据库用户   pg_logical 该目录包含逻辑解码状态数据   pg_multixact 该目录包含多事务状态数据（等待锁定的并发事务）   pg_notify 该目录包含LISTEN/NOTIFY状态数据   pg_replslot 该目录包含存储的复制槽/位数据   pg_serial 该目录包含已经提交的序列化事务的有关信息   pg_snapshots 该目录包含导出的快照   pg_stat 该目录包含统计子系统的永久文件   pg_stat_tmp 该目录包含统计子系统的临时文件   pg_subtrans 该目录包含子事务状态数据   pg_tblspc 该目录包含表空间的符号连接   pg_twophase 该目录包含预备事务的状态文件   PG_VERSION 该文件用于记录版本信息   pg_wal 该目录用于保存预写日志   pg_xact 该目录用于记录事务提交状态   postgresql.auto.conf 只保存alter system命令修改的参数   postgresql.conf PostgreSQL的主配置文件，相当于MySQL的my.cnf   postmaster.opts 记录服务器最后一次启动时使用的命令参数   postmaster.pid 主进程文件     在数据库中通过show data_directory命令可以查询$PGDATA的路径\n  数据文件\r#\r\r顾名思义，数据文件用于存储数据，也称为表文件。文件名以OID命名，对于超出1G的表数据文件，PostgreSQL会自动将其拆分为多个文件来存储，而拆分的文件名将由pg_class表中的relfilenode字段来决定。\nSELECT oid, relname, relkind, relfilenode FROM pg_class WHERE relname =\u0026#39;testtable1\u0026#39;;  日志文件\r#\r\rPostgreSQL日志文件的类型分为：运行日志（pg_log）、重做日志（pg_xlog）、事务日志（pg_xact）和服务器日志。\n  运行日志（pg_log）\n运行日志（pg_log）默认没有开启，开启后会自动生成。查看postgresql.conf文件的配置可以看到相关的参数设置。这个日志一般是记录服务器与数据库的状态，比如各种Error信息，定位慢查询SQL，数据库的启动关闭信息，发生checkpoint过于频繁等的告警信息，诸如此类。该日志有.csv格式和.log。建议使用.csv格式，因为它一般会按大小和时间自动切割。运行日志（pg_log）是可以被清理删除、压缩打包或者转移的，同时并不影响数据库的正常运行。当遇到数据库无法启动或者更改参数没有生效时，第一个想到的就是查看这个日志。\n  重做日志（pg_xlog）\n重做日志（pg_xlog） 是记录PostgreSQL的WAL信息，默认存储在$PGDATA/pg_wal/目录下，是一些事务日志信息(Transaction Log)。默认单个大小是16M，源码安装的时候可以更改其大小（通过./configure --with-wal-segsize=target_value 参数进行设置），这些日志会在定时回滚恢复(PITR)、流复制(Replication Stream)以及归档时被用到，这些日志文件非常重要，记录着数据库发生的各种事务信息，不得随意删除或者移动，不然数据库会有无法恢复的风险。\n  事务日志（pg_xact）\n事务日志（pg_xact）是事务的提交日志，记录了事务的元数据。默认开启，内容一般不能直接读取。默认存储在$PGDATA/pg_xact/目录下。\n  服务器日志\n服务器日志记录了数据库的重要信息。如果用pg_ctl命令启动数据库的时候，没有指定-l参数来指定服务器日志，错误信息可能会直接输出到cmd前台而不被保存。\n   参数文件\r#\r\rPostgreSQL数据库中主要的参数文件是postgresql.conf、pg_hba.conf、postgresql_auto.conf和pg_ident.conf。\n  postgresql.conf\nPostgreSQL的主参数文件，有很详细的说明和注释，和Oracle的pfile，MySQL的my.cnf类似。默认在$PGDATA下。很多参数修改后都需要重启。仔9.6版本之后支持了使用alter system命令来修改，修改后的参数会保存在$PGDATA/postgresql.auto.conf文件下，可以使用reload或者restart来使之生效。\n  pg_hba.conf\n这是一个类似黑白名单，用于访问控制的参数配置文件。\n  postgresql_auto.conf\n它和postgresql.conf的格式相同，但不允许手动编辑，只允许在数据库中通过ALTER SYSTEM命令设置参数，换句话说，postgresql_auto.conf只保存alter system命令修改的参数。在读取postgresql.conf文件时自动读取postgresql_auto.conf，并且postgresql_auto.conf的设置会覆盖掉postgresql.conf中的设置。\n  pg_ident.conf\n这是一个用户映射配置文件，用来配置哪些操作系统用户可以映射为数据库用户。结合pg_hba.conf配置文件中的method为ident可以用特定的操作系统用户和指定的数据库用户登录数据库。\n   控制文件\r#\r\r控制文件（ControlFile）记录了数据库的运行信息，比如数据库ID，是否运行，WAL的位置，CheckPoint的位置等。控制文件（ControlFile）是很重要的文件。 控制文件默认存储在$PGDATA/global/pg_control目录下，在操作系统中使用pg_controldata $PGDATA命令可以查看控制文件的内容。\n redo日志（WAL）\r#\r\r默认存储在$PGDATA/pg_wal目录下，目录中文件名称为16进制由24个字符组成的文件名，每8个字符一组，每组的意义如下：\n00000001 00000000 00000001 时间线 逻辑ID 物理ID 在数据库中通过select pg_switch_wal();命令可以手动切换WAL。\n 进程结构\r#\r\r 在Linux操作系统中使用ps -ef | grep postgres命令可以查询到所有PostgreSQL的进程。\n Postmaster进程\r#\r\r主进程Postmaster是整个数据库实例的总控制进程，负责启动和关闭数据库实例。用户可以运行/usr/local/postgresql/bin/postgres加上合适的参数来启动数据库和Postmaster进程，实际上，postgres是一个指向postmaster的软链接。更多时候，我们使用pg_ctl命令启动数据库，pg_ctl命令也是通过运行postgres来启动数据库，它只是做了一些包装，让我们更容易启动数据库，所以，主进程Postmaster实际是第一个postgres进程，此进程会fork一些与数据库实例相关的辅助子进程，并管理他们。\n当用户与PostgreSQL数据库建立连接时，实际上是先与Postmaster主进程建立连接。此时，客户端程序会发出身份证验证的消息给Postmaster进程，Postmaster主进程根据消息中的信息进行客户端身份验证。如果验证通过，它会fork一个名为postgres的子进程（有些地方也称为：Backend Process）为这个连接服务，fork出来的postgres子进程被称为服务进程，查询pg_stat_activity表可以看到这些服务进程的PID。\n SysLogger进程\r#\r\r在postgresql.conf主配置文件里启用运行日志（pg_log）后，会产生SysLogger进程。SysLogger进程会在日志文件达到指定的大小时关闭当前日志文件，并产生新的日志文件。相关配置参数如下：\n   配置参数 说明     log_destination 配置日志输出的目标，根据不同平台设置不同的值，Linux下默认为stderr   logging_collector 是否开启日志收集器，当设置为on时，启动日志功能，否则，系统将不产生系统日志辅助进程   log_directory 配置日志输出的文件目录   log_filename 配置日志文件名称的命名规则   log_rotation_size 配置日志文件大小，当前日志文件达到这个大小时会被关闭，然后创建一个新的日志文件     BgWriter进程\r#\r\rBgWriter（后台写）进程是PostgreSQL中在后台将脏页写到磁盘的辅助进程，引入该进程主要为了达到两个目的：\n  当数据库在进行查询处理时，若发现要读取的数据不在缓冲区中，要先从磁盘中读取数据所在的数据页（Page）（缓冲区由一个数据页(块)的空间和标题组成），此时，如果缓冲区已满，则需要先选择部分缓冲区中的数据页（Page）将其替换出去。如果被替换的数据页（Page）没有被修改过，那么可以直接丢弃；但如果要被替换的数据页（Page）已被修改，则必需先将这些数据页（Page）写到磁盘中后才能替换，这样一来，数据库的查询处理就会被阻塞。通过使用BgWriter定期将缓冲区中的部分脏页写到磁盘上，为缓冲区腾出空间，这样就可以降低查询处理被阻塞的可能性。\n 脏页是linux内核中的概念，因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存，linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页，内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。\n   PostgreSQL在定期作检查点时，需要把所有脏页写到磁盘，通过BgWriter预先将一些脏页写出到磁盘，可以减少设置检查点时要进行的I/O操作，使系统的I/O负载趋向平稳。通过BgWriter对共享缓冲区写操作的统一管理，避免了其他服务进程在需要读取新的数据页（Page）到共享缓冲区时，需将之前修改过的页面写到磁盘的操作。\n   WALWriter进程\r#\r\rWALWriter（预写日志写）进程用于保存WAL预写日志。预写式日志WAL（Write Ahead Log，也称为Xlog）的中心思想是：对数据文件的修改必须只能发生在这些修改已经记录到日志之后，也就是先写日志后写数据。如果遵循这个过程，那么就不需要在每次事务提交的时候都把数据页（Page）写到磁盘，这一点与Oracle数据库是完全一致的。与WalWriter进程有关的配置在postgresql.conf主配置文件中的\\# WRITE AHEAD LOG下，默认为开启状态。\n 先写日志后写数据是为保证数据库的可恢复性，日志文件能够用来进行事务故障恢复和系统故障恢复，并能够协助后备副本进行介质故障恢复。当数据库文件毁坏后，通过数据库备份可以将数据库恢复到转储结束时刻的正确状态，再利用建立的日志文件，可以把已完成的事务进行重做（redo）处理，而对于故障发生时尚未完成的事务则进行撤消处理，这样不用运行应用程序就可把数据库恢复到故障前某一时刻的正确状态。”\n  PgArch进程\r#\r\rPgArch（归档）进程。从PostgreSQL 8.x开始，有了PITR（Point-In-Time-Recovery）技术，该技术支持将数据库恢复到其运行历史中任意一个有记录的时间点；PITR的另一个重要的基础就是对WAL文件的归档功能。PgArch归档进程的目标就是对WAL日志在磁盘上的存储形式进行归档备份。但在默认情况下，PostgreSQL是非归档模式，因此看不到PgArch进程。与PgArch进程有关的配置在postgresql.conf主配置文件中的# - Archiving -下，需要手动开启。\n AutoVacuum进程\r#\r\rAutoVacuum（自动清理）进程。在PostgreSQL数据库中，对数据进行UPDATE或者DELETE操作后，数据库不会立即删除旧版本的数据，而是标记为删除状态。这是因为PG数据库具有多版本的机制，如果这些旧版本的数据正在被另外的事务打开，那么暂时保留他们是很有必要的。当事务提交后，旧版本的数据已经没有价值了，数据库需要清理垃圾数据腾出空间，而清理工作就是AutoVacuum进程进行的。与AutoVacuum进程有关的配置在postgresql.conf主配置文件中的# AUTOVACUUM下，默认为开启状态。\n PgStat进程\r#\r\rPgStat（统计信息收集）进程是PostgreSQL数据库的信息统计收集器，用来收集数据库运行期间的统计信息，如数据表的增、删、改次数，数据块（数据页）的个数，索引的变化等。收集统计信息主要是为了让优化器能做出正确的判断，选择最佳的执行计划。与PgStat进程有关的配置在postgresql.conf主配置文件中的# RUNTIME STATISTICS下，默认为开启状态。\n CheckPoint进程\r#\r\rCheckPoint（检查点）进程是数据库系统设置的事务序列点，设置检查点是为了保证检查点前的日志信息写入到磁盘中。与CheckPoint进程有关的配置在postgresql.conf主配置文件中的# - Checkpoints -下，默认为开启状态。\n 内存结构\r#\r\r PostgreSQL的内存结构分为本地内存和共享内存。\n 本地内存\r#\r\r本地内存是由Postmaster主进程fork出的每个postgres的子进程（有些地方也称为：Backend Process）自己所使用的内存区域。\n所有本地内存的参数都在$PGDATA/postgresql.conf主配置文件中进行设置。\n   本地内存的参数类型 说明     work_mem 使用work_mem区域用于对元组的排序，例如：order by、distinct等命令的操作。也用于表之间的join操作，例如：merge-join、hash-join等命令的操作，都是由work_mem参数控制内存大小的，默认是4MB。推荐值：（输入内存数量-shared_buffers）/（连接数*3）*1024KB，注意不要全局生效。   mantenance_work_mem 用于一些数据库维护操作时可使用内存空间的大小。例如：vacuum、reindex、alter table add foreign key等命令的操作，都是由mantenance_work_mem参数控制内存大小的，默认是64MB。由于数据库会话一次只能执行其中的一个操作，并且PostgreSQL不会同时运行许多操作，因此可以将mantenance_work_mem参数的值设置为明显大于work_mem的值。设置建议：内存容量*10%，最大不超过1GB。   temp_buffers 用于存放临时表。该参数用于设置每个数据库会话使用的临时缓冲区的最大值。会话本地缓冲区仅用于访问临时表。可以在单个会话中更改此参数的设置，但只能在会话中首次使用临时表之前更改。PostgreSQL利用这个内存区域来保存每个会话的临时表，当会话关闭时，这些临时表将被清除，temp_buffers的默认值是8MB     共享内存\r#\r\r所有进程共同使用的的内存区域。\n共享内存除了clog，其他参数都在$PGDATA/postgresql.conf主配置文件中进行设置。\n   共享内存的参数类型 说明     shared_buffers 表示数据缓冲区中数据块的个数，每个数据块的大小是8KB。PostgreSQL将表和索引中的页面从持久存储（硬盘）加载到内存的共享缓冲池中，然后直接对他们进行操作，共享缓冲池的大小由参数shared_buffers参数控制，默认是：128MB。推荐值：1/4主机物理内存。   wal_buffers 用存放还未写入到磁盘的WAL数据，降低磁盘I/O。默认值-1表示该参数设置为shared_buffers的1/32（大约3%）。   clog clog(全称Commit Log，\rPostgreSQL transaction-commit-log manager，主要在clog.c中实现)里面记录了事务的执行状态，每次事务提交和回滚的时候，都需要更新该状态（调用CommitTransactionCommand(void)），PostgreSQL服务器访问该文件确定事务的状态，保存在$PGDATA/pg_xact目录中，每个文件大小为256KB，每个事务2位（bit），故1个文件可以包含131072个事务。事务有以下四种状态：in_progress、commited、aborted、sub-commited。     总结\r#\r\r   PostgreSQL是一种客户端/服务器的进程架构模型，主要包括内存管理、服务进程、配置文件、磁盘存储管理等几个部分。\n  PostgreSQL中服务对数据的操作主要是通过内存中的缓冲区与磁盘上的数据文件进行交互，内存中的缓冲区分为本地（私有）和共享两种类型。\n  PostgreSQL中配置文件主要负责约束PostgreSQL服务进程的工作方式，同时负责数据库安全访问等功能。\n  PostgreSQL数据库的数据表是以表文件的方式存储在指定的文件目录下，大小超过1G时会生成新的表文件。在相同目录下，还存有空闲空间映射（FSM）文件和可见性映射（VM）文件。\n  PostgreSQL数据库常用的操作命令\n  查看Cluster中有哪些数据库\npostgres=# \\d   查看数据表结构\npostgres=# \\d 表名称   查看数据表存储的相对路径\npostgres=# select pg_relation_filepath(\u0026#39;表名称\u0026#39;);   查看base目录的存储路径\npostgres=# show data_directory;  在PostgreSQL中可以通过\\! [COMMAND]的方式运行shell命令。\n      PostgreSQL优化\r#\r\r postgresql.conf\r#\r\rrandom_page_cost = 2.5 # 规划器对一次非顺序获取磁盘页面的代价估计。默认值是：4.0。高端存储或SSD可适当调小该参数。\nautovacuum_max_worker = 10 # 指定能同时运行autovacuum进程的最大数量，可以适当调大，避免vacuum不及时导致表膨胀。\ncheckpoint_completion_target = 0.7 # 适当调大该参数来降低检查点的I/O负载，默认值是：0.5。\narchive_timeout = 1800 # 强制服务器周期性的切换到新的WAL段文件。\narchive_command = 'test ! -f /paic/dba/pgbackup/${PGNAME}/archlog/%f \u0026amp;\u0026amp; pxz -2 \u0026lt; %p \u0026gt; /paic/dba/pgbackup/${PGNAME}/archlog/%f' # pxz压缩归档日志，64M的归档，压缩时间可以在0.5秒内，压缩比一般可以在1:3左右。\n "},{"id":55,"href":"/docs/Docker/%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85Docker/","title":"源码安装Docker","section":"Docker","content":"卸载之前安装过的Docker\nyum remove -y docker-* 下载并解压Docker\ntar -xvf docker-20.10.9.tgz 将解压出来的Docker目录下的指令文件复制到/usr/bin/目录下\ncp docker/* /usr/bin/ 将Docker注册为Service服务\nvim /etc/systemd/system/docker.service [Unit] Description=Docker Appletion Container Engine Documentation=https://docs.docker.com After=network-online.target Wants=network-online.target [Service] Type=notify ExecStart=/usr/bin/dockerd -g /opt/data/docker ExecReload=/bin/kill -s HUP $MAINPID LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity TimeoutStartSec=0 Delegate=yes KillMode=process Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target  ExecStart=/usr/bin/dockerd -g /opt/data/docker # 启动Docker并指定数据目录\n 创建Docker数据目录\nmkdir -p /opt/data/docker 添加执行权限并重新加载配置文件\nchmod a+x /etc/systemd/system/docker.service systemctl daemon-reload systemctl restart docker "}]